{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b52eed-1c1f-44e9-b6b5-d1a172676a4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <font color='#cec748'>This notebook is to analyze the AGN data from Chenxu: Normalized</font>\n",
    "The notebook uses data from the get_spec_example file to:\n",
    "- Work with the spectra (make adjustments and clean up)\n",
    "- Look at spectra over wavelength\n",
    "- Fit spectral lines\n",
    "- Find BH Mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbae8c-de21-41f3-9713-a140a222b53d",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a72e1df-6d2c-47da-aed6-031bf3973fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dustmaps.config import config\n",
    "config.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93bdf3f4-06d5-42cd-8cf2-736d1fd9e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating dustmaps config with /home/jovyan/Hobby-Eberly-Telesco/hdr3/calib/dustmaps\n"
     ]
    }
   ],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import math\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from elixer import global_config as G\n",
    "G.GLOBAL_LOGGING = True\n",
    "from elixer import spectrum_utilities as ESU\n",
    "from elixer import catalogs\n",
    "\n",
    "\n",
    "from hetdex_api.elixer_widget_cls import ElixerWidget\n",
    "from hetdex_api.config import HDRconfig\n",
    "from hetdex_tools.get_spec import get_spectra\n",
    "from hetdex_api.shot import *\n",
    "from hetdex_api.survey import FiberIndex\n",
    "\n",
    "import inspect\n",
    "import scipy.stats as stats\n",
    "from astropy.table import QTable, Table, Column\n",
    "import warnings\n",
    "from astropy.modeling import models\n",
    "from specutils.spectra import Spectrum1D, SpectralRegion\n",
    "from specutils.fitting import fit_generic_continuum\n",
    "from specutils.fitting.continuum import fit_continuum\n",
    "from astropy.stats import biweight_location\n",
    "from scipy.integrate import quad as quad\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from numpy.polynomial.polynomial import polyval\n",
    "from photutils.centroids import centroid_2dg, centroid_sources\n",
    "from numpy import inf\n",
    "\n",
    "from matplotlib.widgets import Button\n",
    "\n",
    "from astropy.modeling import fitting\n",
    "\n",
    "from tqdm.notebook import tqdm  # For Jupyter notebook\n",
    "from joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "from scipy.stats import probplot\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.stats import median_abs_deviation\n",
    "import warnings\n",
    "\n",
    "from scipy.optimize import curve_fit, differential_evolution, minimize\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a6497-185d-412f-ab28-c689d1d8a96c",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Plotting imports and settings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5852afc-3276-40cb-bbe0-d5b50e46bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "import matplotlib.ticker\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "%matplotlib ipympl\n",
    "plt.style.use('default')\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "plt.rcParams['mathtext.default'] = 'regular'\n",
    "plt.rcParams['xtick.direction']= 'in'\n",
    "plt.rcParams['ytick.direction']= 'in'\n",
    "plt.rcParams['xtick.labelsize']= 14.0\n",
    "plt.rcParams['ytick.labelsize']= 14.0\n",
    "plt.rcParams['mathtext.default'] = 'rm' # All math text will be upright Roman\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d516d-7f52-4724-a498-17b6187b56e9",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e05717-729a-4c32-82df-6a61ba49aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 299792.5 #km s^-1\n",
    "H_0 = 70 #km s^-1 MpC^-1\n",
    "\n",
    "\"\"\"\n",
    "These are the rest wavelengths in angstroms for the lines that are important for the fits.\n",
    "\"\"\"\n",
    "HeII_2733 = 2733.289\n",
    "MgII_2800 = 2799.000\n",
    "FeIV_2829 = 2829.36\n",
    "FeIV_2836 = 2835.740\n",
    "ArIV_2854 = 2853.670\n",
    "ArIV_2868 = 2868.210\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "To get the FWHM to use in my MgII fitting in velocity space. \n",
    "This will give a minumum not a maximum.\n",
    "FWHM = speed of light / spectral resolution.\n",
    "\"\"\"\n",
    "R = 800 #Spectral Resolution\n",
    "\n",
    "FWHM_Velocity = c/R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a36e15a-695c-4f24-b3da-eaa2b2a2bd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get the function\\'s signature\\nsignature = inspect.signature(ESU.stack_spectra)\\nprint(\"Signature:\", signature)\\n\\n# Get the return type annotation\\nreturn_type = signature.return_annotation\\nprint(\"Return type:\", return_type)\\n\\n# Get the docstring\\ndocstring = inspect.getdoc(ESU.stack_spectra)\\nprint(\"Docstring:\", docstring)\\n\\n# Get the source code\\nsource_code = inspect.getsource(ESU.stack_spectra)\\nprint(\"Source code:\\n\", source_code)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to figure out everything about the calls / definitions\n",
    "\n",
    "\"\"\"\n",
    "# Get the function's signature\n",
    "signature = inspect.signature(ESU.stack_spectra)\n",
    "print(\"Signature:\", signature)\n",
    "\n",
    "# Get the return type annotation\n",
    "return_type = signature.return_annotation\n",
    "print(\"Return type:\", return_type)\n",
    "\n",
    "# Get the docstring\n",
    "docstring = inspect.getdoc(ESU.stack_spectra)\n",
    "print(\"Docstring:\", docstring)\n",
    "\n",
    "# Get the source code\n",
    "source_code = inspect.getsource(ESU.stack_spectra)\n",
    "print(\"Source code:\\n\", source_code)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c570da7-965e-4fab-9464-2352658edd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor plotting clear distinctions \\n\\nTeal - #309898 - Original teal base\\nOrange - #FF9F00 - Original orange base\\nRed - #CB0404 - Original red base\\nBlack - #000000 - Original black base\\nNavy Blue - #1D5799 - Deep blue with good contrast against teal\\nYellow - #ECC700 - Bright yellow distinguishable from orange\\nPurple - #8B3D88 - Distinct from blues and reds\\nLime Green - #74B741 - Bright green distinguishable from teal\\nMagenta - #DB3EB1 - Distinct pink/purple\\nBrown - #8D6E42 - Earth tone distinct from oranges and reds\\n\\n\\n\\n\\nSequential Teal Variants (for heatmaps or gradients)\\n\\nTeal 100% - #309898 - Base teal\\nTeal 80% - #5CACA6 - Lighter teal\\nTeal 60% - #87BFB5 - Even lighter teal\\nTeal 40% - #B2D2CC - Very light teal\\nTeal 20% - #D9E6E3 - Almost white teal\\n\\n\\n\\n\\nSequential Orange Variants (for heatmaps or gradients)\\n\\nOrange 100% - #FF9F00 - Base orange\\nOrange 80% - #FFB440 - Lighter orange\\nOrange 60% - #FFC977 - Even lighter orange\\nOrange 40% - #FFDEA6 - Very light orange\\nOrange 20% - #FFF0D9 - Almost white orange\\n\\n\\n\\n\\nHigh Contrast Pairs\\nThese pairs are specifically designed to be highly distinguishable from each other:\\n\\nVivid Blue - #0072B2 - ColorBrewer-inspired blue\\nVivid Orange - #E69F00 - ColorBrewer-inspired orange\\nVivid Green - #009E73 - ColorBrewer-inspired green\\nVivid Red - #D55E00 - ColorBrewer-inspired red\\nVivid Purple - #9467BD - ColorBrewer-inspired purple\\n\\n\\n\\n\\nSpecial Purpose\\n\\nBackground Gray - #F0F0F0 - Light gray for plot backgrounds\\nGrid Line Gray - #CCCCCC - Medium gray for grid lines\\nHighlight Yellow - #FFFB54 - Attention-grabbing highlight\\nReference Line - #505050 - Dark gray for reference lines\\nAnnotation Red - #E41A1C - Bright red for important annotations\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For plotting clear distinctions \n",
    "\n",
    "Teal - #309898 - Original teal base\n",
    "Orange - #FF9F00 - Original orange base\n",
    "Red - #CB0404 - Original red base\n",
    "Black - #000000 - Original black base\n",
    "Navy Blue - #1D5799 - Deep blue with good contrast against teal\n",
    "Yellow - #ECC700 - Bright yellow distinguishable from orange\n",
    "Purple - #8B3D88 - Distinct from blues and reds\n",
    "Lime Green - #74B741 - Bright green distinguishable from teal\n",
    "Magenta - #DB3EB1 - Distinct pink/purple\n",
    "Brown - #8D6E42 - Earth tone distinct from oranges and reds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sequential Teal Variants (for heatmaps or gradients)\n",
    "\n",
    "Teal 100% - #309898 - Base teal\n",
    "Teal 80% - #5CACA6 - Lighter teal\n",
    "Teal 60% - #87BFB5 - Even lighter teal\n",
    "Teal 40% - #B2D2CC - Very light teal\n",
    "Teal 20% - #D9E6E3 - Almost white teal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sequential Orange Variants (for heatmaps or gradients)\n",
    "\n",
    "Orange 100% - #FF9F00 - Base orange\n",
    "Orange 80% - #FFB440 - Lighter orange\n",
    "Orange 60% - #FFC977 - Even lighter orange\n",
    "Orange 40% - #FFDEA6 - Very light orange\n",
    "Orange 20% - #FFF0D9 - Almost white orange\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "High Contrast Pairs\n",
    "These pairs are specifically designed to be highly distinguishable from each other:\n",
    "\n",
    "Vivid Blue - #0072B2 - ColorBrewer-inspired blue\n",
    "Vivid Orange - #E69F00 - ColorBrewer-inspired orange\n",
    "Vivid Green - #009E73 - ColorBrewer-inspired green\n",
    "Vivid Red - #D55E00 - ColorBrewer-inspired red\n",
    "Vivid Purple - #9467BD - ColorBrewer-inspired purple\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Special Purpose\n",
    "\n",
    "Background Gray - #F0F0F0 - Light gray for plot backgrounds\n",
    "Grid Line Gray - #CCCCCC - Medium gray for grid lines\n",
    "Highlight Yellow - #FFFB54 - Attention-grabbing highlight\n",
    "Reference Line - #505050 - Dark gray for reference lines\n",
    "Annotation Red - #E41A1C - Bright red for important annotations\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e35c55-de96-4f56-a331-1faa681c8d13",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Definitions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace224e0-cb24-482a-8414-02c1ab151c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InteractivePlotter:\n",
    "    def __init__(self, plots_data, spectral_lines=None):\n",
    "        \"\"\"\n",
    "        Initialize an interactive plot viewer\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        plots_data : list of tuples\n",
    "            Each tuple contains (x_data, y_data, label)\n",
    "        spectral_lines : dict, optional\n",
    "            Dictionary mapping wavelengths to (color, linestyle, label)\n",
    "        \"\"\"\n",
    "        self.plots = plots_data\n",
    "        self.curr_pos = 0\n",
    "        self.spectral_lines = spectral_lines or {}\n",
    "        \n",
    "        # Create figure and axis\n",
    "        self.fig, self.ax = plt.subplots(figsize=(12, 6))\n",
    "        self.fig.subplots_adjust(bottom=0.2)  # Make room for buttons\n",
    "        \n",
    "        # Connect key press event\n",
    "        self.fig.canvas.mpl_connect('key_press_event', self.key_event)\n",
    "        \n",
    "        # Add navigation buttons\n",
    "        ax_prev = plt.axes([0.7, 0.9, 0.1, 0.075]) #[x-axis, y-axis, width, height]\n",
    "        ax_next = plt.axes([0.81, 0.9, 0.1, 0.075])\n",
    "        self.btn_prev = Button(ax_prev, 'Previous')\n",
    "        self.btn_next = Button(ax_next, 'Next')\n",
    "        self.btn_prev.on_clicked(self.prev_plot)\n",
    "        self.btn_next.on_clicked(self.next_plot)\n",
    "        \n",
    "        # Initial plot\n",
    "        self.update_plot()\n",
    "        \n",
    "    def key_event(self, event):\n",
    "        \"\"\"Handle keyboard navigation\"\"\"\n",
    "        if event.key == \"right\":\n",
    "            self.next_plot(event)\n",
    "        elif event.key == \"left\":\n",
    "            self.prev_plot(event)\n",
    "        \n",
    "    def next_plot(self, event):\n",
    "        \"\"\"Show next plot in sequence\"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        % - modulo operator for circular navigation\n",
    "        % len(self.plots) - takes the remainder when divided by the total number of plots. This creates a \"wrapping\" effect that ensures your index stays within the valid range of the list.\n",
    "        \"\"\"\n",
    "        self.curr_pos = (self.curr_pos + 1) % len(self.plots)\n",
    "        self.update_plot()\n",
    "        \n",
    "    def prev_plot(self, event):\n",
    "        \"\"\"Show previous plot in sequence\"\"\"\n",
    "        self.curr_pos = (self.curr_pos - 1) % len(self.plots)\n",
    "        self.update_plot()\n",
    "    \n",
    "    def update_plot(self):\n",
    "        \"\"\"Update the current plot\"\"\"\n",
    "        if not self.plots:\n",
    "            return\n",
    "            \n",
    "        self.ax.clear()\n",
    "        x_data, y_data, y_data_sd, label = self.plots[self.curr_pos]\n",
    "        \n",
    "        # Plot the main data\n",
    "        self.ax.plot(x_data, y_data, lw=1.5, color=\"black\")\n",
    "        self.ax.fill_between(x_data, y_data-y_data_sd, y_data+y_data_sd, color=\"lightgray\", alpha=0.5)\n",
    "\n",
    "        # Add spectral lines\n",
    "        for wavelength, (color, linestyle, line_label, linewidth) in self.spectral_lines.items():\n",
    "            self.ax.axvline(x=wavelength, color=color, linestyle=linestyle, \n",
    "               linewidth=linewidth, label=line_label)\n",
    "        \n",
    "        # Set labels and title\n",
    "        self.ax.set_title(f\"Spectrum {self.curr_pos+1}/{len(self.plots)}\")\n",
    "        self.ax.set_xlabel(\"Rest Wavelength (Å)\")\n",
    "        self.ax.set_ylabel(r\"Flux [erg $\\AA^{-1} s^{-1} cm^{-2}$] {label}\")\n",
    "        \n",
    "        # Add legend outside the plot area\n",
    "        self.ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), \n",
    "                       ncol=min(5, len(self.spectral_lines)), frameon=False)\n",
    "\n",
    "        # Refresh the canvas\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"Display the interactive plot\"\"\"\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#def getting_spectra_for_redshift_range(index, spec):\n",
    "#    \"\"\"\n",
    "#    \n",
    "#    \n",
    "#    Parameters:\n",
    "#    -----------\n",
    "#    plots_data : list of tuples\n",
    "#        Each tuple contains (x_data, y_data, label)\n",
    "#    spectral_lines : dict, optional\n",
    "#        Dictionary mapping wavelengths to (color, linestyle, label)\n",
    "#    \"\"\"\n",
    "#\n",
    "#    rest_specs_a, rest_errs_a, rest_waves_a = [], [], []\n",
    "#    \n",
    "#    for i in np.arange(len(spec)):\n",
    "#        if i in index:\n",
    "#            obs_spec = spec[i]['spec1d'] * 1e-17\n",
    "#            obs_err = spec[i]['spec1d_err'] * 1e-17\n",
    "#            z = spec[i]['z']\n",
    "#            wavelength = spec[i]['wave1d']\n",
    "#        \n",
    "#            CALFIB_WAVEGRID_VAC = ESU.air_to_vac(wavelength)\n",
    "#        \n",
    "#            spec_rest, wave_rest, err_rest = ESU.shift_flam_to_rest_luminosity_per_aa(z, obs_spec, CALFIB_WAVEGRID_VAC, obs_err)\n",
    "#            \n",
    "#            spec_rest = obs_spec * (1+z)**3\n",
    "#            \n",
    "#            rest_specs_a.append(spec_rest)\n",
    "#            rest_errs_a.append(err_rest)\n",
    "#            rest_waves_a.append(wave_rest)\n",
    "#            \n",
    "#    return rest_specs_a, rest_errs_a, rest_waves_a\n",
    "\n",
    "#def stacking_for_redshift_range(rest_specs, rest_errs, rest_waves):\n",
    "#    #stack all spectra \n",
    "#    avg_type = 'biweight' #'weighted_biweight', 'mean', 'median'\n",
    "#    stack_spec, stack_spec_err, stack_wave, contrib_count = ESU.stack_spectra(rest_specs, rest_errs, rest_waves, avg_type=avg_type)\n",
    "#    \n",
    "#    return stack_spec, stack_spec_err, stack_wave, contrib_count\n",
    "\n",
    "\n",
    "def continuum(wave, start, stop, flux):\n",
    "    index = np.where(np.logical_and(np.array(wave) > start , np.array(wave) < stop))\n",
    "    continuum_wave = wave[index]\n",
    "    continuum_flux = flux[index]\n",
    "    \n",
    "    return [continuum_wave, continuum_flux, index]\n",
    "\n",
    "    \n",
    "def get_residuals(spec, fit):\n",
    "    residuals = spec - fit\n",
    "    return residuals\n",
    "\n",
    "\n",
    "#def getting_spectra_for_redshift_range_con_match(index, specs, errs, waves):\n",
    "#    \n",
    "#\n",
    "#    specs_a, errs_a, waves_a = [], [], []\n",
    "#    \n",
    "#    for i in index:\n",
    "#            specss = specs[i]\n",
    "#            errss = errs[i]\n",
    "#            wavess = waves[i]\n",
    "#        \n",
    "#            specs_a.append(specss)\n",
    "#            errs_a.append(errss)\n",
    "#            waves_a.append(wavess)\n",
    "#            \n",
    "#    return specs_a, errs_a, waves_a\n",
    "\n",
    "\n",
    "\n",
    "def velocity_of_the_center(rest_obs_MgII_center, rest_obs_MgII_center_sd, lab):\n",
    "    \"\"\"\n",
    "    This finds the velocity of the rest observed MgII center from the rest wavelength fits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rest_obs_MgII_center : float\n",
    "        This is the rest wavelength center of the MgII rest wavelength fits. The g1 and g2 centers are averaged.\n",
    "    rest_obs_MgII_center_sd : float\n",
    "        The standard deviation of the rest wavelength center.\n",
    "    lab : float\n",
    "        The lab wavelength for the non doublet resolved MgII\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    velocity : float\n",
    "        The velocity of the center rest wavelength.\n",
    "    velocity_sd : float\n",
    "        The standard deviation of the velocity of the rest wavelength center\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the velocity\n",
    "    vel = (rest_obs_MgII_center - lab) / lab\n",
    "    velocity = c * vel\n",
    "    \n",
    "    # Calculate the standard deviation of the velocity\n",
    "    # Using error propagation: σ_v = c * σ_λ / λ_lab\n",
    "    velocity_sd = c * rest_obs_MgII_center_sd / lab\n",
    "    \n",
    "    return velocity, velocity_sd\n",
    "\n",
    "\n",
    "def velocity_shift_of_center_to_zero(rest_wave, lab, velocity_of_center, velocity_of_center_sd):\n",
    "    \"\"\"\n",
    "    Calculate the velocity shift and its uncertainty.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rest_wave : float or numpy.ndarray\n",
    "        The rest wavelength(s) observed.\n",
    "    lab : float or numpy.ndarray\n",
    "        The laboratory wavelength(s).\n",
    "    velocity_of_center : float\n",
    "        The velocity of the center.\n",
    "    velocity_of_center_sd : float\n",
    "        The standard deviation of the velocity of the center.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    vel : float or numpy.ndarray\n",
    "        The velocity shift.\n",
    "    vel_sd : float or numpy.ndarray\n",
    "        The standard deviation of the velocity shift.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the velocity\n",
    "    V = np.subtract(rest_wave, lab)\n",
    "    V_ = np.divide(V, lab) * c\n",
    "    vel = V_ - velocity_of_center\n",
    "    \n",
    "    # The final velocity shift uncertainty comes only from velocity_of_center\n",
    "    vel_sd = np.full_like(vel, velocity_of_center_sd)\n",
    "    \n",
    "    return vel, vel_sd\n",
    "\n",
    "\n",
    "#Calculating the BH mass\n",
    "def black_hole_mass(lam, wave_L_3000, FWHM, wave_L_3000_err=None, FWHM_err=None):\n",
    "    \"\"\"\n",
    "    Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "    This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lam : float\n",
    "        Normalization constant, typically 1.0.\n",
    "    wave_L_3000 : float or array-like\n",
    "        Continuum luminosity at 3000Å in erg/s.\n",
    "    FWHM : float or array-like\n",
    "        Full Width at Half Maximum of the MgII line in km/s.\n",
    "    wave_L_3000_err : float or array-like, optional\n",
    "        Standard deviation of the continuum luminosity in erg/s.\n",
    "    FWHM_err : float or array-like, optional\n",
    "        Standard deviation of the FWHM in km/s.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    M_bh_per_solar : float or array-like\n",
    "        Black hole mass in units of solar masses.\n",
    "    M_bh_per_solar_err : float or array-like or None\n",
    "        Standard deviation of the black hole mass in solar masses.\n",
    "        Returns None if both input errors are None.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The error propagation uses the standard formula for error propagation:\n",
    "    For a function f(x,y) = A * x^a * y^b, the relative error is:\n",
    "    σ_f/f = sqrt((a*σ_x/x)^2 + (b*σ_y/y)^2)\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    Based on the calibration from McLure & Dunlop (2004) and Vestergaard & Peterson (2006).\n",
    "    \"\"\"\n",
    "    # Convert input to numpy arrays if they aren't already\n",
    "    wave_L_3000 = np.asarray(wave_L_3000)\n",
    "    FWHM = np.asarray(FWHM)\n",
    "    \n",
    "    # Process input errors\n",
    "    if wave_L_3000_err is not None:\n",
    "        wave_L_3000_err = np.asarray(wave_L_3000_err)\n",
    "    if FWHM_err is not None:\n",
    "        FWHM_err = np.asarray(FWHM_err)\n",
    "    \n",
    "    # Compute black hole mass\n",
    "    xx = lam * wave_L_3000  # erg/s\n",
    "    xxx = xx / (10**7)  # watts (conversion from erg/s to watts)\n",
    "    \n",
    "    # Exponents in the formula\n",
    "    power_lum = 0.47\n",
    "    power_fwhm = 2.0\n",
    "    \n",
    "    # Calculate black hole mass\n",
    "    M_bh_per_solar = 3.37 * ((xxx / 10**37)**power_lum) * (FWHM**power_fwhm)\n",
    "    \n",
    "    # If no errors are provided, return only the mass\n",
    "    if wave_L_3000_err is None and FWHM_err is None:\n",
    "        return M_bh_per_solar, None\n",
    "    \n",
    "    # Error propagation\n",
    "    # Initialize error array with zeros\n",
    "    M_bh_per_solar_err = np.zeros_like(M_bh_per_solar, dtype=float)\n",
    "    \n",
    "    # For elements where both errors are provided\n",
    "    mask_both = np.logical_and(\n",
    "        np.logical_and(wave_L_3000_err is not None, FWHM_err is not None),\n",
    "        np.logical_and(wave_L_3000_err > 0, FWHM_err > 0)\n",
    "    )\n",
    "    \n",
    "    # For elements where only luminosity error is provided\n",
    "    mask_lum_only = np.logical_and(\n",
    "        np.logical_and(wave_L_3000_err is not None, FWHM_err is None),\n",
    "        wave_L_3000_err > 0\n",
    "    )\n",
    "    \n",
    "    # For elements where only FWHM error is provided\n",
    "    mask_fwhm_only = np.logical_and(\n",
    "        np.logical_and(wave_L_3000_err is None, FWHM_err is not None),\n",
    "        FWHM_err > 0\n",
    "    )\n",
    "    \n",
    "    # Calculate relative errors for each component\n",
    "    if np.any(mask_both) or np.any(mask_lum_only):\n",
    "        # Relative error contribution from luminosity\n",
    "        rel_err_lum = power_lum * (wave_L_3000_err / wave_L_3000)\n",
    "    \n",
    "    if np.any(mask_both) or np.any(mask_fwhm_only):\n",
    "        # Relative error contribution from FWHM\n",
    "        rel_err_fwhm = power_fwhm * (FWHM_err / FWHM)\n",
    "    \n",
    "    # Calculate total relative error and convert to absolute error\n",
    "    if np.any(mask_both):\n",
    "        rel_err_total = np.sqrt(rel_err_lum**2 + rel_err_fwhm**2)\n",
    "        M_bh_per_solar_err = M_bh_per_solar * rel_err_total\n",
    "    elif np.any(mask_lum_only):\n",
    "        M_bh_per_solar_err = M_bh_per_solar * rel_err_lum\n",
    "    elif np.any(mask_fwhm_only):\n",
    "        M_bh_per_solar_err = M_bh_per_solar * rel_err_fwhm\n",
    "    \n",
    "    return M_bh_per_solar, M_bh_per_solar_err\n",
    "\n",
    "\n",
    "def DM_func(z, omega_m=0.3, omega_lambda=0.7):\n",
    "    \"\"\"\n",
    "    Function for the proper motion distance integration.\n",
    "\n",
    "    Paper\n",
    "    -----\n",
    "    https://arxiv.org/pdf/astro-ph/9905116\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : float\n",
    "        Redshift\n",
    "    omega_m : float, optional\n",
    "        Matter density parameter, default is 0.3\n",
    "    omega_lambda : float, optional\n",
    "        Dark energy density parameter, default is 0.7\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The integrand for the proper motion distance calculation\n",
    "    \"\"\"\n",
    "    return 1.0 / np.sqrt(omega_m * (1 + z)**3 + omega_lambda)\n",
    "\n",
    "def DM_single(z, omega_m=0.3, omega_lambda=0.7):\n",
    "    \"\"\"\n",
    "    Calculate proper motion distance for a single redshift value.\n",
    "\n",
    "    Paper\n",
    "    -----\n",
    "    https://arxiv.org/pdf/astro-ph/9905116\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : float\n",
    "        Redshift\n",
    "    omega_m : float, optional\n",
    "        Matter density parameter, default is 0.3\n",
    "    omega_lambda : float, optional\n",
    "        Dark energy density parameter, default is 0.7\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Proper motion distance in Mpc\n",
    "    float\n",
    "        Integration error (not statistical error)\n",
    "    \"\"\"\n",
    "    result, error = quad(lambda x: DM_func(x, omega_m, omega_lambda), 0, z)\n",
    "    return (c/H_0) * result, (c/H_0) * error\n",
    "\n",
    "def DM_Multiple(z_array, omega_m=0.3, omega_lambda=0.7, omega_m_err=0.01, omega_lambda_err=0.01, \n",
    "                h0_err=1.0, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Calculate proper motion distance with full error propagation for multiple redshifts.\n",
    "\n",
    "    Paper\n",
    "    -----\n",
    "    https://arxiv.org/pdf/astro-ph/9905116\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z_array : array-like\n",
    "        Array of redshift values\n",
    "    omega_m : float, optional\n",
    "        Matter density parameter, default is 0.3\n",
    "    omega_lambda : float, optional\n",
    "        Dark energy density parameter, default is 0.7\n",
    "    omega_m_err : float, optional\n",
    "        Uncertainty in omega_m, default is 0.01\n",
    "    omega_lambda_err : float, optional\n",
    "        Uncertainty in omega_lambda, default is 0.01\n",
    "    h0_err : float, optional\n",
    "        Uncertainty in H0, default is 1.0 km/s/Mpc\n",
    "    n_samples : int, optional\n",
    "        Number of Monte Carlo samples for error propagation, default is 1000\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        Array of proper motion distances in Mpc\n",
    "    array-like\n",
    "        Array of standard deviations of proper motion distances in Mpc\n",
    "    \"\"\"\n",
    "    DM_array = []\n",
    "    DM_SD_array = []\n",
    "    \n",
    "    # Base calculation without error propagation\n",
    "    for z in z_array:\n",
    "        dm, _ = DM_single(z, omega_m, omega_lambda)\n",
    "        DM_array.append(dm)\n",
    "    \n",
    "    # Monte Carlo error propagation\n",
    "    for i, z in enumerate(z_array):\n",
    "        # Generate random samples for cosmological parameters\n",
    "        om_samples = np.random.normal(omega_m, omega_m_err, n_samples)\n",
    "        ol_samples = np.random.normal(omega_lambda, omega_lambda_err, n_samples)\n",
    "        h0_samples = np.random.normal(H_0, h0_err, n_samples)\n",
    "        \n",
    "        # Calculate DM for each sample\n",
    "        dm_samples = []\n",
    "        for j in range(n_samples):\n",
    "            # Make sure physical constraints are satisfied\n",
    "            if om_samples[j] < 0:\n",
    "                om_samples[j] = 0\n",
    "            if ol_samples[j] < 0:\n",
    "                ol_samples[j] = 0\n",
    "                \n",
    "            result, _ = quad(lambda x: DM_func(x, om_samples[j], ol_samples[j]), 0, z)\n",
    "            dm = (c/h0_samples[j]) * result\n",
    "            dm_samples.append(dm)\n",
    "        \n",
    "        # Calculate standard deviation\n",
    "        DM_SD_array.append(np.std(dm_samples))\n",
    "    \n",
    "    return np.array(DM_array), np.array(DM_SD_array)\n",
    "    \n",
    "def DL(DM, DM_SD, z):\n",
    "    \"\"\"\n",
    "    This is getting the Luminosity distances for the redshifts in each of the bins given the proper motion distance and redshift.\n",
    "    \n",
    "    Paper\n",
    "    -----\n",
    "    https://arxiv.org/pdf/astro-ph/9905116\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DM: This is the proper motion distance. Calulated by the DM_Multiple definition.\n",
    "    DM SD: The standard deviation of the proper motion distances.\n",
    "    Z: The individual redshifts in each given redshift bins.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DL_Array: The Luminosity distance array for each redshift value in each of the redshift bins.\n",
    "    DL_SD_Array: The Standard deviation of the Luminosity distance for each of the redshift values in each of the given redshift bins.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays if they aren't already\n",
    "    DM = np.array(DM)\n",
    "    DM_SD = np.array(DM_SD)\n",
    "    z = np.array(z)\n",
    "    \n",
    "    # Check that all arrays have the same length\n",
    "    if not (len(DM) == len(DM_SD) == len(z)):\n",
    "        raise ValueError(\"Input arrays DM, DM_SD, and z must have the same length\")\n",
    "    \n",
    "    # Calculate luminosity distance and its standard deviation\n",
    "    DL_Array = (1 + z) * DM\n",
    "    DL_SD_Array = (1 + z) * DM_SD\n",
    "                                 \n",
    "    return DL_Array, DL_SD_Array\n",
    "\n",
    "def getting_the_L_3000_Index(wave):\n",
    "    \"\"\"\n",
    "    This is getting the wave index for the continuum luminosity at 3000 angstroms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Wave : The rest wavelength array for each of the galaxies in each of the redshift bins.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    L_3000_Range_Index_Array : The index array for the continuum luminosity at 3000 angstroms.\n",
    "    \"\"\"\n",
    "    \n",
    "    L_3000_Range_Index_Array = []\n",
    "    \n",
    "    for i in wave:\n",
    "        L_3000_Range_Index_Array.append(np.where(np.logical_and(i > 2950, i < 3050))[0])\n",
    "        \n",
    "    return L_3000_Range_Index_Array\n",
    "\n",
    "def getting_the_L_2000_Index(wave):\n",
    "    \"\"\"\n",
    "    Identifies AGN spectra that contain wavelengths in the 2590-2690 Angstrom range and returns their indices.\n",
    "    \n",
    "    This function is used to find AGN spectra that have continuum measurements near 2000 Angstroms.\n",
    "    Due to redshift limitations, some AGN spectra don't extend to 3000 Angstroms in rest wavelength.\n",
    "    These indices will be used to establish a relationship between continuum luminosities at 2000 and 3000 \n",
    "    Angstroms, which helps estimate the 3000 Angstrom continuum luminosity for AGN with limited spectral coverage.\n",
    "    \n",
    "    Note: Despite the function name referencing 2000 Angstroms, it actually looks for wavelengths \n",
    "    in the 2590-2690 Angstrom range, which is used as a proxy for the 2000 Angstrom continuum.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wave : list of arrays\n",
    "        A list where each element is a wavelength array (in Angstroms) for an individual AGN spectrum.\n",
    "        The index of this list corresponds to the AGN index in the dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    L_2000_Range_Index_Array : list of arrays\n",
    "        A list of numpy arrays, where each array contains the indices within an individual spectrum's \n",
    "        wavelength array that fall within the 2590-2690 Angstrom range. Each element in this list \n",
    "        corresponds to an AGN that has wavelengths in the desired range.\n",
    "        \n",
    "    L_2000_Wave_Index_Array : list\n",
    "        A list of indices that indicate which AGN in the original dataset have spectra \n",
    "        containing wavelengths in the 2590-2690 Angstrom range. These indices can be used\n",
    "        to select the corresponding AGN from the original dataset.\n",
    "    \"\"\"\n",
    "    L_2000_Range_Index_Array = []  # Stores wavelength indices within each spectrum\n",
    "    L_2000_Wave_Index_Array = []   # Stores AGN indices that have the desired wavelength range\n",
    "    a = -1  # Counter to track the current AGN index\n",
    "    \n",
    "    for i in wave:\n",
    "        a = a + 1  # Increment AGN index counter\n",
    "        \n",
    "        # Find indices where wavelength is between 2590-2690 Angstroms\n",
    "        jj = np.where(np.logical_and(i > 2590, i < 2690))[0]\n",
    "        \n",
    "        # Skip AGN that don't have wavelengths in the desired range\n",
    "        if len(jj) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # Store the wavelength indices for this AGN\n",
    "            L_2000_Range_Index_Array.append(np.where(np.logical_and(i > 2590, i < 2690))[0])\n",
    "            \n",
    "            # Store the index of this AGN\n",
    "            L_2000_Wave_Index_Array.append(a)\n",
    "        \n",
    "    return L_2000_Range_Index_Array, L_2000_Wave_Index_Array\n",
    "\n",
    "\n",
    "\n",
    "def getting_the_L_3000_wave(wave, index):\n",
    "    \"\"\"\n",
    "    This takes the rest wavelengths and the luminosity 3000 angstroms index to find the wavelength values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    waves : rest wavelengths.\n",
    "    index : the index values from the getting_the_L_3000_Index definition. (Which AGN have wavelengths in the 3000 angstrom range)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    L_3000_Waves_Array : The rest wavelengths that correspond to the wave index.\n",
    "    \"\"\"\n",
    "    \n",
    "    L_3000_Wave_Array = [] \n",
    "    \n",
    "    for i in np.arange(len(index)):\n",
    "        L_3000_Wave_Array.append(wave[i][index[i]])\n",
    "        \n",
    "    return L_3000_Wave_Array\n",
    "\n",
    "\n",
    "def getting_the_L_3000_flux(flux, flux_sd, index):\n",
    "    \"\"\"\n",
    "    This takes the flux values from the data in each of the redshift bins and the index of the rest wavelengths for the getting_the_L_3000_Index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flux : The flux of each of the AGN in each of the redshift bins.\n",
    "    index : The index for the getting_the_L_3000_Index. (Which AGN have wavelengths in the 3000 angstrom range)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    L_3000_Flux_Array : The flux at the indexes for the luminosity at 3000 angstroms.\n",
    "    \"\"\"\n",
    "    \n",
    "    L_3000_Flux_Array = []\n",
    "    L_3000_Flux_SD_Array = []\n",
    "    \n",
    "    for i in np.arange(len(flux)):\n",
    "        L_3000_Flux_Array.append(flux[i][index[i]])\n",
    "        L_3000_Flux_SD_Array.append(flux_sd[i][index[i]])\n",
    "        \n",
    "    return L_3000_Flux_Array, L_3000_Flux_SD_Array\n",
    "\n",
    "\n",
    "def getting_the_L_2000_waves(waves, index):\n",
    "    \"\"\"\n",
    "    This takes the rest wavelengths and the luminosity 2000 angstroms index to find the wavelength values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    waves : rest wavelengths.\n",
    "    index : the index values from the getting_the_L_2000_Index definition. (Which AGN have wavelengths in the 2000 angstrom range)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    L_2000_Waves_Array : The rest wavelengths that correspond to the wave index.\n",
    "    \"\"\"\n",
    "    L_2000_Waves_Array = []\n",
    "    \n",
    "    for i in range(len(index)):\n",
    "        #print(i)\n",
    "        L_2000_Waves_Array.append(waves[i][index[i]])\n",
    "\n",
    "    return L_2000_Waves_Array\n",
    "\n",
    "def getting_the_L_2000_flux(flux, flux_sd, index):\n",
    "    \"\"\"\n",
    "    This takes the flux values from the data in each of the redshift bins and the index of the rest wavelengths for the getting_the_L_2000_Index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flux : The flux of each of the AGN in each of the redshift bins.\n",
    "    index : The index for the getting_the_L_2000_Index. (Which AGN have wavelengths in the 2000 angstrom range)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    L_2000_Flux_Array : The flux at the indexes for the luminosity at 2000 angstroms.\n",
    "    \"\"\"\n",
    "    L_2000_Flux_Array = []\n",
    "    L_2000_Flux_SD_Array = []\n",
    "    \n",
    "    for i in range(len(index)):\n",
    "        L_2000_Flux_Array.append(flux[i][index[i]])\n",
    "        L_2000_Flux_SD_Array.append(flux_sd[i][index[i]])\n",
    "        \n",
    "    return L_2000_Flux_Array, L_2000_Flux_SD_Array\n",
    "\n",
    "\n",
    "#def getting_the_continuum_fit_and_res(l_3000_flux_array, l_3000_wave_array):\n",
    "#    \n",
    "#    Y_Continuum_Fitted_Array = []\n",
    "#    Res_Array = []\n",
    "#\n",
    "#    for i in np.arange(len(l_3000_flux_array)):\n",
    "#\n",
    "#        spectrum = Spectrum1D(flux=l_3000_flux_array[i]*u.erg/u.angstrom/u.second/u.cm**2, spectral_axis=l_3000_wave_array[i]*u.angstrom)\n",
    "#        \n",
    "#        with warnings.catch_warnings():  # Ignore warnings\n",
    "#            warnings.simplefilter('ignore')\n",
    "#            g1_fit = fit_generic_continuum(spectrum, model = models.Chebyshev1D(4))\n",
    "#            \n",
    "#        y_continuum_fitted = g1_fit(l_3000_wave_array[i]*u.angstrom)\n",
    "#            \n",
    "#        res = get_residuals(l_3000_flux_array[i], y_continuum_fitted*u.angstrom*u.s*u.cm**2/u.erg)\n",
    "#        \n",
    "#        Y_Continuum_Fitted_Array.append(y_continuum_fitted)\n",
    "#        Res_Array.append(res)\n",
    "#        \n",
    "#    return [Y_Continuum_Fitted_Array, Res_Array]\n",
    "\n",
    "\n",
    "def getting_the_bin_sizes(wave):\n",
    "    \"\"\"\n",
    "    Calculate the wavelength bin sizes (step sizes) for spectral data arrays.\n",
    "    \n",
    "    This function determines the wavelength step size between adjacent points in each\n",
    "    wavelength array. It assumes that the wavelength spacing is uniform within each array, \n",
    "    so it only calculates the difference between the second and third elements of each array\n",
    "    (indices 2 and 1) to represent the bin size. This bin size information is used for \n",
    "    proper flux integration when calculating continuum luminosities at 3000 or 2000 Angstroms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wave : list of arrays\n",
    "        A list of wavelength arrays, where each array contains the wavelength values\n",
    "        for a specific spectrum in either the 3000 or 2000 Angstrom continuum region.\n",
    "        Each element in the list corresponds to a different AGN spectrum.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Bin_Size_Array : list\n",
    "        A list containing the wavelength bin sizes (in Angstroms) for each spectrum.\n",
    "        Each element corresponds to the bin size of the wavelength array at the same\n",
    "        index in the input 'wave' list.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - The function assumes uniform wavelength spacing within each array.\n",
    "    - It uses the difference between the third and second elements (indices 2 and 1)\n",
    "      as a representative bin size for the entire array.\n",
    "    - These bin sizes are important for proper numerical integration of flux densities\n",
    "      to calculate luminosities.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> wavelengths = [\n",
    "    ...     np.array([2990, 2995, 3000, 3005, 3010]),\n",
    "    ...     np.array([2980, 2990, 3000, 3010, 3020])\n",
    "    ... ]\n",
    "    >>> getting_the_bin_sizes(wavelengths)\n",
    "    [5.0, 10.0]\n",
    "    \"\"\"\n",
    "    Bin_Size_Array = []\n",
    "    \n",
    "    for i in wave:\n",
    "        # Calculate the step size (bin size) by taking the difference between\n",
    "        # adjacent wavelength points. Using indices 2 and 1 assumes uniform spacing.\n",
    "        bin_size = i[2] - i[1]\n",
    "        Bin_Size_Array.append(bin_size)\n",
    "        \n",
    "    return Bin_Size_Array\n",
    "    \n",
    "#def getting_the_biweight_flux(y_continuum_fit, y_continuum_std, bin_size):\n",
    "#    \"\"\"\n",
    "#    Calculate the biweight flux from continuum fit values, accounting for bin sizes.\n",
    "#    \n",
    "#    This function converts the continuum fit values (flux densities) to total flux\n",
    "#    by multiplying by the bin size and applying astropy units.\n",
    "#    \n",
    "#    Parameters\n",
    "#    ----------\n",
    "#    y_continuum_fit : list of arrays\n",
    "#        Continuum fit values (flux densities) for each spectrum at 3000 Angstroms.\n",
    "#        Each array contains the flux density values for a single spectrum.\n",
    "#    \n",
    "#    y_continuum_std : list of arrays\n",
    "#        Standard deviations of the continuum fit values.\n",
    "#        Each array contains the standard deviations for a single spectrum.\n",
    "#    \n",
    "#    bin_size : list of float\n",
    "#        Bin sizes (wavelength steps) for each spectrum in Angstroms.\n",
    "#    \n",
    "#    Returns\n",
    "#    -------\n",
    "#    BiWeight_Flux_Array : list\n",
    "#        List of arrays containing the biweighted flux values with astropy units.\n",
    "#    \n",
    "#    BiWeight_Flux_Std_Array : list\n",
    "#        List of arrays containing the standard deviations of the biweighted flux values.\n",
    "#    \"\"\"\n",
    "#    BiWeight_Flux_Array = []\n",
    "#    BiWeight_Flux_Std_Array = []\n",
    "#    \n",
    "#    for i in range(len(bin_size)):\n",
    "#        # Convert flux density to flux by multiplying by bin size\n",
    "#        # Note: y_continuum_fit is assumed to be in units of erg/s/cm^2/Angstrom\n",
    "#        # Multiplying by bin_size (Angstroms) gives flux in erg/s/cm^2\n",
    "#        flux = y_continuum_fit[i] * bin_size[i] * u.erg / (u.s * u.cm**2)\n",
    "#        \n",
    "#        # Propagate the uncertainty\n",
    "#        flux_std = y_continuum_std[i] * bin_size[i] * u.erg / (u.s * u.cm**2)\n",
    "#        \n",
    "#        BiWeight_Flux_Array.append(flux)\n",
    "#        BiWeight_Flux_Std_Array.append(flux_std)\n",
    "#        \n",
    "#    return BiWeight_Flux_Array, BiWeight_Flux_Std_Array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def getting_the_biweight_loc(biweight_flux, biweight_flux_std):\n",
    "#    \"\"\"\n",
    "#    Calculate the biweight location (robust mean) of flux values.\n",
    "#    \n",
    "#    Parameters\n",
    "#    ----------\n",
    "#    biweight_flux : list\n",
    "#        List of arrays containing flux values with astropy units.\n",
    "#    \n",
    "#    biweight_flux_std : list\n",
    "#        List of arrays containing standard deviations of flux values.\n",
    "#    \n",
    "#    Returns\n",
    "#    -------\n",
    "#    BiWeight_Location_Array : list\n",
    "#        List of biweight location values (robust means) for each spectrum.\n",
    "#    \n",
    "#    BiWeight_Location_Std_Array : list\n",
    "#        List of standard deviation estimates for the biweight location values.\n",
    "#    \"\"\"\n",
    "#    BiWeight_Location_Array = []\n",
    "#    BiWeight_Location_Std_Array = []\n",
    "#    \n",
    "#    for i in range(len(biweight_flux)):\n",
    "#        # Calculate biweight location (robust mean)\n",
    "#        loc = biweight_location(biweight_flux[i].value)\n",
    "#        \n",
    "#        # For the standard deviation, we use the median of the flux standard deviations\n",
    "#        # This is a simplified approach; a more rigorous approach would use bootstrap resampling\n",
    "#        loc_std = np.median(biweight_flux_std[i].value)\n",
    "#        \n",
    "#        # Add the units back\n",
    "#        loc = loc * biweight_flux[i].unit\n",
    "#        loc_std = loc_std * biweight_flux_std[i].unit\n",
    "#        \n",
    "#        BiWeight_Location_Array.append(loc)\n",
    "#        BiWeight_Location_Std_Array.append(loc_std)\n",
    "#                                       \n",
    "#    return BiWeight_Location_Array, BiWeight_Location_Std_Array\n",
    "\n",
    "#def L_3000_2000(biweight_loc, biweight_loc_std, dl, dl_std, z):\n",
    "#    \"\"\"\n",
    "#    Calculate the luminosity at 3000 Angstroms using biweight location, luminosity distance, and redshift.\n",
    "#    \n",
    "#    This function converts the observed flux to luminosity using the luminosity distance\n",
    "#    and corrects for redshift.\n",
    "#    \n",
    "#    Parameters\n",
    "#    ----------\n",
    "#    biweight_loc : list\n",
    "#        List of biweight location values (robust means of flux) for each spectrum.\n",
    "#    \n",
    "#    biweight_loc_std : list\n",
    "#        List of standard deviations for the biweight location values.\n",
    "#    \n",
    "#    dl : array-like\n",
    "#        Luminosity distances for each spectrum in cm.\n",
    "#    \n",
    "#    dl_std : array-like\n",
    "#        Standard deviations of the luminosity distances in cm.\n",
    "#    \n",
    "#    z : array-like\n",
    "#        Redshift values for each spectrum.\n",
    "#    \n",
    "#    Returns\n",
    "#    -------\n",
    "#    L_3000_Array : list\n",
    "#        List of luminosity values at 3000 Angstroms in units of erg/s.\n",
    "#    \n",
    "#    L_3000_Std_Array : list\n",
    "#        List of standard deviations of the luminosity values.\n",
    "#    \"\"\"\n",
    "#    L_3000_Array = []\n",
    "#    L_3000_Std_Array = []\n",
    "#    \n",
    "#    for i in range(len(z)):\n",
    "#        # Calculate luminosity: L = F * (1+z) * 4πD_L²\n",
    "#        # The (1+z) factor accounts for redshift\n",
    "#        # Note: biweight_loc should be in units of erg/s/cm²\n",
    "#        # Multiplying by 4πD_L² converts to erg/s\n",
    "#        l = biweight_loc[i] * (1 + z[i]) * (4 * np.pi * dl[i]**2)\n",
    "#        \n",
    "#        # Error propagation for luminosity\n",
    "#        # For a function f(x,y,z) = x*y*z, the relative error is:\n",
    "#        # σ_f/f = sqrt((σ_x/x)² + (σ_y/y)² + (σ_z/z)²)\n",
    "#        # Here we ignore the uncertainty in z as it's typically very small\n",
    "#        \n",
    "#        # Relative errors\n",
    "#        rel_err_flux = biweight_loc_std[i] / biweight_loc[i]\n",
    "#        rel_err_dl = 2 * dl_std[i] / dl[i]  # Factor of 2 because distance is squared\n",
    "#        \n",
    "#        # Overall relative error\n",
    "#        rel_err = np.sqrt(rel_err_flux**2 + rel_err_dl**2)\n",
    "#        \n",
    "#        # Absolute error\n",
    "#        l_std = l * rel_err\n",
    "#        \n",
    "#        L_3000_Array.append(l)\n",
    "#        L_3000_Std_Array.append(l_std)\n",
    "#    \n",
    "#    return L_3000_Array, L_3000_Std_Array\n",
    "\n",
    "\n",
    "#def subtracted_continuum(Continuum_wave, Continuum_spec):\n",
    "#    \n",
    "#    spectrum = Spectrum1D(flux=Continuum_spec*u.erg/u.angstrom/u.second/u.cm**2, spectral_axis=Continuum_wave*u.angstrom)\n",
    "#        \n",
    "#    with warnings.catch_warnings():  # Ignore warnings\n",
    "#        warnings.simplefilter('ignore')\n",
    "#        g1_fit = fit_generic_continuum(spectrum, model = models.Chebyshev1D(5))#, exclude_regions=SpectralRegion(2700 * u.um, 2900 * u.um))\n",
    "#            \n",
    "#    y_continuum_fitted = g1_fit(Continuum_wave*u.angstrom)\n",
    "#                \n",
    "#    res = get_residuals(Continuum_spec, y_continuum_fitted*u.angstrom*u.s*u.cm**2/u.erg)\n",
    "#    \n",
    "#    Subtracted_Continuum_Only = np.subtract(Continuum_spec, y_continuum_fitted*u.angstrom*u.s*u.cm**2/u.erg)\n",
    "#    \n",
    "#    return [Subtracted_Continuum_Only, y_continuum_fitted, res]\n",
    "\n",
    "\n",
    "#def subtracted_local_spec(y_Continuum_Fitted, Spec):\n",
    "#\n",
    "#    y_Continuum_Fitted = np.linspace(min(y_Continuum_Fitted), max(y_Continuum_Fitted), len(Spec))\n",
    "#    Subtracted_Local_Spec_Fit = np.divide(Spec, y_Continuum_Fitted*u.angstrom*u.s*u.cm**2/u.erg)\n",
    "#    \n",
    "#  \n",
    "#    return Subtracted_Local_Spec_Fit\n",
    "\n",
    "\n",
    "#def getting_the_centriod(data):\n",
    "#    x_init = 25\n",
    "#    y_init = 27\n",
    "#    \n",
    "#    x, y = centroid_sources(data.data, 25, 27, box_size=35, centroid_func=centroid_2dg)\n",
    "#    print(x,y)\n",
    "#       \n",
    "#    return x, y\n",
    "\n",
    "#def stack_image_cutouts(cutouts):\n",
    "#        \"\"\"\n",
    "#        given a set of cutouts (list of dictionaries)\n",
    "#        stack the filters and return a single FITS cutout image\n",
    "#\n",
    "#        Notice: in an exception case, there is no imaging and \"cutouts\" is actually a matplotlib figure\n",
    "#        for the empty data\n",
    "#\n",
    "#        :param cutouts:\n",
    "#        :return:\n",
    "#        \"\"\"\n",
    "#\n",
    "#        stacked_cutout = None\n",
    "#        if cutouts is not None and len(cutouts) > 0:\n",
    "#            try:\n",
    "#                total_adjusted_exptime = 1.0\n",
    "#                ref_exptime = 0.0\n",
    "#                for c in cutouts:\n",
    "#                    if c and isinstance(c,dict) and c['cutout']:\n",
    "#                        if stacked_cutout is None:\n",
    "#                            stacked_cutout = c['cutout']\n",
    "#                            try:\n",
    "#                                ref_exptime = c['details']['exptime']\n",
    "#                                if not ref_exptime:\n",
    "#                                    ref_exptime = 1.0\n",
    "#                            except:\n",
    "#                                ref_exptime = 1.0\n",
    "#                            total_adjusted_exptime = 1.0\n",
    "#                        else:\n",
    "#                            try:\n",
    "#                                #log.debug(f\"{np.shape(stacked_cutout.data)}, {np.shape(c['cutout'].data)}, {c['details']['exptime']}, {ref_exptime}\")\n",
    "#                                this_exptime = 1.0 if c['details']['exptime'] is None else c['details']['exptime']\n",
    "#                                stacked_cutout.data = np.add(stacked_cutout.data, c['cutout'].data * this_exptime / ref_exptime)\n",
    "#                                total_adjusted_exptime += c['details']['exptime'] / ref_exptime\n",
    "#                            except:\n",
    "#                                pass\n",
    "#                if stacked_cutout and total_adjusted_exptime:\n",
    "#                    stacked_cutout.data /= total_adjusted_exptime\n",
    "#            except Warning:\n",
    "#                print(\"Warning\")\n",
    "#        return stacked_cutout\n",
    "\n",
    "    \n",
    "#def getting_the_instrument(redshift_range_index):\n",
    "#    HCC_SSP_Array_025_035 = []\n",
    "#    HSC_SSP_ID_Array_025_035 = []\n",
    "#    HSC_Array_025_035 = []\n",
    "#    HSC_ID_Array_025_035 = []\n",
    "#    MegaPrime_Array_025_035 = []\n",
    "#    MegaPrime_ID_Array_025_035 = []\n",
    "#    \n",
    "#    for num  in np.arange(len(Data_Redshift_Confirmed_From_Images[redshift_range_index])):\n",
    "#        #print(num)\n",
    "#        coord = SkyCoord(Data_Redshift_Confirmed_From_Images[\"RA\"][redshift_range_index][num], Data_Redshift_Confirmed_From_Images[\"DEC\"][redshift_range_index][num], unit = 'deg')\n",
    "#        cutouts = catlib.get_cutouts(position=coord,radius=5.,aperture=1.5,dynamic=False,first=False,nudge=False,filter=None)\n",
    "#        \n",
    "#        for cutout in cutouts:\n",
    "#        \n",
    "#            if cutout[\"instrument\"] == \"HSC SSP\":\n",
    "#                HCC_SSP_Array_025_035.append(cutouts)\n",
    "#                HSC_SSP_ID_Array_025_035.append(Data_Redshift_Confirmed_From_Images[\"Detectid\"][redshift_range_index][num])\n",
    "#            if cutout[\"instrument\"] == \"HsC\":\n",
    "#                HSC_Array_025_035.append(cutouts)\n",
    "#                HSC_ID_Array_025_035.append(Data_Redshift_Confirmed_From_Images[\"Detectid\"][redshift_range_index][num])\n",
    "#            if cutout[\"instrument\"] == \"CFHTLS/MegaPrime\":\n",
    "#                MegaPrime_Array_025_035.append(cutouts)\n",
    "#                MegaPrime_ID_Array_025_035.append(Data_Redshift_Confirmed_From_Images[\"Detectid\"][redshift_range_index][num])\n",
    "#                \n",
    "#                \n",
    "#    return HCC_SSP_Array_025_035, HSC_SSP_ID_Array_025_035 , HSC_Array_025_035, HSC_ID_Array_025_035, MegaPrime_Array_025_035, MegaPrime_ID_Array_025_035\n",
    "\n",
    "#def fit_continuum_with_metrics_for_unstacked(wave_rest_list, spec_rest_list, spec_std_list=None, scaling_factor=1e-17):\n",
    "#    \"\"\"\n",
    "#    Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "#    Uses analytic covariance matrix for uncertainty estimation instead of bootstrapping.\n",
    "#    \n",
    "#    Parameters\n",
    "#    ----------\n",
    "#    wave_rest_list : list of arrays\n",
    "#        List of wavelength arrays for each spectrum\n",
    "#    spec_rest_list : list of arrays\n",
    "#        List of flux arrays for each spectrum\n",
    "#    spec_std_list : list of arrays, optional\n",
    "#        List of flux standard deviation arrays for each spectrum\n",
    "#    scaling_factor : float\n",
    "#        Scaling factor to apply to the flux values\n",
    "#    \n",
    "#    Returns\n",
    "#    -------\n",
    "#    dict\n",
    "#        Dictionary containing:\n",
    "#        - spectra: List of Spectrum1D objects\n",
    "#        - continua: List of fitted continuum arrays\n",
    "#        - residuals: List of residual arrays\n",
    "#        - fit_std: List of standard deviation arrays for each continuum fit\n",
    "#        - fit_metrics: List of dictionaries with fit quality metrics (r², χ², p-value)\n",
    "#    \"\"\"\n",
    "#    # Initialize output containers\n",
    "#    spectra = []\n",
    "#    fitted_continua = []\n",
    "#    residuals = []\n",
    "#    fit_std_dev = []\n",
    "#    fit_metrics = []\n",
    "#        \n",
    "#    # Handle the case where spec_std_list is None\n",
    "#    if spec_std_list is None:\n",
    "#        spec_std_list = [None] * len(wave_rest_list)\n",
    "#    \n",
    "#    for i, (wave_rest, spec_rest, spec_std) in enumerate(zip(wave_rest_list, spec_rest_list, spec_std_list)):\n",
    "#        # Create spectrum object\n",
    "#        spectrum = Spectrum1D(spec_rest * 1e16 * u.erg / u.angstrom / u.second / u.cm**2, \n",
    "#                             wave_rest * u.angstrom)\n",
    "#\n",
    "#        # Define model and fitter for analytic uncertainty\n",
    "#        model = models.Chebyshev1D(4)\n",
    "#        fitter = fitting.LevMarLSQFitter()\n",
    "#        exclude_regions = [SpectralRegion(2745*u.angstrom, 2885*u.angstrom)]\n",
    "#        \n",
    "#        # Create mask to exclude regions\n",
    "#        mask = ~((wave_rest >= 2745) & (wave_rest <= 2885))\n",
    "#        \n",
    "#        # Get weights from uncertainties if available\n",
    "#        if spec_std is not None and np.all(spec_std > 0):\n",
    "#            weights = 1.0 / (spec_std**2)\n",
    "#        else:\n",
    "#            weights = np.ones_like(spec_rest)\n",
    "#        \n",
    "#        # Fit continuum while suppressing warnings\n",
    "#        with warnings.catch_warnings():\n",
    "#            warnings.simplefilter('ignore')\n",
    "#            # First fit with specutils for compatibility with the original function\n",
    "#            continuum_fit = fit_generic_continuum(spectrum, model=model, exclude_regions=exclude_regions)\n",
    "#\n",
    "#            # Also fit directly with astropy fitter to get covariance matrix\n",
    "#            fitted_model = fitter(model, wave_rest[mask], spec_rest[mask], weights=weights[mask])\n",
    "#                \n",
    "#        # Evaluate the fitted continuum model\n",
    "#        wave_angstrom = wave_rest * u.angstrom\n",
    "#        y_continuum = continuum_fit(wave_angstrom)\n",
    "#        y_continuum_original_scale = y_continuum.value * 1e-16\n",
    "#\n",
    "#        # Calculate residuals: (spectrum - continuum) / continuum\n",
    "#        residual = (spec_rest - y_continuum_original_scale) / y_continuum_original_scale\n",
    "#\n",
    "#        # Calculate standard deviation for y_continuum_original_scale using the analytic covariance matrix approach\n",
    "#        param_cov = fitter.fit_info.get('param_cov')\n",
    "#        \n",
    "#        if param_cov is not None:\n",
    "#            # Create design matrix for Chebyshev polynomials\n",
    "#            n_params = len(fitted_model.parameters)\n",
    "#            design_matrix = np.zeros((len(wave_rest), n_params))\n",
    "#            \n",
    "#            # Normalize x-values to [-1, 1] for Chebyshev polynomials\n",
    "#            x_norm = 2 * (wave_rest - wave_rest.min()) / (wave_rest.max() - wave_rest.min()) - 1\n",
    "#            \n",
    "#            # Fill design matrix for each Chebyshev polynomial degree\n",
    "#            for j in range(n_params):\n",
    "#                # Create unit vector for this parameter\n",
    "#                params = np.zeros(n_params)\n",
    "#                params[j] = 1.0\n",
    "#                \n",
    "#                # Evaluate Chebyshev polynomial for this degree\n",
    "#                if j == 0:\n",
    "#                    design_matrix[:, j] = np.ones_like(x_norm)  # T_0(x) = 1\n",
    "#                elif j == 1:\n",
    "#                    design_matrix[:, j] = x_norm  # T_1(x) = x\n",
    "#                else:\n",
    "#                    # Recursive definition of Chebyshev polynomials\n",
    "#                    # T_n(x) = 2x*T_{n-1}(x) - T_{n-2}(x)\n",
    "#                    T_n_minus_2 = np.ones_like(x_norm)\n",
    "#                    T_n_minus_1 = x_norm\n",
    "#                    T_n = None\n",
    "#                    \n",
    "#                    for n in range(2, j + 1):\n",
    "#                        T_n = 2 * x_norm * T_n_minus_1 - T_n_minus_2\n",
    "#                        T_n_minus_2 = T_n_minus_1\n",
    "#                        T_n_minus_1 = T_n\n",
    "#                    \n",
    "#                    design_matrix[:, j] = T_n\n",
    "#            \n",
    "#            # Calculate uncertainty from covariance matrix: sqrt(sum_ij D_i * cov_ij * D_j)\n",
    "#            # This is equivalent to sqrt(D * cov * D^T) for each point\n",
    "#            # This is the standard deviation for y_continuum_original_scale\n",
    "#            y_continuum_std = np.sqrt(np.sum(\n",
    "#                (design_matrix @ param_cov) * design_matrix, \n",
    "#                axis=1\n",
    "#            )) * 1e-16  # Apply the same scaling as y_continuum_original_scale\n",
    "#        else:\n",
    "#            # Fallback if covariance matrix not available\n",
    "#            # Estimate uncertainty from residuals\n",
    "#            y_continuum_std = np.ones_like(y_continuum_original_scale) * np.std(residual) * np.abs(y_continuum_original_scale)\n",
    "#            \n",
    "#        # Calculate fit quality metrics\n",
    "#        # 1. R-squared (coefficient of determination)\n",
    "#        spec_mean = np.mean(spec_rest)\n",
    "#        ss_total = np.sum((spec_rest - spec_mean)**2)\n",
    "#        ss_residual = np.sum((spec_rest - y_continuum_original_scale)**2)\n",
    "#        r_squared = 1 - (ss_residual / ss_total)\n",
    "#            \n",
    "#        # 2. Chi-squared goodness of fit\n",
    "#        # Exclude regions used in fitting\n",
    "#        mask = (wave_rest < 2745) | (wave_rest > 2885)\n",
    "#        \n",
    "#        # Optimized weights calculation - same as before\n",
    "#        if spec_std is not None and np.all(spec_std > 0):\n",
    "#            weights = 1.0 / (spec_std**2)\n",
    "#        else:\n",
    "#            weights = np.ones_like(spec_rest)\n",
    "#            \n",
    "#        chi_squared = np.sum(weights[mask] * ((spec_rest[mask] - y_continuum_original_scale[mask])**2))\n",
    "#        \n",
    "#        # 3. Reduced chi-squared (chi-squared per degree of freedom)\n",
    "#        dof = np.sum(mask) - model.degree - 1  # degrees of freedom\n",
    "#        reduced_chi_squared = chi_squared / dof if dof > 0 else np.nan\n",
    "#        \n",
    "#        # 4. Kolmogorov-Smirnov test (normality of residuals)\n",
    "#        # Normalized residuals should follow a normal distribution for a good fit\n",
    "#        norm_std = np.std(residual)\n",
    "#        norm_residuals = residual / norm_std if norm_std > 0 else residual\n",
    "#        ks_statistic, p_value = stats.kstest(norm_residuals[mask], 'norm')\n",
    "#        \n",
    "#        # Store fit metrics\n",
    "#        metrics = {\n",
    "#            'r_squared': r_squared,\n",
    "#            'chi_squared': chi_squared,\n",
    "#            'reduced_chi_squared': reduced_chi_squared,\n",
    "#            'ks_statistic': ks_statistic,\n",
    "#            'p_value': p_value,\n",
    "#            'best_metric': 'r_squared' if r_squared > 0.9 else 'reduced_chi_squared'\n",
    "#        }\n",
    "#        \n",
    "#        # Store results\n",
    "#        spectra.append(spectrum)\n",
    "#        fitted_continua.append(y_continuum_original_scale)\n",
    "#        residuals.append(residual)\n",
    "#        fit_std_dev.append(y_continuum_std)  # Now storing the standard deviation of the continuum\n",
    "#        fit_metrics.append(metrics)\n",
    "#\n",
    "#    return spectra, fitted_continua, residuals, fit_std_dev, fit_metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def fit_continuum_with_metrics_for_unstacked(wave_rest_list, spec_rest_list, spec_std_list=None, scaling_factor=1e-17):\n",
    "#    \"\"\"\n",
    "#    Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "#    Uses bootstrap resampling for uncertainty estimation.\n",
    "#    \n",
    "#    Parameters\n",
    "#    ----------\n",
    "#    wave_rest_list : list of arrays\n",
    "#        List of wavelength arrays for each spectrum\n",
    "#    spec_rest_list : list of arrays\n",
    "#        List of flux arrays for each spectrum\n",
    "#    spec_std_list : list of arrays, optional\n",
    "#        List of flux standard deviation arrays for each spectrum\n",
    "#    scaling_factor : float\n",
    "#        Scaling factor to apply to the flux values\n",
    "#    \n",
    "#    Returns\n",
    "#    -------\n",
    "#    dict\n",
    "#        Dictionary containing:\n",
    "#        - spectra: List of Spectrum1D objects\n",
    "#        - continua: List of fitted continuum arrays\n",
    "#        - residuals: List of residual arrays\n",
    "#        - fit_std: List of standard deviation arrays for each continuum fit\n",
    "#        - fit_metrics: List of dictionaries with fit quality metrics (r², χ², p-value)\n",
    "#    \"\"\"\n",
    "#    \n",
    "#    # Initialize output containers\n",
    "#    spectra = []\n",
    "#    fitted_continua = []\n",
    "#    residuals = []\n",
    "#    fit_std_dev = []\n",
    "#    fit_metrics = []\n",
    "#    \n",
    "#    # Pre-define constants and model\n",
    "#    \n",
    "#    # Handle the case where spec_std_list is None\n",
    "#    if spec_std_list is None:\n",
    "#        spec_std_list = [None] * len(wave_rest_list)\n",
    "#    \n",
    "#    # Create a progress bar for spectrum processing\n",
    "#    spectrum_pbar = tqdm(total=len(wave_rest_list), desc=\"Processing spectra\", position=0)\n",
    "#    \n",
    "#    # Loop through each spectrum\n",
    "#    for i, (wave_rest, spec_rest, spec_std) in enumerate(zip(wave_rest_list, spec_rest_list, spec_std_list)):\n",
    "#        # Create spectrum object\n",
    "#        spectrum = Spectrum1D(spec_rest * 1e16 * u.erg / u.angstrom / u.second / u.cm**2, \n",
    "#                             wave_rest * u.angstrom)\n",
    "#\n",
    "#        # Define model and fitter \n",
    "#        model = models.Chebyshev1D(4)\n",
    "#        fitter = fitting.LevMarLSQFitter()\n",
    "#        exclude_regions = [SpectralRegion(2745*u.angstrom, 2885*u.angstrom)]\n",
    "#        \n",
    "#        # Create mask to exclude regions\n",
    "#        mask = ~((wave_rest >= 2745) & (wave_rest <= 2885))\n",
    "#        \n",
    "#        # Get weights from uncertainties if available\n",
    "#        if spec_std is not None and np.all(spec_std > 0):\n",
    "#            weights = 1.0 / (spec_std**2)\n",
    "#        else:\n",
    "#            weights = np.ones_like(spec_rest)\n",
    "#        \n",
    "#        # Fit continuum while suppressing warnings\n",
    "#        with warnings.catch_warnings():\n",
    "#            warnings.simplefilter('ignore')\n",
    "#            # First fit with specutils for compatibility with the original function\n",
    "#            continuum_fit = fit_generic_continuum(spectrum, model=model, exclude_regions=exclude_regions)\n",
    "#                \n",
    "#        # Evaluate the fitted continuum model\n",
    "#        wave_angstrom = wave_rest * u.angstrom\n",
    "#        y_continuum = continuum_fit(wave_angstrom)\n",
    "#        y_continuum_original_scale = y_continuum.value * 1e-16\n",
    "#\n",
    "#        # Calculate residuals: (spectrum - continuum) / continuum\n",
    "#        residual = (spec_rest - y_continuum_original_scale) / y_continuum_original_scale\n",
    "#\n",
    "#        # Calculate standard deviation using bootstrap resampling\n",
    "#        n_bootstrap = 500\n",
    "#        bootstrap_results = np.zeros((n_bootstrap, len(wave_rest)))\n",
    "#        \n",
    "#        # Create a progress bar for bootstrap resampling that updates in place\n",
    "#        bootstrap_pbar = tqdm(total=n_bootstrap, \n",
    "#                            desc=f\"Bootstrap for spectrum {i+1}/{len(wave_rest_list)}\", \n",
    "#                            position=1,\n",
    "#                            leave=False)\n",
    "#        \n",
    "#        for b in range(n_bootstrap):\n",
    "#                \n",
    "#            # Create bootstrap sample (resample with replacement)\n",
    "#            indices = np.random.choice(len(wave_rest), size=len(wave_rest), replace=True)\n",
    "#            # Sort indices to ensure monotonicity\n",
    "#            boot_indices = np.sort(indices)\n",
    "#            \n",
    "#            wave_boot = wave_rest[boot_indices]\n",
    "#            spec_boot = spec_rest[boot_indices]\n",
    "#            \n",
    "#            # Get weights for this bootstrap sample\n",
    "#            if spec_std is not None and np.all(spec_std > 0):\n",
    "#                boot_weights = 1.0 / (spec_std[boot_indices]**2)\n",
    "#            else:\n",
    "#                boot_weights = np.ones_like(spec_boot)\n",
    "#            \n",
    "#            # Create spectrum for bootstrap sample\n",
    "#            boot_spectrum = Spectrum1D(flux=spec_boot * 1e16 * u.erg / u.angstrom / u.second / u.cm**2, \n",
    "#                                      spectral_axis=wave_boot * u.angstrom)\n",
    "#            \n",
    "#            # Create mask for this bootstrap sample\n",
    "#            boot_mask = ~((wave_boot >= 2745) & (wave_boot <= 2885))\n",
    "#            \n",
    "#            # Fit continuum to bootstrap sample\n",
    "#            with warnings.catch_warnings():\n",
    "#                warnings.simplefilter('ignore')\n",
    "#                boot_fit = fit_generic_continuum(\n",
    "#                    boot_spectrum, \n",
    "#                    model=models.Chebyshev1D(4),\n",
    "#                    exclude_regions=[SpectralRegion(2745*u.angstrom, 2885*u.angstrom)]\n",
    "#                )\n",
    "#                \n",
    "#            # Evaluate on original wavelength grid and store\n",
    "#            boot_continuum = boot_fit(wave_rest * u.angstrom)\n",
    "#            bootstrap_results[b] = boot_continuum.value * 1e-16\n",
    "#            \n",
    "#            # Update the bootstrap progress bar\n",
    "#            bootstrap_pbar.update(1)\n",
    "#        \n",
    "#        # Close the bootstrap progress bar\n",
    "#        bootstrap_pbar.close()\n",
    "#        \n",
    "#        # Calculate standard deviation across bootstrap samples\n",
    "#        # Scale up by a factor to make the standard deviation more visible\n",
    "#        y_continuum_std = np.std(bootstrap_results, axis=0) * 5.0\n",
    "#        \n",
    "#        # Calculate fit quality metrics\n",
    "#        # 1. R-squared (coefficient of determination)\n",
    "#        spec_mean = np.mean(spec_rest)\n",
    "#        ss_total = np.sum((spec_rest - spec_mean)**2)\n",
    "#        ss_residual = np.sum((spec_rest - y_continuum_original_scale)**2)\n",
    "#        r_squared = 1 - (ss_residual / ss_total)\n",
    "#            \n",
    "#        # 2. Chi-squared goodness of fit\n",
    "#        # Exclude regions used in fitting\n",
    "#        mask = (wave_rest < 2745) | (wave_rest > 2885)\n",
    "#        \n",
    "#        # Optimized weights calculation - same as before\n",
    "#        if spec_std is not None and np.all(spec_std > 0):\n",
    "#            weights = 1.0 / (spec_std**2)\n",
    "#        else:\n",
    "#            weights = np.ones_like(spec_rest)\n",
    "#            \n",
    "#        chi_squared = np.sum(weights[mask] * ((spec_rest[mask] - y_continuum_original_scale[mask])**2))\n",
    "#        \n",
    "#        # 3. Reduced chi-squared (chi-squared per degree of freedom)\n",
    "#        dof = np.sum(mask) - model.degree - 1  # degrees of freedom\n",
    "#        reduced_chi_squared = chi_squared / dof if dof > 0 else np.nan\n",
    "#        \n",
    "#        # 4. Kolmogorov-Smirnov test (normality of residuals)\n",
    "#        # Normalized residuals should follow a normal distribution for a good fit\n",
    "#        norm_std = np.std(residual)\n",
    "#        norm_residuals = residual / norm_std if norm_std > 0 else residual\n",
    "#        ks_statistic, p_value = stats.kstest(norm_residuals[mask], 'norm')\n",
    "#        \n",
    "#        # Store fit metrics\n",
    "#        metrics = {\n",
    "#            'r_squared': r_squared,\n",
    "#            'chi_squared': chi_squared,\n",
    "#            'reduced_chi_squared': reduced_chi_squared,\n",
    "#            'ks_statistic': ks_statistic,\n",
    "#            'p_value': p_value,\n",
    "#            'best_metric': 'r_squared' if r_squared > 0.9 else 'reduced_chi_squared'\n",
    "#        }\n",
    "#        \n",
    "#        # Store results\n",
    "#        spectra.append(spectrum)\n",
    "#        fitted_continua.append(y_continuum_original_scale)\n",
    "#        residuals.append(residual)\n",
    "#        fit_std_dev.append(y_continuum_std)  # Now storing the standard deviation of the continuum\n",
    "#        fit_metrics.append(metrics)\n",
    "#        \n",
    "#        # Update the spectrum progress bar\n",
    "#        spectrum_pbar.update(1)\n",
    "#    \n",
    "#    # Close the spectrum progress bar\n",
    "#    spectrum_pbar.close()\n",
    "#\n",
    "#    return spectra, fitted_continua, residuals, fit_std_dev, fit_metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _bootstrap_fit(wave_rest, spec_rest, spec_std, model, exclude_region, n_bootstrap):\n",
    "    \"\"\"\n",
    "    Perform bootstrap fits in parallel for a single spectrum.\n",
    "    \"\"\"\n",
    "    bootstrap_results = np.zeros((n_bootstrap, len(wave_rest)))\n",
    "\n",
    "    def single_bootstrap(_):\n",
    "        indices = np.random.choice(len(wave_rest), size=len(wave_rest), replace=True)\n",
    "        boot_indices = np.sort(indices)\n",
    "        wave_boot = wave_rest[boot_indices]\n",
    "        spec_boot = spec_rest[boot_indices]\n",
    "        spec_std_boot = spec_std[boot_indices] if spec_std is not None else None\n",
    "\n",
    "        boot_spectrum = Spectrum1D(flux=spec_boot * 1e16 * u.erg / u.angstrom / u.second / u.cm**2,\n",
    "                                   spectral_axis=wave_boot * u.angstrom)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            boot_fit = fit_generic_continuum(boot_spectrum, model=model, exclude_regions=[exclude_region])\n",
    "        return boot_fit(wave_rest * u.angstrom).value * 1e-16\n",
    "\n",
    "    # Parallel bootstrap execution\n",
    "    results = Parallel(n_jobs=-2, backend='loky')( #N_jobs=-2 means to use all of the cpu cores except for one. This keeps the machine functional.\n",
    "        delayed(single_bootstrap)(i) for i in range(n_bootstrap) \n",
    "    )\n",
    "\n",
    "    return np.vstack(results)\n",
    "\n",
    "\n",
    "def fit_continuum_with_metrics_for_unstacked(wave_rest_list, spec_rest_list, spec_std_list=None, scaling_factor=1e-17, n_bootstrap=500):\n",
    "\n",
    "    spectra = []\n",
    "    fitted_continua = []\n",
    "    residuals = []\n",
    "    fit_std_dev = []\n",
    "    fit_metrics = []\n",
    "\n",
    "    if spec_std_list is None:\n",
    "        spec_std_list = [None] * len(wave_rest_list)\n",
    "\n",
    "    continuum_model = models.Chebyshev1D(4)\n",
    "    fitter = fitting.LevMarLSQFitter()\n",
    "    exclude_region = SpectralRegion(2745 * u.angstrom, 2885 * u.angstrom)\n",
    "\n",
    "    for i, (wave_rest, spec_rest, spec_std) in enumerate(tqdm(zip(wave_rest_list, spec_rest_list, spec_std_list),\n",
    "                                                               total=len(wave_rest_list),\n",
    "                                                               desc=\"Fitting spectra\")):\n",
    "\n",
    "        spectrum = Spectrum1D(spec_rest * 1e16 * u.erg / u.angstrom / u.second / u.cm**2,\n",
    "                              wave_rest * u.angstrom)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            continuum_fit = fit_generic_continuum(spectrum, model=continuum_model,\n",
    "                                                  exclude_regions=[exclude_region])\n",
    "\n",
    "        wave_angstrom = wave_rest * u.angstrom\n",
    "        y_continuum = continuum_fit(wave_angstrom)\n",
    "        y_continuum_original_scale = y_continuum.value * 1e-16\n",
    "\n",
    "        residual = (spec_rest - y_continuum_original_scale) / y_continuum_original_scale\n",
    "\n",
    "        # Parallel bootstrap computation\n",
    "        bootstrap_results = _bootstrap_fit(wave_rest, spec_rest, spec_std, continuum_model,\n",
    "                                           exclude_region, n_bootstrap)\n",
    "\n",
    "        y_continuum_std = np.std(bootstrap_results, axis=0) * 5.0\n",
    "\n",
    "        spec_mean = np.mean(spec_rest)\n",
    "        ss_total = np.sum((spec_rest - spec_mean) ** 2)\n",
    "        ss_residual = np.sum((spec_rest - y_continuum_original_scale) ** 2)\n",
    "        r_squared = 1 - (ss_residual / ss_total)\n",
    "\n",
    "        mask = (wave_rest < 2745) | (wave_rest > 2885)\n",
    "        weights = 1.0 / (spec_std ** 2) if spec_std is not None and np.all(spec_std > 0) else np.ones_like(spec_rest)\n",
    "        chi_squared = np.sum(weights[mask] * ((spec_rest[mask] - y_continuum_original_scale[mask]) ** 2))\n",
    "\n",
    "        dof = np.sum(mask) - continuum_model.degree - 1\n",
    "        reduced_chi_squared = chi_squared / dof if dof > 0 else np.nan\n",
    "\n",
    "        norm_std = np.std(residual)\n",
    "        norm_residuals = residual / norm_std if norm_std > 0 else residual\n",
    "        ks_statistic, p_value = stats.kstest(norm_residuals[mask], 'norm')\n",
    "\n",
    "        metrics = {\n",
    "            'r_squared': r_squared,\n",
    "            'chi_squared': chi_squared,\n",
    "            'reduced_chi_squared': reduced_chi_squared,\n",
    "            'ks_statistic': ks_statistic,\n",
    "            'p_value': p_value,\n",
    "            'best_metric': 'r_squared' if r_squared > 0.9 else 'reduced_chi_squared'\n",
    "        }\n",
    "\n",
    "        spectra.append(spectrum)\n",
    "        fitted_continua.append(y_continuum_original_scale)\n",
    "        residuals.append(residual)\n",
    "        fit_std_dev.append(y_continuum_std)\n",
    "        fit_metrics.append(metrics)\n",
    "\n",
    "    return spectra, fitted_continua, residuals, fit_std_dev, fit_metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def fit_continuum_with_metrics_for_stacked(wave_a, spec_a, spec_std_a=None, scaling_factor=1e-16):\n",
    "    \"\"\"\n",
    "    Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wave_rest_list : list of arrays\n",
    "        List of wavelength arrays for each spectrum\n",
    "    spec_rest_list : list of arrays\n",
    "        List of flux arrays for each spectrum\n",
    "    spec_std_list : list of arrays, optional\n",
    "        List of flux standard deviation arrays for each spectrum\n",
    "    scaling_factor : float\n",
    "        Scaling factor to apply to the flux values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing:\n",
    "        - spectra: List of Spectrum1D objects\n",
    "        - continua: List of fitted continuum arrays\n",
    "        - residuals: List of residual arrays\n",
    "        - fit_std: List of standard deviation arrays for each fit\n",
    "        - fit_metrics: List of dictionaries with fit quality metrics (r², χ², p-value)\n",
    "    \"\"\"\n",
    "    # Initialize output containers\n",
    "    spectra = []\n",
    "    fitted_continua = []\n",
    "    residuals = []\n",
    "    fit_std_dev = []\n",
    "    fit_metrics = []\n",
    "\n",
    "    spec_a = np.where(np.isnan(spec_a), 0, spec_a)\n",
    "\n",
    "    spec_a = np.where(np.isnan(spec_a), 0, spec_a)\n",
    "    \n",
    "    spectrum = Spectrum1D(spec_a *1e16 * u.erg / u.angstrom / u.second / u.cm**2, wave_a * u.angstrom)\n",
    "    \n",
    "    # Fit continuum while suppressing warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        continuum_fit = fit_generic_continuum(spectrum, model = models.Chebyshev1D(4), exclude_regions=[SpectralRegion(2745*u.angstrom, 2885*u.angstrom)])\n",
    "            \n",
    "    # Fix: evaluate the fitted continuum model properly\n",
    "    y_continuum = continuum_fit(wave_a * u.angstrom)\n",
    "    \n",
    "    # First get the raw numerical values without units\n",
    "    y_continuum_original_scale = y_continuum.value *1e-16\n",
    "        \n",
    "    # Calculate residuals: (spectrum - continuum) / continuum\n",
    "    residual = (spec_a - y_continuum_original_scale) / y_continuum_original_scale\n",
    "    # Calculate standard deviation of the fit\n",
    "    # This uses bootstrap resampling to estimate fit uncertainty \n",
    "    n_bootstrap = 500\n",
    "    bootstrap_results = np.zeros((n_bootstrap, len(wave_a)))\n",
    "        \n",
    "    for b in range(n_bootstrap):\n",
    "        # Create bootstrap sample (resample with replacement)\n",
    "        indices = np.random.choice(len(wave_a), size=len(wave_a), replace=True)\n",
    "        # Sort indices to ensure monotonicity\n",
    "        boot_indices = np.sort(indices)\n",
    "            \n",
    "        wave_boot = wave_a[boot_indices]\n",
    "        spec_boot = spec_a[boot_indices]\n",
    "            \n",
    "        boot_spectrum = Spectrum1D(flux=spec_boot * 1e16 * u.erg / u.angstrom / u.second / u.cm**2, spectral_axis=wave_boot * u.angstrom)\n",
    "        # Fit continuum to bootstrap sample\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            boot_fit = fit_generic_continuum(\n",
    "                        boot_spectrum, \n",
    "                        model= models.Chebyshev1D(4),\n",
    "                        exclude_regions=[SpectralRegion(2745*u.angstrom, 2885*u.angstrom)]\n",
    "                    )\n",
    "                    \n",
    "        # Evaluate on original wavelength grid and store\n",
    "        boot_continuum = boot_fit(wave_a * u.angstrom)\n",
    "        bootstrap_results[b] = boot_continuum.value * 1e-16\n",
    "    \n",
    "    # Calculate standard deviation across bootstrap samples\n",
    "    # This is the standard deviation for y_continuum_original_scale\n",
    "    y_continuum_std = np.std(bootstrap_results, axis=0)\n",
    "        \n",
    "    # Calculate fit quality metrics\n",
    "    # 1. R-squared (coefficient of determination)\n",
    "    ss_total = np.sum((spec_a - np.mean(spec_a))**2)\n",
    "    ss_residual = np.sum((spec_a - y_continuum_original_scale)**2)\n",
    "    r_squared = 1 - (ss_residual / ss_total)\n",
    "        \n",
    "    # 2. Chi-squared goodness of fit\n",
    "    # Exclude regions used in fitting\n",
    "    mask = (wave_a < 2745) | (wave_a > 2885)\n",
    "    weights = 1.0 / (spec_std_a**2) if np.all(spec_std_a > 0) else np.ones_like(spec_a)\n",
    "    chi_squared = np.sum(weights[mask] * ((spec_a[mask] - y_continuum_original_scale[mask])**2))\n",
    "    \n",
    "    # 3. Reduced chi-squared (chi-squared per degree of freedom)\n",
    "    dof = np.sum(mask) - models.Chebyshev1D(4).degree - 1  # degrees of freedom\n",
    "    reduced_chi_squared = chi_squared / dof if dof > 0 else np.nan\n",
    "    \n",
    "    # 4. Kolmogorov-Smirnov test (normality of residuals)\n",
    "    # Normalized residuals should follow a normal distribution for a good fit\n",
    "    normalized_residuals = residual / np.std(residual)\n",
    "    ks_statistic, p_value = stats.kstest(normalized_residuals[mask], 'norm')\n",
    "    # Store fit metrics\n",
    "    metrics = {\n",
    "        'r_squared': r_squared,\n",
    "        'chi_squared': chi_squared,\n",
    "        'reduced_chi_squared': reduced_chi_squared,\n",
    "        'ks_statistic': ks_statistic,\n",
    "        'p_value': p_value,\n",
    "        'best_metric': 'r_squared' if r_squared > 0.9 else 'reduced_chi_squared'\n",
    "    }\n",
    "    \n",
    "    # Store results\n",
    "    spectra.append(spectrum)\n",
    "    fitted_continua.append(y_continuum_original_scale)\n",
    "    residuals.append(residual)\n",
    "    fit_std_dev.append(y_continuum_std)  # Now storing the standard deviation of the continuum\n",
    "    fit_metrics.append(metrics)\n",
    "\n",
    "    return spectra, fitted_continua, residuals, fit_std_dev, fit_metrics\n",
    "\n",
    "\n",
    "def double_gaussian_exp_model(x, g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma, exp_amp, exp_decay):\n",
    "    \"\"\"Model with two Gaussians and an exponential component\"\"\"\n",
    "    gaussian1 = g1_amp * np.exp(-0.5 * ((x - g1_center) / g1_sigma)**2)\n",
    "    gaussian2 = g2_amp * np.exp(-0.5 * ((x - g2_center) / g2_sigma)**2)\n",
    "    exponential = exp_amp * np.exp(-x / exp_decay)\n",
    "    return gaussian1 + gaussian2 + exponential\n",
    "\n",
    "def double_gaussian_model(x, g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma):\n",
    "    \"\"\"Model with two Gaussians and an exponential component\"\"\"\n",
    "    gaussian1 = g1_amp * np.exp(-0.5 * ((x - g1_center) / g1_sigma)**2)\n",
    "    gaussian2 = g2_amp * np.exp(-0.5 * ((x - g2_center) / g2_sigma)**2)\n",
    "    return gaussian1 + gaussian2\n",
    "\n",
    "def calc_components_No_Exponential(x, params):\n",
    "    \"\"\"Calculate individual components for plotting\"\"\"\n",
    "    g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma = params\n",
    "    \n",
    "    gaussian1 = g1_amp * np.exp(-0.5 * ((x - g1_center) / g1_sigma)**2)\n",
    "    gaussian2 = g2_amp * np.exp(-0.5 * ((x - g2_center) / g2_sigma)**2)\n",
    "    \n",
    "    return {\n",
    "        'gaussian1': gaussian1,\n",
    "        'gaussian2': gaussian2,\n",
    "        'total': gaussian1 + gaussian2}\n",
    "    \n",
    "def calc_components(x, params):\n",
    "    \"\"\"Calculate individual components for plotting\"\"\"\n",
    "    g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma, exp_amp, exp_decay = params\n",
    "    \n",
    "    gaussian1 = g1_amp * np.exp(-0.5 * ((x - g1_center) / g1_sigma)**2)\n",
    "    gaussian2 = g2_amp * np.exp(-0.5 * ((x - g2_center) / g2_sigma)**2)\n",
    "    exponential = exp_amp * np.exp(-x / exp_decay)\n",
    "    \n",
    "    return {\n",
    "        'gaussian1': gaussian1,\n",
    "        'gaussian2': gaussian2,\n",
    "        'exponential': exponential,\n",
    "        'total': gaussian1 + gaussian2 + exponential\n",
    "    }\n",
    "\n",
    "\n",
    "def double_gaussian_model_velocity(x, g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma):\n",
    "    \"\"\"Model with two Gaussians and an exponential component\"\"\"\n",
    "    gaussian1 = g1_amp * np.exp(-0.5 * ((x - g1_center) / g1_sigma)**2)\n",
    "    gaussian2 = g2_amp * np.exp(-0.5 * ((x - g2_center) / g2_sigma)**2)\n",
    "   \n",
    "    return gaussian1 + gaussian2 \n",
    "\n",
    "def calc_components_velocity(x, params):\n",
    "    \"\"\"Calculate individual components for plotting\"\"\"\n",
    "    g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma = params\n",
    "    \n",
    "    gaussian1 = g1_amp * np.exp(-0.5 * ((x - g1_center) / g1_sigma)**2)\n",
    "    gaussian2 = g2_amp * np.exp(-0.5 * ((x - g2_center) / g2_sigma)**2)\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'gaussian1': gaussian1,\n",
    "        'gaussian2': gaussian2,\n",
    "        'total': gaussian1 + gaussian2}\n",
    "    \n",
    "\n",
    "def luminosity_evolution_correction(luminosities, luminosities_SD, redshifts, ref_z=0.25, evolution_model='power_law', plot_results=True, n_bins=7):\n",
    "    \"\"\"\n",
    "    Apply luminosity evolution correction to AGN luminosity data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    luminosities : array-like\n",
    "        Original luminosity values\n",
    "    luminosities_SD : array-like\n",
    "        Standard deviations of original luminosities\n",
    "    redshifts : array-like\n",
    "        Redshift values\n",
    "    ref_z : float, default=0.25\n",
    "        Reference redshift for correction\n",
    "    evolution_model : str, default='power_law'\n",
    "        Evolution model ('power_law', 'exponential', 'linear')\n",
    "    plot_results : bool, default=True\n",
    "        Whether to create plots\n",
    "    n_bins : int, default=10\n",
    "        Number of redshift bins for binned output\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    corrected_luminosities : array\n",
    "        Luminosity values corrected for evolution\n",
    "    corrected_luminosities_SD : array\n",
    "        Standard deviations of corrected luminosities (properly propagated)\n",
    "    correction_params : dict\n",
    "        Parameters of the fitted evolution model\n",
    "    binned_results : dict\n",
    "        Dictionary containing binned corrected luminosities and their SDs\n",
    "    \"\"\"\n",
    "\n",
    "    luminosities = np.asarray(luminosities)\n",
    "    redshifts = np.asarray(redshifts)\n",
    "    luminosities_SD = np.asarray(luminosities_SD)\n",
    "\n",
    "    # Define evolution models\n",
    "    def power_law(z, alpha):\n",
    "        return (1 + z)**alpha\n",
    "    \n",
    "    def exponential(z, k):\n",
    "        return np.exp(k * z)\n",
    "    \n",
    "    def linear(z, m):\n",
    "        return 1 + m * z\n",
    "    \n",
    "    # Take natural log of luminosities for fitting\n",
    "    log_luminosities = np.log(luminosities)\n",
    "    \n",
    "    # Choose evolution model and fit\n",
    "    if evolution_model == 'power_law':\n",
    "        X = np.log(1 + redshifts).reshape(-1, 1)\n",
    "        model = stats.linregress(X.flatten(), log_luminosities)\n",
    "        alpha = model.slope\n",
    "        intercept = model.intercept\n",
    "        evolution_func = power_law\n",
    "        params = [alpha]\n",
    "        correction_params = {'model': 'power_law', 'alpha': alpha}\n",
    "    \n",
    "    elif evolution_model == 'exponential':\n",
    "        X = redshifts.reshape(-1, 1)\n",
    "        model = stats.linregress(X.flatten(), log_luminosities)\n",
    "        k = model.slope\n",
    "        intercept = model.intercept\n",
    "        evolution_func = exponential\n",
    "        params = [k]\n",
    "        correction_params = {'model': 'exponential', 'k': k}\n",
    "    \n",
    "    elif evolution_model == 'linear':\n",
    "        def linear_fit_func(z, log_L0, m):\n",
    "            return log_L0 + np.log(1 + m * z)\n",
    "        \n",
    "        popt, _ = curve_fit(linear_fit_func, redshifts, log_luminosities)\n",
    "        log_L0, m = popt\n",
    "        intercept = log_L0\n",
    "        evolution_func = linear\n",
    "        params = [m]\n",
    "        correction_params = {'model': 'linear', 'm': m}\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Evolution model must be 'power_law', 'exponential', or 'linear'\")\n",
    "    \n",
    "    # Calculate correction factors\n",
    "    correction_factors = evolution_func(redshifts, *params) / evolution_func(ref_z, *params)\n",
    "    \n",
    "    # Apply correction to normalize to reference redshift\n",
    "    corrected_luminosities = luminosities / correction_factors\n",
    "\n",
    "    # Propagate uncertainty: corrected_SD = original_SD / correction_factor\n",
    "    corrected_luminosities_SD = luminosities_SD / correction_factors\n",
    "\n",
    "    # Create redshift bins for binned output\n",
    "    z_bins = np.linspace(np.min(redshifts), np.max(redshifts), n_bins + 1)\n",
    "    z_bin_centers = (z_bins[:-1] + z_bins[1:]) / 2\n",
    "    digitized_bins = np.digitize(redshifts, z_bins)\n",
    "    \n",
    "    # Organize corrected data by redshift bins\n",
    "    binned_corrected_luminosities = []\n",
    "    binned_corrected_luminosities_SD = []\n",
    "    bin_info = []\n",
    "    \n",
    "    for i in range(1, len(z_bins)):\n",
    "        bin_mask = digitized_bins == i\n",
    "        if np.sum(bin_mask) > 0:\n",
    "            bin_corrected_lum = corrected_luminosities[bin_mask]\n",
    "            bin_corrected_lum_SD = corrected_luminosities_SD[bin_mask]\n",
    "            \n",
    "            binned_corrected_luminosities.append(bin_corrected_lum)\n",
    "            binned_corrected_luminosities_SD.append(bin_corrected_lum_SD)\n",
    "            \n",
    "            bin_info.append({\n",
    "                'bin_index': i-1,\n",
    "                'z_center': z_bin_centers[i-1],\n",
    "                'z_range': (z_bins[i-1], z_bins[i]),\n",
    "                'n_objects': len(bin_corrected_lum),\n",
    "                'redshifts': redshifts[bin_mask]\n",
    "            })\n",
    "    \n",
    "    # Create binned results dictionary\n",
    "    binned_results = {\n",
    "        'corrected_luminosities_by_bin': binned_corrected_luminosities,\n",
    "        'corrected_luminosities_SD_by_bin': binned_corrected_luminosities_SD,\n",
    "        'bin_info': bin_info,\n",
    "        'z_bins': z_bins,\n",
    "        'z_bin_centers': z_bin_centers\n",
    "    }\n",
    "\n",
    "    if plot_results:\n",
    "        # Color scheme\n",
    "        purple = \"#a714ff\"\n",
    "        pink = \"#ff14f5\"\n",
    "        teal = \"#14D8FF\"\n",
    "        main_blue = \"#60B5FF\"\n",
    "        green = \"#00FF9C\"\n",
    "        orange = \"#ffbb14\"\n",
    "        red = \"#FF5757\"\n",
    "        \n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "        plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        z_bins_for_errors = np.linspace(min(redshifts), max(redshifts), 10)\n",
    "        digitized = np.digitize(redshifts, z_bins_for_errors)\n",
    "        \n",
    "        z_bin_centers = []\n",
    "        orig_lum_means = []\n",
    "        orig_lum_stds = []\n",
    "        corr_lum_means = []\n",
    "        corr_lum_stds = []\n",
    "        \n",
    "        for i in range(1, len(z_bins_for_errors)):\n",
    "            bin_mask = digitized == i\n",
    "            if np.sum(bin_mask) > 1:\n",
    "                z_bin_centers.append((z_bins_for_errors[i-1] + z_bins_for_errors[i]) / 2)\n",
    "                orig_lum_means.append(np.mean(luminosities[bin_mask]))\n",
    "                orig_lum_stds.append(np.std(luminosities_SD[bin_mask]))\n",
    "                corr_lum_means.append(np.mean(corrected_luminosities[bin_mask]))\n",
    "                corr_lum_stds.append(np.std(corrected_luminosities_SD[bin_mask]))  # Updated\n",
    "\n",
    "        axs[0].scatter(redshifts, luminosities, marker='o', alpha=0.5, color=main_blue, s=30, zorder=3)\n",
    "        axs[0].errorbar(redshifts, luminosities, yerr=luminosities_SD, linestyle='', ecolor=\"black\", capsize=5, capthick=2, zorder=0)\n",
    "        axs[0].set_xlabel('Redshift (z)', fontsize=12)\n",
    "        axs[0].set_ylabel('Original Luminosity', fontsize=12)\n",
    "        axs[0].set_title('Original Luminosity vs Redshift', fontsize=12)\n",
    "        axs[0].set_yscale('log')\n",
    "        axs[0].grid(True, alpha=0.3, zorder=0)\n",
    "        axs[0].spines['top'].set_linewidth(1.5)\n",
    "        axs[0].spines['right'].set_linewidth(1.5)\n",
    "        axs[0].spines['left'].set_linewidth(1.5)\n",
    "        axs[0].spines['bottom'].set_linewidth(1.5)\n",
    "        axs[0].tick_params(axis='both', which='major', width=1.5, length=5, labelsize=10)\n",
    "        axs[0].tick_params(axis='both', which='minor', width=1, length=3, labelsize=8)\n",
    "        \n",
    "        axs[1].scatter(redshifts, corrected_luminosities, alpha=0.5, color=green, s=30, zorder=3)\n",
    "        axs[1].errorbar(redshifts, corrected_luminosities, yerr=corrected_luminosities_SD, linestyle='', ecolor=\"black\", capsize=5, capthick=2, zorder=0)  # Updated\n",
    "        axs[1].set_xlabel('Redshift (z)', fontsize=12)\n",
    "        axs[1].set_ylabel('Corrected Luminosity', fontsize=12)\n",
    "        axs[1].set_title(f'Corrected Luminosity vs Redshift (ref z={ref_z})', fontsize=12)\n",
    "        axs[1].set_yscale('log')\n",
    "        axs[1].grid(True, alpha=0.3, zorder=0)\n",
    "        axs[1].spines['top'].set_linewidth(1.5)\n",
    "        axs[1].spines['right'].set_linewidth(1.5)\n",
    "        axs[1].spines['left'].set_linewidth(1.5)\n",
    "        axs[1].spines['bottom'].set_linewidth(1.5)\n",
    "        axs[1].tick_params(axis='both', which='major', width=1.5, length=5, labelsize=10)\n",
    "        axs[1].tick_params(axis='both', which='minor', width=1, length=3, labelsize=8)\n",
    "        \n",
    "        axs[2].hist(np.log10(luminosities), bins=15, alpha=0.5, label='Original', color=purple)\n",
    "        axs[2].hist(np.log10(corrected_luminosities), bins=15, alpha=0.5, label='Corrected', color=teal)\n",
    "        axs[2].set_xlabel('Log Luminosity', fontsize=12)\n",
    "        axs[2].set_ylabel('Number', fontsize=12)\n",
    "        axs[2].set_title('Luminosity Distribution', fontsize=12)\n",
    "        axs[2].legend(\n",
    "            loc='upper right', \n",
    "            fontsize=9, \n",
    "            frameon=True, \n",
    "            fancybox=True, \n",
    "            shadow=True, \n",
    "            borderpad=0.8, \n",
    "            edgecolor='black', \n",
    "            facecolor='white', \n",
    "            handlelength=2.5,\n",
    "            columnspacing=1.5,\n",
    "            labelspacing=1.5\n",
    "        )\n",
    "        axs[2].grid(True, alpha=0.3, zorder=0)\n",
    "        axs[2].spines['top'].set_linewidth(1.5)\n",
    "        axs[2].spines['right'].set_linewidth(1.5)\n",
    "        axs[2].spines['left'].set_linewidth(1.5)\n",
    "        axs[2].spines['bottom'].set_linewidth(1.5)\n",
    "        axs[2].tick_params(axis='both', which='major', width=1.5, length=5, labelsize=10)\n",
    "        axs[2].tick_params(axis='both', which='minor', width=1, length=3, labelsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return corrected_luminosities, corrected_luminosities_SD, correction_params, binned_results\n",
    "\n",
    "def analyze_correction_results(luminosities, corrected_luminosities, redshifts, n_bins=7):\n",
    "    \"\"\"\n",
    "    Analyze the results of luminosity evolution correction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    luminosities : array-like\n",
    "        Original luminosity values\n",
    "    corrected_luminosities : array-like\n",
    "        Corrected luminosity values\n",
    "    redshifts : array-like\n",
    "        Redshift values\n",
    "    n_bins : int, default=7\n",
    "        Number of redshift bins for analysis\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Analysis results containing statistics and diagnostics\n",
    "    \"\"\"\n",
    "    \n",
    "    luminosities = np.asarray(luminosities)\n",
    "    corrected_luminosities = np.asarray(corrected_luminosities)\n",
    "    redshifts = np.asarray(redshifts)\n",
    "    \n",
    "    # Color scheme matching the original code\n",
    "    purple = \"#a714ff\"\n",
    "    pink = \"#ff14f5\"\n",
    "    teal = \"#14D8FF\"\n",
    "    main_blue = \"#60B5FF\"\n",
    "    green = \"#00FF9C\"\n",
    "    orange = \"#ffbb14\"\n",
    "    red = \"#FF5757\"\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "    \n",
    "    # Calculate correction factors\n",
    "    correction_factors = luminosities / corrected_luminosities\n",
    "    \n",
    "    # Basic statistics\n",
    "    original_stats = {\n",
    "        'mean': np.mean(luminosities),\n",
    "        'median': np.median(luminosities),\n",
    "        'std': np.std(luminosities),\n",
    "        'min': np.min(luminosities),\n",
    "        'max': np.max(luminosities)\n",
    "    }\n",
    "    \n",
    "    corrected_stats = {\n",
    "        'mean': np.mean(corrected_luminosities),\n",
    "        'median': np.median(corrected_luminosities),\n",
    "        'std': np.std(corrected_luminosities),\n",
    "        'min': np.min(corrected_luminosities),\n",
    "        'max': np.max(corrected_luminosities)\n",
    "    }\n",
    "    \n",
    "    # Create redshift bins for detailed analysis\n",
    "    z_bins = np.linspace(np.min(redshifts), np.max(redshifts), n_bins + 1)\n",
    "    z_bin_centers = (z_bins[:-1] + z_bins[1:]) / 2\n",
    "    digitized = np.digitize(redshifts, z_bins)\n",
    "    \n",
    "    # Analyze each redshift bin\n",
    "    bin_analysis = []\n",
    "    for i in range(1, len(z_bins)):\n",
    "        bin_mask = digitized == i\n",
    "        if np.sum(bin_mask) > 0:\n",
    "            bin_data = {\n",
    "                'z_center': z_bin_centers[i-1],\n",
    "                'z_range': (z_bins[i-1], z_bins[i]),\n",
    "                'n_objects': np.sum(bin_mask),\n",
    "                'original_lum_mean': np.mean(luminosities[bin_mask]),\n",
    "                'original_lum_std': np.std(luminosities[bin_mask]),\n",
    "                'corrected_lum_mean': np.mean(corrected_luminosities[bin_mask]),\n",
    "                'corrected_lum_std': np.std(corrected_luminosities[bin_mask]),\n",
    "                'mean_correction_factor': np.mean(correction_factors[bin_mask]),\n",
    "                'correction_factor_std': np.std(correction_factors[bin_mask])\n",
    "            }\n",
    "            bin_analysis.append(bin_data)\n",
    "    \n",
    "    # Test for correlation with redshift (before and after correction)\n",
    "    original_corr, original_p = stats.pearsonr(redshifts, np.log10(luminosities))\n",
    "    corrected_corr, corrected_p = stats.pearsonr(redshifts, np.log10(corrected_luminosities))\n",
    "    \n",
    "    # Variance reduction analysis\n",
    "    variance_reduction = (np.var(np.log10(luminosities)) - np.var(np.log10(corrected_luminosities))) / np.var(np.log10(luminosities))\n",
    "    \n",
    "    # Create comprehensive plots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Correction factors vs redshift\n",
    "    axs[0, 0].scatter(redshifts, correction_factors, alpha=0.6, color=orange, s=40)\n",
    "    axs[0, 0].set_xlabel('Redshift (z)', fontsize=12)\n",
    "    axs[0, 0].set_ylabel('Correction Factor', fontsize=12)\n",
    "    axs[0, 0].set_title('Correction Factors vs Redshift', fontsize=12)\n",
    "    axs[0, 0].grid(True, alpha=0.3)\n",
    "    axs[0, 0].set_yscale('log')\n",
    "    \n",
    "    # Plot 2: Log luminosity vs redshift correlation comparison\n",
    "    axs[0, 1].scatter(redshifts, np.log10(luminosities), alpha=0.5, color=main_blue, \n",
    "                     label=f'Original (r={original_corr:.3f})', s=30)\n",
    "    axs[0, 1].scatter(redshifts, np.log10(corrected_luminosities), alpha=0.5, color=green, \n",
    "                     label=f'Corrected (r={corrected_corr:.3f})', s=30)\n",
    "    axs[0, 1].set_xlabel('Redshift (z)', fontsize=12)\n",
    "    axs[0, 1].set_ylabel('Log₁₀ Luminosity', fontsize=12)\n",
    "    axs[0, 1].set_title('Luminosity-Redshift Correlation', fontsize=12)\n",
    "    axs[0, 1].legend(fontsize=10)\n",
    "    axs[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Variance comparison by redshift bin\n",
    "    if bin_analysis:\n",
    "        z_centers = [bin_data['z_center'] for bin_data in bin_analysis]\n",
    "        orig_vars = [bin_data['original_lum_std']**2 for bin_data in bin_analysis]\n",
    "        corr_vars = [bin_data['corrected_lum_std']**2 for bin_data in bin_analysis]\n",
    "        \n",
    "        x = np.arange(len(z_centers))\n",
    "        width = 0.35\n",
    "        \n",
    "        axs[0, 2].bar(x - width/2, orig_vars, width, label='Original', color=purple, alpha=0.7)\n",
    "        axs[0, 2].bar(x + width/2, corr_vars, width, label='Corrected', color=teal, alpha=0.7)\n",
    "        axs[0, 2].set_xlabel('Redshift Bin Center', fontsize=12)\n",
    "        axs[0, 2].set_ylabel('Variance', fontsize=12)\n",
    "        axs[0, 2].set_title('Variance by Redshift Bin', fontsize=12)\n",
    "        axs[0, 2].set_xticks(x)\n",
    "        axs[0, 2].set_xticklabels([f'{z:.2f}' for z in z_centers], rotation=45)\n",
    "        axs[0, 2].legend(fontsize=10)\n",
    "        axs[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    \n",
    "    # Q-Q plot to compare distributions\n",
    "    orig_quantiles = np.sort(np.log10(luminosities))\n",
    "    corr_quantiles = np.sort(np.log10(corrected_luminosities))\n",
    "    \n",
    "    # Theoretical normal quantiles\n",
    "    n = len(orig_quantiles)\n",
    "    theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "    \n",
    "    axs[1, 0].scatter(theoretical_quantiles, orig_quantiles, alpha=0.6, color=purple, \n",
    "                     label='Original', s=20)\n",
    "    axs[1, 0].scatter(theoretical_quantiles, corr_quantiles, alpha=0.6, color=teal, \n",
    "                     label='Corrected', s=20)\n",
    "    axs[1, 0].plot(theoretical_quantiles, theoretical_quantiles, 'k--', alpha=0.5)\n",
    "    axs[1, 0].set_xlabel('Theoretical Normal Quantiles', fontsize=12)\n",
    "    axs[1, 0].set_ylabel('Sample Quantiles (Log Luminosity)', fontsize=12)\n",
    "    axs[1, 0].set_title('Q-Q Plot vs Normal Distribution', fontsize=12)\n",
    "    axs[1, 0].legend(fontsize=10)\n",
    "    axs[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Residuals analysis\n",
    "    # Calculate residuals from mean trend\n",
    "    z_sorted_idx = np.argsort(redshifts)\n",
    "    z_sorted = redshifts[z_sorted_idx]\n",
    "    orig_sorted = np.log10(luminosities[z_sorted_idx])\n",
    "    corr_sorted = np.log10(corrected_luminosities[z_sorted_idx])\n",
    "    \n",
    "    # Simple moving average for trend\n",
    "    window = max(5, len(redshifts) // 10)\n",
    "    orig_trend = np.convolve(orig_sorted, np.ones(window)/window, mode='same')\n",
    "    corr_trend = np.convolve(corr_sorted, np.ones(window)/window, mode='same')\n",
    "    \n",
    "    orig_residuals = orig_sorted - orig_trend\n",
    "    corr_residuals = corr_sorted - corr_trend\n",
    "    \n",
    "    axs[1, 1].scatter(z_sorted, orig_residuals, alpha=0.6, color=purple, \n",
    "                     label=f'Original (σ={np.std(orig_residuals):.3f})', s=20)\n",
    "    axs[1, 1].scatter(z_sorted, corr_residuals, alpha=0.6, color=teal, \n",
    "                     label=f'Corrected (σ={np.std(corr_residuals):.3f})', s=20)\n",
    "    axs[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    axs[1, 1].set_xlabel('Redshift (z)', fontsize=12)\n",
    "    axs[1, 1].set_ylabel('Residuals (Log Luminosity)', fontsize=12)\n",
    "    axs[1, 1].set_title('Residuals from Trend', fontsize=12)\n",
    "    axs[1, 1].legend(fontsize=10)\n",
    "    axs[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Statistical summary\n",
    "    axs[1, 2].axis('off')\n",
    "    \n",
    "    # Create text summary\n",
    "    summary_text = f\"\"\"Statistical Summary:\n",
    "\n",
    "Original Data:\n",
    "  Mean: {original_stats['mean']:.2e}\n",
    "  Std:  {original_stats['std']:.2e}\n",
    "  \n",
    "Corrected Data:\n",
    "  Mean: {corrected_stats['mean']:.2e}\n",
    "  Std:  {corrected_stats['std']:.2e}\n",
    "\n",
    "Correlation with Redshift:\n",
    "  Original:  r = {original_corr:.4f} (p = {original_p:.4f})\n",
    "  Corrected: r = {corrected_corr:.4f} (p = {corrected_p:.4f})\n",
    "\n",
    "Variance Reduction: {variance_reduction:.1%}\n",
    "\n",
    "Correction Factor Stats:\n",
    "  Mean: {np.mean(correction_factors):.3f}\n",
    "  Range: {np.min(correction_factors):.3f} - {np.max(correction_factors):.3f}\n",
    "  \n",
    "Data Points: {len(luminosities)}\n",
    "Redshift Range: {np.min(redshifts):.3f} - {np.max(redshifts):.3f}\"\"\"\n",
    "    \n",
    "    axs[1, 2].text(0.05, 0.95, summary_text, transform=axs[1, 2].transAxes, \n",
    "                   fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    # Style all plots\n",
    "    for ax in axs.flat:\n",
    "        if ax.get_xlabel():  # Skip the text-only subplot\n",
    "            ax.spines['top'].set_linewidth(1.5)\n",
    "            ax.spines['right'].set_linewidth(1.5)\n",
    "            ax.spines['left'].set_linewidth(1.5)\n",
    "            ax.spines['bottom'].set_linewidth(1.5)\n",
    "            ax.tick_params(axis='both', which='major', width=1.5, length=5, labelsize=10)\n",
    "            ax.tick_params(axis='both', which='minor', width=1, length=3, labelsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compile results\n",
    "    analysis_results = {\n",
    "        'original_statistics': original_stats,\n",
    "        'corrected_statistics': corrected_stats,\n",
    "        'correlation_analysis': {\n",
    "            'original_correlation': original_corr,\n",
    "            'original_p_value': original_p,\n",
    "            'corrected_correlation': corrected_corr,\n",
    "            'corrected_p_value': corrected_p\n",
    "        },\n",
    "        'correction_factors': {\n",
    "            'mean': np.mean(correction_factors),\n",
    "            'std': np.std(correction_factors),\n",
    "            'min': np.min(correction_factors),\n",
    "            'max': np.max(correction_factors)\n",
    "        },\n",
    "        'variance_reduction': variance_reduction,\n",
    "        'bin_analysis': bin_analysis,\n",
    "        'data_summary': {\n",
    "            'n_objects': len(luminosities),\n",
    "            'redshift_range': (np.min(redshifts), np.max(redshifts)),\n",
    "            'luminosity_range_original': (np.min(luminosities), np.max(luminosities)),\n",
    "            'luminosity_range_corrected': (np.min(corrected_luminosities), np.max(corrected_luminosities))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return analysis_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bce8b9-54ab-4cf9-a72a-39e48b3e85c8",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Lab Wavelength Values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b966bd-cbd9-4476-8fe9-7f2c67c44c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "OIII_3133 = np.float64(3132.794)\n",
    "MgII_doublet_unresolved = np.mean(np.array([2795.528, 2802.705]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6a637-4628-4d93-a8f2-ca5ff828c78e",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Grabbing the spectra</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca329838-82d2-4cd9-a774-3c64de732b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Redshift_Confirmed = \"Table_Spec_Redshift_Confirmed_New_Old.fits\"\n",
    "File_Redshift_Unconfirmed = \"Table_Spec_Redshift_Unconfirmed_New_Old.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ac4318-09c4-4db9-ba73-5d8745bc4452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Detectid    z        wave1d              spec1d               spec1d_err           RA        DEC   \n",
      "---------- ----- ---------------- ---------------------- ---------------------- ---------- ---------\n",
      "2100061353 0.639 3470.0 .. 5540.0 3.5350318 .. 7.6069765 18.156052 .. 6.2139535 15.0775433 -0.082578\n"
     ]
    }
   ],
   "source": [
    "Data_Redshift_Confirmed = Table.read(File_Redshift_Confirmed, format = 'fits')\n",
    "Data_Redshift_Unconfirmed = Table.read(File_Redshift_Unconfirmed, format = 'fits')\n",
    "\n",
    "print(Data_Redshift_Confirmed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269bda28-d2ed-41cb-aed4-e952422c5cdc",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Grabbing the spectra from the Image Part of this Project</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d535878-c89d-4f08-8e8a-de54752b7ff5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Table_Detect_IDs_From_Images.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m File_Redshift_Confirmed_From_Images \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable_Detect_IDs_From_Images.fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m Data_Redshift_Confirmed_From_Images \u001b[38;5;241m=\u001b[39m \u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFile_Redshift_Confirmed_From_Images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/table/connect.py:62\u001b[0m, in \u001b[0;36mTableRead.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m units \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m descriptions \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescriptions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 62\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# For some readers (e.g., ascii.ecsv), the returned `out` class is not\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# guaranteed to be the same as the desired output `cls`.  If so,\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# try coercing to desired class without copying (io.registry.read\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# would normally do a copy).  The normal case here is swapping\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Table <=> QTable.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/io/registry/core.py:221\u001b[0m, in \u001b[0;36mUnifiedInputRegistry.read\u001b[0;34m(self, cls, format, cache, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m: path})\n\u001b[1;32m    220\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_reader(\u001b[38;5;28mformat\u001b[39m, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# User has read with a subclass where only the parent class is\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# registered.  This returns the parent class, so try coercing\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# to desired subclass.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/io/fits/connect.py:252\u001b[0m, in \u001b[0;36mread_table_fits\u001b[0;34m(input, hdu, astropy_native, memmap, character_as_bytes, unit_parse_strict, mask_invalid, strip_spaces)\u001b[0m\n\u001b[1;32m    249\u001b[0m     mask_invalid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     strip_spaces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m hdulist \u001b[38;5;241m=\u001b[39m \u001b[43mfits_open\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharacter_as_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcharacter_as_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_table_fits(\n\u001b[1;32m    256\u001b[0m         hdulist,\n\u001b[1;32m    257\u001b[0m         hdu\u001b[38;5;241m=\u001b[39mhdu,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m         strip_spaces\u001b[38;5;241m=\u001b[39mstrip_spaces,\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/io/fits/hdu/hdulist.py:220\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/io/fits/hdu/hdulist.py:484\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    476\u001b[0m ):\n\u001b[1;32m    477\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/io/fits/hdu/hdulist.py:1186\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/io/fits/file.py:240\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache, use_fsspec, fsspec_kwargs, decompress_in_memory)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_fileobj(fileobj, mode, overwrite)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filelike(fileobj, mode, overwrite)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/astropy/io/fits/file.py:701\u001b[0m, in \u001b[0;36m_File._open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    698\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_read_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, magic, mode, ext\u001b[38;5;241m=\u001b[39mext):\n\u001b[0;32m--> 701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIO_FITS_MODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_on_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Table_Detect_IDs_From_Images.fits'"
     ]
    }
   ],
   "source": [
    "File_Redshift_Confirmed_From_Images = \"Table_Detect_IDs_From_Images.fits\"\n",
    "Data_Redshift_Confirmed_From_Images = Table.read(File_Redshift_Confirmed_From_Images, format = 'fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817580c7-a561-4d13-b36b-c52b354d0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "Detect_IDs_from_Images = Data_Redshift_Confirmed_From_Images[\"Detect_ID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd1339-90c4-409b-994b-bc88a7c1e0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087d48e-a8cc-4b89-bc7a-4f5a6c5ddc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Detect_IDs_from_Images_Index_Array = []\n",
    "\n",
    "for i in np.arange(len(Detect_IDs_from_Images)):\n",
    "    Detect_ID_Index = np.where(Data_Redshift_Confirmed[\"Detectid\"] == Detect_IDs_from_Images[i])[0]\n",
    "    if len(Detect_ID_Index) > 0:\n",
    "        Detect_IDs_from_Images_Index_Array.append(Detect_ID_Index)\n",
    "\n",
    "Data_Redshift_Confirmed_From_Images = Data_Redshift_Confirmed[np.array(Detect_IDs_from_Images_Index_Array)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631d94a-d904-4d5e-a7ef-ac3fe5deb373",
   "metadata": {},
   "source": [
    "# <font color='#e55730' size=5 >For Confirmed Redshift</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b2a38-b68a-495e-9474-803555ba269f",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Looking at the Elixer for Confirmed Redshift</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b309f3-3e37-4800-b748-111df4711231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elixer Report for the Redshift Confirmed Sources\n",
    "EW = ElixerWidget(detectlist=Data_Redshift_Confirmed_From_Images[\"Detectid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22601ce-2ee5-4c1e-b6a7-5ae9c0b231c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESU.shift_flam_to_rest_luminosity_per_aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330e111-e41e-433c-9fb9-05f97615be83",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Looking at all the plots for the Data from the Images</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d7e7f-f7aa-46e6-a6c2-a3933e1269aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spec_Rest = []\n",
    "Wave_Rest = []\n",
    "Spec_Rest_SD = []\n",
    "Detect_ID_Names = []\n",
    "\n",
    "for i in np.arange(len(Data_Redshift_Confirmed_From_Images)):\n",
    "\n",
    "    #load an individual spectrum. The spectrum units are in 10^-17 erg AA^-1 s^-1 cm^-2. Need to multiply by 1e-17.\n",
    "    obs_spec, obs_err = Data_Redshift_Confirmed_From_Images[i]['spec1d'][0]*1e-17, Data_Redshift_Confirmed_From_Images[i]['spec1d_err'][0]*1e-17\n",
    "    #Get the coresponding redshift\n",
    "    z = Data_Redshift_Confirmed_From_Images[i][\"z\"][0]\n",
    "    #Get the coresponding Detect ID\n",
    "    detectida = Data_Redshift_Confirmed_From_Images[i][\"Detectid\"]\n",
    "    \n",
    "    #Put in the wavelengths in to get the wave grid. The air to vacuum accounts for the fact that the light changes based on the medium it travels through. So vacuum wavelength is different than air wavelength.\n",
    "    CALFIB_WAVEGRID_VAC = ESU.air_to_vac(Data_Redshift_Confirmed_From_Images[i]['wave1d'][0])\n",
    "    #Get the rest values. \n",
    "    spec_rest, wave_rest, err_rest = ESU.shift_flam_to_rest_luminosity_per_aa(z, obs_spec, CALFIB_WAVEGRID_VAC, obs_err)\n",
    "\n",
    "    spec_rest = obs_spec * (1+z)**3\n",
    "    spec_rest_SD = obs_err * (1 + z)**3\n",
    "    \n",
    "    Spec_Rest.append(spec_rest)\n",
    "    Wave_Rest.append(wave_rest)\n",
    "    Spec_Rest_SD.append(spec_rest_SD)\n",
    "    Detect_ID_Names.append(detectida)\n",
    "    \n",
    "# Define spectral lines\n",
    "spectral_lines = {\n",
    "        1892.030: ('#309898', '-.', 'SiIII', 3),\n",
    "        1908.734: ('#FF9F00', '--', 'CIII', 3),\n",
    "        2142.780: ('#CB0404', '-.', 'NII', 3),\n",
    "        2320.951: ('#1D5799', ':', 'OIII', 3),\n",
    "        2733.289: ('red', '-.', 'HeII', 3),\n",
    "        2799.000: ('#8B3D88', '--', 'MgII', 3),\n",
    "        2829.360: ('blue', '-.' ,'FeIV', 3),\n",
    "        2835.740: ('orange', ':' ,'FeIV', 3),\n",
    "        2853.670: ('green', '--' ,'ArIV', 3),\n",
    "        2868.210: ('pink', '-.' ,'ARIV', 3),\n",
    "        2945.106: ('#74B741', '--', 'HeI', 3),\n",
    "        3132.794: ('#DB3EB1', ':', 'OIII', 3),\n",
    "        2648.710: ('black', '-', 'Fe XI', 3)\n",
    "    } #Rest Wavelength, color, linestyle, label, linewidth\n",
    "\n",
    "\n",
    "Plots_For_Interactive_Plotting = []   \n",
    "# Sample plot data - in real use case, this would be your spectral data\n",
    "for j in np.arange(len(Spec_Rest)):\n",
    "    wave_spec_interactive = Wave_Rest[j]\n",
    "    spec_rest_interactive = Spec_Rest[j]\n",
    "    spec_rest_sd_interactive = Spec_Rest_SD[j]\n",
    "    names_interactive = Detect_ID_Names[i]\n",
    "    Plots_For_Interactive_Plotting.append([wave_spec_interactive, spec_rest_interactive, spec_rest_sd_interactive, names_interactive])\n",
    "    \n",
    "# Create and display the interactive plotter\n",
    "plotter = InteractivePlotter(Plots_For_Interactive_Plotting, spectral_lines)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682c0c5-261a-4b0a-9f55-f31cf0626ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Get the function's signature\n",
    "signature = inspect.signature(ESU.shift_flam_to_rest_luminosity_per_aa)\n",
    "print(\"Signature:\", signature)\n",
    "\n",
    "# Get the return type annotation\n",
    "return_type = signature.return_annotation\n",
    "print(\"Return type:\", return_type)\n",
    "\n",
    "# Get the docstring\n",
    "docstring = inspect.getdoc(ESU.shift_flam_to_rest_luminosity_per_aa)\n",
    "print(\"Docstring:\", docstring)\n",
    "\n",
    "# Get the source code\n",
    "source_code = inspect.getsource(ESU.shift_flam_to_rest_luminosity_per_aa)\n",
    "print(\"Source code:\\n\", source_code)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d567272-d847-4e5e-adc4-f00cc873bca0",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Stacking the Rest Wavelength Spectra Using Biweight</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03519ec5-a36b-488f-a588-4589fa58769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack all spectra \n",
    "avg_type = 'biweight' #Options: 'weighted_biweight', 'mean', 'median'\n",
    "Stack_Spec, Stack_Spec_SD, Stack_Wave, Contrib_Count, Stack_Flux_SD = ESU.stack_spectra(Spec_Rest, Spec_Rest_SD, Wave_Rest, avg_type=avg_type, std=True) #Contrib_Count is the number of spectra contributing to the wavelength bin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4d4fa-a80e-432b-8e7d-119f20f91545",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(Stack_Wave, Stack_Spec, color=\"black\")\n",
    "plt.fill_between(Stack_Wave, Stack_Spec - Stack_Spec_SD, Stack_Spec + Stack_Spec_SD, color=\"green\", alpha=0.9, zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802f54a-3409-4cfa-88e8-f098a7f0cf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a69230-e833-472f-bea8-ec17d07be678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffb4d616-5378-405b-8780-e1a62464690a",
   "metadata": {},
   "source": [
    "# <font color='#e55730' size=5> Normalizing by matching average spec continuum values to original stacked continuum</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ba216-cd28-40fe-8547-882ba73f41bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a38a2c-3ce7-4f7e-ab7e-0b59c4ebc09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c927c-fa71-4e36-a509-c2809133aa01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c244563-0fdc-412c-920d-350158d32d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd9754-6713-4fd3-9350-ccb81683e756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0aebf5-6566-4329-9eb8-f5a33e17182f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74145dfe-d835-450f-9201-e1298d16fb48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed423e0d-aa37-4f85-b19e-1a807044ff27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d12338fa-4e36-42a4-b8f6-04ceac6e8872",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Seperating the Individual spectra and the stacked spectra</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fcad9-9f5e-4fc3-aac4-71fa3425d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_025_035 = []\n",
    "Z_035_045 = []\n",
    "Z_045_055 = []\n",
    "Z_055_065 = []\n",
    "Z_065_075 = []\n",
    "Z_075_085 = []\n",
    "Z_085_096 = []\n",
    "\n",
    "Z_025_035_Index = []\n",
    "Z_035_045_Index = []\n",
    "Z_045_055_Index = []\n",
    "Z_055_065_Index = []\n",
    "Z_065_075_Index = []\n",
    "Z_075_085_Index = []\n",
    "Z_085_096_Index = [] \n",
    "\n",
    "\n",
    "a = -1\n",
    "for i in Data_Redshift_Confirmed_From_Images[\"z\"]:\n",
    "    a = a+1\n",
    "    #print(i)\n",
    "    if 0.25 <= i < 0.35:\n",
    "        #print(i)\n",
    "        Z_025_035.append(i)\n",
    "        Z_025_035_Index.append(a)\n",
    "    if 0.35 <= i < 0.45:\n",
    "        Z_035_045.append(i)\n",
    "        Z_035_045_Index.append(a)\n",
    "    if 0.45 <= i < 0.55:\n",
    "        Z_045_055.append(i)\n",
    "        Z_045_055_Index.append(a)\n",
    "    if 0.55 <= i < 0.65:\n",
    "        Z_055_065.append(i)\n",
    "        Z_055_065_Index.append(a)\n",
    "    if 0.65 <= i < 0.75:\n",
    "        Z_065_075.append(i)\n",
    "        Z_065_075_Index.append(a)\n",
    "    if 0.75 <= i < 0.85:\n",
    "        Z_075_085.append(i)\n",
    "        Z_075_085_Index.append(a)\n",
    "    if 0.85<= i <= 0.96:\n",
    "        Z_085_096.append(i)\n",
    "        Z_085_096_Index.append(a)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac97ffa-2466-42a0-8ba4-3968609e39a7",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Getting the Resdshift Bins</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e9575-9678-4673-ac50-c4f8c587f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the non stacked spectra\n",
    "#Spec_Rest_025_035, Spec_Rest_SD_025_035, Wave_Rest_025_035 = np.array(Spec_Rest)[Z_025_035_Index], np.array(Spec_Rest_SD)[Z_025_035_Index], np.array(Wave_Rest)[Z_025_035_Index]\n",
    "#Spec_Rest_035_045, Spec_Rest_SD_035_045, Wave_Rest_035_045 = np.array(Spec_Rest)[Z_035_045_Index], np.array(Spec_Rest_SD)[Z_035_045_Index], np.array(Wave_Rest)[Z_035_045_Index]\n",
    "#Spec_Rest_045_055, Spec_Rest_SD_045_055, Wave_Rest_045_055 = np.array(Spec_Rest)[Z_045_055_Index], np.array(Spec_Rest_SD)[Z_045_055_Index], np.array(Wave_Rest)[Z_045_055_Index]\n",
    "#Spec_Rest_055_065, Spec_Rest_SD_055_065, Wave_Rest_055_065 = np.array(Spec_Rest)[Z_055_065_Index], np.array(Spec_Rest_SD)[Z_055_065_Index], np.array(Wave_Rest)[Z_055_065_Index]\n",
    "#Spec_Rest_065_075, Spec_Rest_SD_065_075, Wave_Rest_065_075 = np.array(Spec_Rest)[Z_065_075_Index], np.array(Spec_Rest_SD)[Z_065_075_Index], np.array(Wave_Rest)[Z_065_075_Index]\n",
    "#Spec_Rest_075_085, Spec_Rest_SD_075_085, Wave_Rest_075_085 = np.array(Spec_Rest)[Z_075_085_Index], np.array(Spec_Rest_SD)[Z_075_085_Index], np.array(Wave_Rest)[Z_075_085_Index]\n",
    "#Spec_Rest_085_096, Spec_Rest_SD_085_096, Wave_Rest_085_096 = np.array(Spec_Rest)[Z_085_096_Index], np.array(Spec_Rest_SD)[Z_085_096_Index], np.array(Wave_Rest)[Z_085_096_Index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8716aa-e3cc-4935-b36c-8ea7d85ca832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Data slicing for each redshift bin\n",
    "redshift_data = {\n",
    "    '025_035': {\n",
    "        'spec': np.array(Spec_Rest)[Z_025_035_Index],\n",
    "        'spec_sd': np.array(Spec_Rest_SD)[Z_025_035_Index],\n",
    "        'wave': np.array(Wave_Rest)[Z_025_035_Index]\n",
    "    },\n",
    "    '035_045': {\n",
    "        'spec': np.array(Spec_Rest)[Z_035_045_Index],\n",
    "        'spec_sd': np.array(Spec_Rest_SD)[Z_035_045_Index],\n",
    "        'wave': np.array(Wave_Rest)[Z_035_045_Index]\n",
    "    },\n",
    "    '045_055': {\n",
    "        'spec': np.array(Spec_Rest)[Z_045_055_Index],\n",
    "        'spec_sd': np.array(Spec_Rest_SD)[Z_045_055_Index],\n",
    "        'wave': np.array(Wave_Rest)[Z_045_055_Index]\n",
    "    },\n",
    "    '055_065': {\n",
    "        'spec': np.array(Spec_Rest)[Z_055_065_Index],\n",
    "        'spec_sd': np.array(Spec_Rest_SD)[Z_055_065_Index],\n",
    "        'wave': np.array(Wave_Rest)[Z_055_065_Index]\n",
    "    },\n",
    "    '065_075': {\n",
    "        'spec': np.array(Spec_Rest)[Z_065_075_Index],\n",
    "        'spec_sd': np.array(Spec_Rest_SD)[Z_065_075_Index],\n",
    "        'wave': np.array(Wave_Rest)[Z_065_075_Index]\n",
    "    },\n",
    "    '075_085': {\n",
    "        'spec': np.array(Spec_Rest)[Z_075_085_Index],\n",
    "        'spec_sd': np.array(Spec_Rest_SD)[Z_075_085_Index],\n",
    "        'wave': np.array(Wave_Rest)[Z_075_085_Index]\n",
    "    },\n",
    "    '085_096': {\n",
    "        'spec': np.array(Spec_Rest)[Z_085_096_Index],\n",
    "        'spec_sd': np.array(Spec_Rest_SD)[Z_085_096_Index],\n",
    "        'wave': np.array(Wave_Rest)[Z_085_096_Index]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Histogram configuration\n",
    "bin_labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Calculate bin counts\n",
    "bin_counts = [len(redshift_data[key]['spec']) for key in redshift_data.keys()]\n",
    "\n",
    "# Color assignment for each bin\n",
    "bar_colors = [colors[key] for key in redshift_data.keys()]\n",
    "\n",
    "# Create figure with MNRAS specifications\n",
    "fig, ax = plt.subplots(figsize=(10, 6), facecolor='white')\n",
    "\n",
    "# Create histogram bars\n",
    "bars = ax.bar(\n",
    "    range(len(bin_labels)),\n",
    "    bin_counts,\n",
    "    color=bar_colors,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    "    alpha=0.8,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Redshift Bin\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Number of Sources\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Distribution of Sources Across Redshift Bins\", fontsize=14, pad=15)\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks(range(len(bin_labels)))\n",
    "ax.set_xticklabels(bin_labels, rotation=45, ha='right')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='y', \n",
    "        linestyle='--', alpha=0.7, zorder=1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Annotate bars with counts\n",
    "for i, (bar, count) in enumerate(zip(bars, bin_counts)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, \n",
    "            height + max(bin_counts) * 0.01, \n",
    "            f'{count}', \n",
    "            ha='center', \n",
    "            va='bottom', \n",
    "            fontsize=11,\n",
    "            fontweight='bold',\n",
    "            zorder=4)\n",
    "\n",
    "# Set y-axis limits with padding\n",
    "ax.set_ylim(0, max(bin_counts) * 1.15)\n",
    "\n",
    "# Add statistical information as text box\n",
    "total_sources = sum(bin_counts)\n",
    "stats_text = f'Total Sources: {total_sources}\\nMean per bin: {np.mean(bin_counts):.1f}\\nStd: {np.std(bin_counts):.1f}'\n",
    "\n",
    "ax.text(0.02, 0.98, stats_text,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', \n",
    "                  facecolor='white', \n",
    "                  edgecolor='black',\n",
    "                  alpha=0.9))\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"redshift_bin_histogram_MNRAS.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"redshift_bin_histogram_MNRAS.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3632aa4-b563-448e-a9ba-3f9bd0fe1d8a",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Getting the Continuums</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5647e-8ab3-401b-a94b-8e426e8c1525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c9e81-9f57-4e12-810d-5a8b91d6935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectrum_1D_Spectra_NonStacked_Array, Spectrum_1D_Continuum_NonStacked_Array, Spectrum_1D_Residuals_NonStacked_Array, Spectrum_1D_Continuum_SD_NonStacked_Array, Spectrum_1D_Fit_Metrics_NonStacked_Array = fit_continuum_with_metrics_for_unstacked(np.array(Wave_Rest),\n",
    "#                                                                                                                                                                                                                                      Spec_Rest,\n",
    "#                                                                                                                                                                                                                                      Spec_Rest_SD,\n",
    "#                                                                                                                                                                                                                                      scaling_factor=1e-16)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb92a97-ca3a-4185-9b10-0dced379fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The fit_continuum_with_metrics_for_unstacked :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Fit_Gen_Continuum_UnStacked.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spectrum_1D_Spectra_NonStacked_Array,\n",
    "     Spectrum_1D_Continuum_NonStacked_Array,\n",
    "     Spectrum_1D_Residuals_NonStacked_Array,\n",
    "     Spectrum_1D_Continuum_SD_NonStacked_Array,\n",
    "     Spectrum_1D_Fit_Metrics_NonStacked_Array) = fit_continuum_with_metrics_for_unstacked(\n",
    "        np.array(Wave_Rest),\n",
    "        Spec_Rest,\n",
    "        Spec_Rest_SD,\n",
    "        scaling_factor=1e-16,\n",
    "        n_bootstrap=500\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spectrum_1D_Spectra_NonStacked_Array)\n",
    "    continuum_flux = convert_to_fits_compatible(Spectrum_1D_Continuum_NonStacked_Array)\n",
    "    residuals_flux = convert_to_fits_compatible(Spectrum_1D_Residuals_NonStacked_Array)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Spectrum_1D_Continuum_SD_NonStacked_Array)\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Spectrum_1D_Fit_Metrics_NonStacked_Array)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spectrum_1D_Spectra_NonStacked_Array = table[\"Spectra\"]\n",
    "    Spectrum_1D_Continuum_NonStacked_Array = table[\"Continuum\"]\n",
    "    Spectrum_1D_Residuals_NonStacked_Array = table[\"Residuals\"]\n",
    "    Spectrum_1D_Continuum_SD_NonStacked_Array = table[\"Continuum_SD\"]\n",
    "    Spectrum_1D_Fit_Metrics_NonStacked_Array = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7af7b-03e2-480a-827c-a9d4487036bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The fit_continuum_with_metrics_for_stacked :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Fit_Gen_Continuum_Stacked.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "  # Run the fitting\n",
    "    (Spectrum_1D_Spectra_Stacked_Array,\n",
    "    Spectrum_1D_Continuum_Stacked_Array,\n",
    "    Spectrum_1D_Residuals_Stacked_Array,\n",
    "    Spectrum_1D_Continuum_SD_Stacked_Array,\n",
    "    Spectrum_1D_Fit_Metrics_Stacked_Array) = fit_continuum_with_metrics_for_stacked(\n",
    "        np.array(Stack_Wave),\n",
    "        Stack_Spec,\n",
    "        Stack_Spec_SD,\n",
    "        scaling_factor=1e-16\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spectrum_1D_Spectra_Stacked_Array)\n",
    "    continuum_flux = convert_to_fits_compatible(Spectrum_1D_Continuum_Stacked_Array)\n",
    "    residuals_flux = convert_to_fits_compatible(Spectrum_1D_Residuals_Stacked_Array)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Spectrum_1D_Continuum_SD_Stacked_Array)\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Spectrum_1D_Fit_Metrics_Stacked_Array)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spectrum_1D_Spectra_Stacked_Array = table[\"Spectra\"]\n",
    "    Spectrum_1D_Continuum_Stacked_Array = table[\"Continuum\"]\n",
    "    Spectrum_1D_Residuals_Stacked_Array = table[\"Residuals\"]\n",
    "    Spectrum_1D_Continuum_SD_Stacked_Array = table[\"Continuum_SD\"]\n",
    "    Spectrum_1D_Fit_Metrics_Stacked_Array = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb8450-5c34-44e8-8927-1d9ba84c616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "'''colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    " '''   \n",
    "# Just checking the spectra and continuum fits to make sure the fit_continuum_with_metrics_for... worked the right way.\n",
    "print(Spectrum_1D_Continuum_NonStacked_Array[0], Spectrum_1D_Continuum_SD_NonStacked_Array[0])\n",
    "\n",
    "# Create figure with MNRAS-compliant dimensions and styling\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7), facecolor='white')\n",
    "\n",
    "# Plot spectrum with uncertainty band\n",
    "spectrum_line = ax.plot(Wave_Rest[0], Spec_Rest[0], \n",
    "                       color='#60B5FF', linewidth=2.0, \n",
    "                       label='Spectrum', zorder=5)\n",
    "\n",
    "spectrum_fill = ax.fill_between(Wave_Rest[0], \n",
    "                               Spec_Rest[0] - Spec_Rest_SD[0], \n",
    "                               Spec_Rest[0] + Spec_Rest_SD[0], \n",
    "                               color=\"#60B5FF\", alpha=0.3, \n",
    "                               label=r'Spectrum $\\pm 1\\sigma$', zorder=1)\n",
    "\n",
    "# Plot continuum fit with uncertainty band\n",
    "continuum_line = ax.plot(Wave_Rest[0], Spectrum_1D_Continuum_NonStacked_Array[0], \n",
    "                        color=\"#ffbb14\", linewidth=2.0, \n",
    "                        label='Continuum Fit', zorder=4)\n",
    "\n",
    "continuum_fill = ax.fill_between(Wave_Rest[0], \n",
    "                                Spectrum_1D_Continuum_NonStacked_Array[0] - Spectrum_1D_Continuum_SD_NonStacked_Array[0], \n",
    "                                Spectrum_1D_Continuum_NonStacked_Array[0] + Spectrum_1D_Continuum_SD_NonStacked_Array[0], \n",
    "                                color=\"#ffbb14\", alpha=0.3, \n",
    "                                label=r'Continuum $\\pm 1\\sigma$', zorder=3)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Rest Wavelength [\\AA]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Flux Density\", fontsize=14, color=\"black\")  # Adjust units as needed\n",
    "ax.set_title(\"Spectrum and Continuum Fit Validation\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='best',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"Spectrum_Continuum_Validation_MNRAS.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"Spectrum_Continuum_Validation_MNRAS.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e6908-ce34-495f-86b6-ca7bd85d5ef7",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Scaling the Continuums</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de362d1b-bdbe-4587-ac15-0cce96300272",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This gets the stack wavelength to match each \n",
    "of the rest wavelength for the individual spectra\n",
    "\"\"\"\n",
    "Index_to_Normalize_Array = []\n",
    "\n",
    "for i in np.arange(len(Wave_Rest)):\n",
    "    Index_to_Normalize_Array.append(np.where(np.logical_and(Stack_Wave > min(Wave_Rest[i]), Stack_Wave < max(Wave_Rest[i])))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9fc85-0593-4f69-96b5-ad7330b9e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The continuum for the stacked array and the individual spectra and matched them.\n",
    "The dif scales up the individual spectra to match the level of the stacked spectra.\n",
    "\"\"\"\n",
    "\n",
    "New_Y_For_NonStacked_Array = []\n",
    "New_Y_StdDev_For_NonStacked_Array = []  # New array to store propagated standard deviations\n",
    "\n",
    "for i in np.arange(len(Spectrum_1D_Spectra_NonStacked_Array)):    \n",
    "    \n",
    "    # Calculate average values for scaling\n",
    "    a_y_stack = np.average(Spectrum_1D_Continuum_Stacked_Array[0])  # The stacked continuum\n",
    "    a_y_indiv = np.average(Spectrum_1D_Continuum_NonStacked_Array[i])  # The unstacked continuums\n",
    "    dif = np.subtract(a_y_stack, a_y_indiv)  # Stacked continuum - unstacked continuums\n",
    "    \n",
    "    # Apply scaling to the original unstacked spectra\n",
    "    New_Y_For_NonStacked_Array.append(Spec_Rest[i] + dif)\n",
    "    \n",
    "    # Propagate standard deviations\n",
    "    # Assuming Spec_Rest_StdDev and Stacked_StdDev are your input standard deviations\n",
    "    # For addition/subtraction, errors add in quadrature\n",
    "    stack_std = Stack_Spec_SD[0]  # Standard deviation of stacked spectra\n",
    "    indiv_std = Spec_Rest_SD[i]  # Standard deviation of individual spectra\n",
    "    \n",
    "    # Propagate error (when adding/subtracting values, add errors in quadrature)\n",
    "    propagated_std = np.sqrt(stack_std**2 + indiv_std**2)\n",
    "    \n",
    "    # Store the propagated standard deviation\n",
    "    New_Y_StdDev_For_NonStacked_Array.append(propagated_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef7911-436b-4bc6-915a-b783de449260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a0282-b3f0-4469-9227-0de92c14d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Checking to make sure the scaling (New_Y_For_NonStacked_Array) worked.\n",
    "num = 26\n",
    "\n",
    "# Create figure with MNRAS-compliant dimensions and styling\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7), facecolor='white')\n",
    "\n",
    "# Color scheme from the first code (using complementary colors)\n",
    "colors = {\n",
    "    'scaled': \"#a714ff\",    # Purple (deep/cool)\n",
    "    'stacked': \"#14D8FF\",   # Teal\n",
    "    'original': \"#60B5FF\"   # Blue\n",
    "}\n",
    "\n",
    "# Plot the three spectra with MNRAS styling\n",
    "scaled_line = ax.plot(Wave_Rest[num], New_Y_For_NonStacked_Array[num], \n",
    "                     color=colors['scaled'], linewidth=2.0, \n",
    "                     label=\"Scaled\", zorder=5)\n",
    "\n",
    "stacked_line = ax.plot(Stack_Wave[Index_to_Normalize_Array[num]], Stack_Spec[Index_to_Normalize_Array[num]], \n",
    "                      color=colors['stacked'], linewidth=2.0, \n",
    "                      label=\"Stacked\", zorder=4)\n",
    "\n",
    "original_line = ax.plot(Wave_Rest[num], Spec_Rest[num], \n",
    "                       color=colors['original'], linewidth=2.0, \n",
    "                       label=\"Original\", zorder=3)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Rest Wavelength [\\AA]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Flux [erg \\AA$^{-1}$ s$^{-1}$ cm$^{-2}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Scaling Validation: Comparison of Original, Scaled, and Stacked Spectra\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='best',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"Scaling_Validation_MNRAS.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"Scaling_Validation_MNRAS.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ff4f3-6b3c-46e6-b017-08ca88d508ad",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >ReStacking the individual spectra. But, with the scaled spectra that now match the old stacked specta</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ad1f1-f458-4d4a-9fa9-ad9449c4db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Restacking the now scaled original specta.\n",
    "New_Y_For_NonStacked_Array = the scaled version of the Spec_Rest\n",
    "The Spec_Rest_SD doesn't need to be scaled with the Spec_Rest\n",
    "\"\"\"\n",
    "avg_type = 'biweight' #'weighted_biweight', 'mean', 'median'\n",
    "ReStacked_Spec_Continuum_Scaled, ReStacked_Spec_SD_Continuum_Scaled, ReStacked_Wave_Continuum_Scaled, ReStacked_Contrib_Count_Continuum_Scaled, ReStack_Spec_SD = ESU.stack_spectra(New_Y_For_NonStacked_Array, New_Y_StdDev_For_NonStacked_Array, Wave_Rest, \n",
    "                                                                                                                                                                                    avg_type=avg_type, std=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c661c-36d9-4579-bf67-8eebeb59be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Checking that restacking of the scaled individual spectra worked.\n",
    "\n",
    "# Create figure with MNRAS-compliant dimensions and styling\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7), facecolor='white')\n",
    "\n",
    "# Color scheme from the first code for spectra\n",
    "spectrum_colors = {\n",
    "    'restacked': \"#a714ff\",    # Purple (deep/cool)\n",
    "    'original': \"#FF5757\"      # Red (warm)\n",
    "}\n",
    "\n",
    "# Plot the stacked spectra with MNRAS styling\n",
    "restacked_line = ax.step(ReStacked_Wave_Continuum_Scaled, ReStacked_Spec_Continuum_Scaled, \n",
    "                        color=spectrum_colors['restacked'], linewidth=2.0, \n",
    "                        label=\"ReStacked\", zorder=5, where='mid')\n",
    "\n",
    "original_line = ax.step(Stack_Wave, Stack_Spec, \n",
    "                       color=spectrum_colors['original'], linewidth=2.0, \n",
    "                       label=\"Original Stacked\", zorder=4, where='mid')\n",
    "\n",
    "# Emission line markers with organized colors and improved styling\n",
    "line_properties = [\n",
    "    (1892.030, 'limegreen', '-.', r'SiIII'),\n",
    "    (1908.734, '#ffbb14', '--', r'CIII'),  # Orange from color scheme\n",
    "    (2799, 'black', '--', r'MgII'),\n",
    "    (2320.951, '#FF5757', ':', r'OIII'),  # Red from color scheme\n",
    "    (2142.780, '#00FF9C', '-.', r'NII'),  # Green from color scheme\n",
    "    (3132.794, '#ff14f5', ':', r'OIII'),  # Pink from color scheme\n",
    "    (2945.106, '#14D8FF', '--', r'HeI')   # Teal from color scheme\n",
    "]\n",
    "\n",
    "# Add emission line markers\n",
    "for wavelength, color, linestyle, label in line_properties:\n",
    "    ax.axvline(x=wavelength, color=color, linestyle=linestyle, \n",
    "              linewidth=2.0, alpha=0.8, label=label, zorder=3)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Rest Wavelength [\\AA]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Flux [erg \\AA$^{-1}$ s$^{-1}$ cm$^{-2}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Restacking Validation: Comparison of Original and ReStacked Spectra\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style - split into two columns for better organization\n",
    "legend = ax.legend(\n",
    "    loc='upper right',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.5,\n",
    "    labelspacing=0.8,\n",
    "    numpoints=1,\n",
    "    ncol=2\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"Restacking_Validation_MNRAS.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"Restacking_Validation_MNRAS.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ff059-f166-487b-9356-5a8910eedf59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c8aa1-e962-41a6-b1f1-ff24f888bd41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be95223e-6822-41b9-a021-4d4deb865325",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Takeing the Scaled spectra and dividing them up into the redshift bins</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416bff1-8853-4cc7-b4ac-80157a7283b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bffb67-35e7-45e8-a6bf-e1bead3aaa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dividing up the continuum scaled (to match the original stack), New_Y_For_SonStacked_Array, into the redshift bins.\n",
    "\"\"\"\n",
    "Spec_Rest_Continuum_Scaled_025_035, Spec_Rest_SD_Continuum_Scaled_025_035, Waves_Rest_Continuum_Scaled_025_035 = np.array(New_Y_For_NonStacked_Array)[Z_025_035_Index], np.array(New_Y_StdDev_For_NonStacked_Array)[Z_025_035_Index], np.array(Wave_Rest)[Z_025_035_Index]\n",
    "Spec_Rest_Continuum_Scaled_035_045, Spec_Rest_SD_Continuum_Scaled_035_045, Waves_Rest_Continuum_Scaled_035_045 = np.array(New_Y_For_NonStacked_Array)[Z_035_045_Index], np.array(New_Y_StdDev_For_NonStacked_Array)[Z_035_045_Index], np.array(Wave_Rest)[Z_035_045_Index]\n",
    "Spec_Rest_Continuum_Scaled_045_055, Spec_Rest_SD_Continuum_Scaled_045_055, Waves_Rest_Continuum_Scaled_045_055 = np.array(New_Y_For_NonStacked_Array)[Z_045_055_Index], np.array(New_Y_StdDev_For_NonStacked_Array)[Z_045_055_Index], np.array(Wave_Rest)[Z_045_055_Index]\n",
    "Spec_Rest_Continuum_Scaled_055_065, Spec_Rest_SD_Continuum_Scaled_055_065, Waves_Rest_Continuum_Scaled_055_065 = np.array(New_Y_For_NonStacked_Array)[Z_055_065_Index], np.array(New_Y_StdDev_For_NonStacked_Array)[Z_055_065_Index], np.array(Wave_Rest)[Z_055_065_Index]\n",
    "Spec_Rest_Continuum_Scaled_065_075, Spec_Rest_SD_Continuum_Scaled_065_075, Waves_Rest_Continuum_Scaled_065_075 = np.array(New_Y_For_NonStacked_Array)[Z_065_075_Index], np.array(New_Y_StdDev_For_NonStacked_Array)[Z_065_075_Index], np.array(Wave_Rest)[Z_065_075_Index]\n",
    "Spec_Rest_Continuum_Scaled_075_085, Spec_Rest_SD_Continuum_Scaled_075_085, Waves_Rest_Continuum_Scaled_075_085 = np.array(New_Y_For_NonStacked_Array)[Z_075_085_Index], np.array(New_Y_StdDev_For_NonStacked_Array)[Z_075_085_Index], np.array(Wave_Rest)[Z_075_085_Index]\n",
    "Spec_Rest_Continuum_Scaled_085_096, Spec_Rest_SD_Continuum_Scaled_085_096, Waves_Rest_Continuum_Scaled_085_096 = np.array(New_Y_For_NonStacked_Array)[Z_085_096_Index], np.array(New_Y_StdDev_For_NonStacked_Array)[Z_085_096_Index], np.array(Wave_Rest)[Z_085_096_Index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3817d0d6-37c8-455a-aa6e-e4a901f80495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stacking the continuum scaled individual spectra into the seven different redshift bins.\n",
    "\"\"\"\n",
    "avg_type = 'biweight' #'weighted_biweight', 'mean', 'median'\n",
    "\n",
    "\n",
    "ReStacked_Spec_Continuum_Scaled_025_035, ReStacked_Spec_SD_Continuum_Scaled_025_035, ReStacked_Wave_Continuum_Scaled_025_035, ReStacked_Contrib_Count_Continuum_Scaled_025_035 = ESU.stack_spectra(Spec_Rest_Continuum_Scaled_025_035, \n",
    "                                                                                                                                                                                                    Spec_Rest_SD_Continuum_Scaled_025_035, \n",
    "                                                                                                                                                                                                    Waves_Rest_Continuum_Scaled_025_035, avg_type=avg_type)\n",
    "\n",
    "ReStacked_Spec_Continuum_Scaled_035_045, ReStacked_Spec_SD_Continuum_Scaled_035_045, ReStacked_Wave_Continuum_Scaled_035_045, ReStacked_Contrib_Count_Continuum_Scaled_035_045 = ESU.stack_spectra(Spec_Rest_Continuum_Scaled_035_045, \n",
    "                                                                                                                                                                                                    Spec_Rest_SD_Continuum_Scaled_035_045, \n",
    "                                                                                                                                                                                                    Waves_Rest_Continuum_Scaled_035_045, avg_type=avg_type)\n",
    "\n",
    "ReStacked_Spec_Continuum_Scaled_045_055, ReStacked_Spec_SD_Continuum_Scaled_045_055, ReStacked_Wave_Continuum_Scaled_045_055, ReStacked_Contrib_Count_Continuum_Scaled_045_055 = ESU.stack_spectra(Spec_Rest_Continuum_Scaled_045_055, \n",
    "                                                                                                                                                                                                    Spec_Rest_SD_Continuum_Scaled_045_055, \n",
    "                                                                                                                                                                                                    Waves_Rest_Continuum_Scaled_045_055, avg_type=avg_type)\n",
    "\n",
    "ReStacked_Spec_Continuum_Scaled_055_065, ReStacked_Spec_SD_Continuum_Scaled_055_065, ReStacked_Wave_Continuum_Scaled_055_065, ReStacked_Contrib_Count_Continuum_Scaled_055_065 = ESU.stack_spectra(Spec_Rest_Continuum_Scaled_055_065, \n",
    "                                                                                                                                                                                                    Spec_Rest_SD_Continuum_Scaled_055_065, \n",
    "                                                                                                                                                                                                    Waves_Rest_Continuum_Scaled_055_065, avg_type=avg_type)\n",
    "\n",
    "ReStacked_Spec_Continuum_Scaled_065_075, ReStacked_Spec_SD_Continuum_Scaled_065_075, ReStacked_Wave_Continuum_Scaled_065_075, ReStacked_Contrib_Count_Continuum_Scaled_065_075 = ESU.stack_spectra(Spec_Rest_Continuum_Scaled_065_075, \n",
    "                                                                                                                                                                                                    Spec_Rest_SD_Continuum_Scaled_065_075, \n",
    "                                                                                                                                                                                                    Waves_Rest_Continuum_Scaled_065_075, avg_type=avg_type)\n",
    "\n",
    "ReStacked_Spec_Continuum_Scaled_075_085, ReStacked_Spec_SD_Continuum_Scaled_075_085, ReStacked_Wave_Continuum_Scaled_075_085, ReStacked_Contrib_Count_Continuum_Scaled_075_085 = ESU.stack_spectra(Spec_Rest_Continuum_Scaled_075_085, \n",
    "                                                                                                                                                                                                    Spec_Rest_SD_Continuum_Scaled_075_085, \n",
    "                                                                                                                                                                                                    Waves_Rest_Continuum_Scaled_075_085, avg_type=avg_type)\n",
    "\n",
    "ReStacked_Spec_Continuum_Scaled_085_096, ReStacked_Spec_SD_Continuum_Scaled_085_096, ReStacked_Wave_Continuum_Scaled_085_096, ReStacked_Contrib_Count_Continuum_Scaled_085_096 = ESU.stack_spectra(Spec_Rest_Continuum_Scaled_085_096, \n",
    "                                                                                                                                                                                                    Spec_Rest_SD_Continuum_Scaled_085_096, \n",
    "                                                                                                                                                                                                    Waves_Rest_Continuum_Scaled_085_096, avg_type=avg_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041ed70-b9c5-4c8a-b5ec-e845f900ab65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e7ca4-5840-4510-a90e-aae61e60fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Checking the ReStacked and binned (into redshift ranges) spectra.\n",
    "\n",
    "# Create figure with MNRAS-compliant dimensions and styling\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7), facecolor='white')\n",
    "\n",
    "# Color scheme from the first code - organized by redshift bins\n",
    "redshift_colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Uncertainty band colors (lighter versions)\n",
    "uncertainty_colors = {\n",
    "    '025_035': \"#d4a7ff\",  # Light purple\n",
    "    '035_045': \"#ff87f8\",  # Light pink\n",
    "    '045_055': \"#87ebff\",  # Light teal\n",
    "    '055_065': \"#b3d5ff\",  # Light blue\n",
    "    '065_075': \"#80ffce\",  # Light green\n",
    "    '075_085': \"#ffdd87\",  # Light orange\n",
    "    '085_096': \"#ff9999\"   # Light red\n",
    "}\n",
    "\n",
    "# Redshift bin labels\n",
    "redshift_labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting\n",
    "datasets = [\n",
    "    ('025_035', ReStacked_Wave_Continuum_Scaled_025_035, ReStacked_Spec_Continuum_Scaled_025_035, ReStacked_Spec_SD_Continuum_Scaled_025_035),\n",
    "    ('035_045', ReStacked_Wave_Continuum_Scaled_035_045, ReStacked_Spec_Continuum_Scaled_035_045, ReStacked_Spec_SD_Continuum_Scaled_035_045),\n",
    "    ('045_055', ReStacked_Wave_Continuum_Scaled_045_055, ReStacked_Spec_Continuum_Scaled_045_055, ReStacked_Spec_SD_Continuum_Scaled_045_055),\n",
    "    ('055_065', ReStacked_Wave_Continuum_Scaled_055_065, ReStacked_Spec_Continuum_Scaled_055_065, ReStacked_Spec_SD_Continuum_Scaled_055_065),\n",
    "    ('065_075', ReStacked_Wave_Continuum_Scaled_065_075, ReStacked_Spec_Continuum_Scaled_065_075, ReStacked_Spec_SD_Continuum_Scaled_065_075),\n",
    "    ('075_085', ReStacked_Wave_Continuum_Scaled_075_085, ReStacked_Spec_Continuum_Scaled_075_085, ReStacked_Spec_SD_Continuum_Scaled_075_085),\n",
    "    ('085_096', ReStacked_Wave_Continuum_Scaled_085_096, ReStacked_Spec_Continuum_Scaled_085_096, ReStacked_Spec_SD_Continuum_Scaled_085_096)\n",
    "]\n",
    "\n",
    "# Plot each redshift bin\n",
    "for i, (key, wave, spec, spec_sd) in enumerate(datasets):\n",
    "    # Plot uncertainty bands\n",
    "    ax.fill_between(wave, spec - spec_sd, spec + spec_sd, \n",
    "                   color=uncertainty_colors[key], alpha=0.4, \n",
    "                   zorder=i, label=f'{redshift_labels[i]} $\\pm 1\\sigma$')\n",
    "    \n",
    "    # Plot spectra\n",
    "    ax.step(wave, spec, color=redshift_colors[key], linewidth=2.0, \n",
    "           label=redshift_labels[i], zorder=i+10, where='mid')\n",
    "\n",
    "# Emission line markers with organized colors and improved styling\n",
    "line_properties = [\n",
    "    (1892.030, 'limegreen', '-.', r'Si\\,{\\sc iii}', 2.0),\n",
    "    (1908.734, 'darkorange', '--', r'C\\,{\\sc iii}', 2.0),\n",
    "    (2799, 'black', '--', r'Mg\\,{\\sc ii}', 2.5),  # Thicker for prominence\n",
    "    (2320.951, 'darkred', ':', r'O\\,{\\sc iii}', 2.0),\n",
    "    (2142.780, 'darkgoldenrod', '-.', r'N\\,{\\sc ii}', 2.0),\n",
    "    (3132.794, 'darkred', ':', r'O\\,{\\sc iii}', 2.0),\n",
    "    (2945.106, 'darkgreen', '--', r'He\\,{\\sc i}', 2.0)\n",
    "]\n",
    "\n",
    "# Add emission line markers\n",
    "for wavelength, color, linestyle, label, linewidth in line_properties:\n",
    "    ax.axvline(x=wavelength, color=color, linestyle=linestyle, \n",
    "              linewidth=linewidth, alpha=0.8, label=label, zorder=20)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Rest Wavelength [\\AA]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Flux [erg s$^{-1}$ cm$^{-2}$ \\AA$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(r\"Redshift-Binned Stacked Spectra: $0.25 \\leq z \\leq 0.96$\", fontsize=14, pad=15)\n",
    "\n",
    "# Set axis limits\n",
    "ax.set_ylim(0.25e-16, 4.0e-16)\n",
    "\n",
    "# Configure legend with MNRAS style - organized in multiple columns\n",
    "legend = ax.legend(\n",
    "    loc='upper right',\n",
    "    fontsize=9,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.6,\n",
    "    handletextpad=0.4,\n",
    "    columnspacing=0.8,\n",
    "    handlelength=1.2,\n",
    "    labelspacing=0.5,\n",
    "    numpoints=1,\n",
    "    ncol=3,\n",
    "    bbox_to_anchor=(1.0, 1.0)\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"Redshift_Binned_Spectra_MNRAS.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"Redshift_Binned_Spectra_MNRAS.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a07b9a-c1b9-4576-ba8d-afe2486ad793",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Cutting out the continuum (aka lowering them down to zero) of the restacked spectra</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f54977-03db-4165-84ed-8f0417f13bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the continuum on the left side of the MgII emission\n",
    "\"\"\"\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_025_035_Left = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2500, 2700, ReStacked_Spec_Continuum_Scaled_025_035)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_025_035_Left = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2500, 2700, ReStacked_Spec_Continuum_Scaled_025_035)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_035_045_Left = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2500, 2700, ReStacked_Spec_Continuum_Scaled_035_045)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_035_045_Left = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2500, 2700, ReStacked_Spec_Continuum_Scaled_035_045)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_045_055_Left = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2500, 2700, ReStacked_Spec_Continuum_Scaled_045_055)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_045_055_Left = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2500, 2700, ReStacked_Spec_Continuum_Scaled_045_055)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_055_065_Left = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2500, 2700, ReStacked_Spec_Continuum_Scaled_055_065)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_055_065_Left = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2500, 2700, ReStacked_Spec_Continuum_Scaled_055_065)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_065_075_Left = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2500, 2700, ReStacked_Spec_Continuum_Scaled_065_075)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_065_075_Left = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2500, 2700, ReStacked_Spec_Continuum_Scaled_065_075)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_075_085_Left = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2500, 2700, ReStacked_Spec_Continuum_Scaled_075_085)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_075_085_Left = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2500, 2700, ReStacked_Spec_Continuum_Scaled_075_085)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_085_096_Left = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2300, 2700, ReStacked_Spec_Continuum_Scaled_085_096)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_085_096_Left = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2300, 2700, ReStacked_Spec_Continuum_Scaled_085_096)[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_025_035_Left = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_025_035)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_025_035_Left = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_025_035)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_035_045_Left = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_035_045)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_035_045_Left = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_035_045)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_045_055_Left = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_045_055)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_045_055_Left = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_045_055)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_055_065_Left = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_055_065)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_055_065_Left = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_055_065)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_065_075_Left = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_065_075)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_065_075_Left = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_065_075)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_075_085_Left = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_075_085)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_075_085_Left = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2500, 2700, ReStacked_Spec_SD_Continuum_Scaled_075_085)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_085_096_Left = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2300, 2700, ReStacked_Spec_SD_Continuum_Scaled_085_096)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_085_096_Left = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2300, 2700, ReStacked_Spec_SD_Continuum_Scaled_085_096)[1]\n",
    "\n",
    "\n",
    "print(ReStacked_Spec_Continuum_Scaled_025_035[0:3])\n",
    "print(ReStacked_Spec_SD_Continuum_Scaled_025_035[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538899d-404a-43bd-8aae-3746f1309a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the continuum on the right side of the MgII emission\n",
    "\"\"\"\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_025_035_Right = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2900, 3100, ReStacked_Spec_Continuum_Scaled_025_035)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_025_035_Right = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2900, 3100, ReStacked_Spec_Continuum_Scaled_025_035)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_035_045_Right = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2900, 3100, ReStacked_Spec_Continuum_Scaled_035_045)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_035_045_Right = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2900, 3100, ReStacked_Spec_Continuum_Scaled_035_045)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_045_055_Right = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2900, 3100, ReStacked_Spec_Continuum_Scaled_045_055)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_045_055_Right = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2900, 3100, ReStacked_Spec_Continuum_Scaled_045_055)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_055_065_Right = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2900, 3100, ReStacked_Spec_Continuum_Scaled_055_065)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_055_065_Right = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2900, 3100, ReStacked_Spec_Continuum_Scaled_055_065)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_065_075_Right = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2900, 3100, ReStacked_Spec_Continuum_Scaled_065_075)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_065_075_Right = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2900, 3100, ReStacked_Spec_Continuum_Scaled_065_075)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_075_085_Right = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2900, 3100, ReStacked_Spec_Continuum_Scaled_075_085)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_075_085_Right = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2900, 3100, ReStacked_Spec_Continuum_Scaled_075_085)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_085_096_Right = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2900, 2990, ReStacked_Spec_Continuum_Scaled_085_096)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_085_096_Right = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2900, 2990, ReStacked_Spec_Continuum_Scaled_085_096)[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_025_035_Right = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_025_035)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_025_035_Right = continuum(ReStacked_Wave_Continuum_Scaled_025_035, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_025_035)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_035_045_Right = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_035_045)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_035_045_Right = continuum(ReStacked_Wave_Continuum_Scaled_035_045, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_035_045)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_045_055_Right = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_045_055)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_045_055_Right = continuum(ReStacked_Wave_Continuum_Scaled_045_055, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_045_055)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_055_065_Right = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_055_065)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_055_065_Right = continuum(ReStacked_Wave_Continuum_Scaled_055_065, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_055_065)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_065_075_Right = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_065_075)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_065_075_Right = continuum(ReStacked_Wave_Continuum_Scaled_065_075, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_065_075)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_075_085_Right = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_075_085)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_075_085_Right = continuum(ReStacked_Wave_Continuum_Scaled_075_085, 2900, 3100, ReStacked_Spec_SD_Continuum_Scaled_075_085)[1]\n",
    "\n",
    "MgII_Continuum_ReStacked_Wave_Continuum_Scaled_SD_085_096_Right = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2300, 2700, ReStacked_Spec_SD_Continuum_Scaled_085_096)[0]\n",
    "MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_085_096_Right = continuum(ReStacked_Wave_Continuum_Scaled_085_096, 2300, 2700, ReStacked_Spec_SD_Continuum_Scaled_085_096)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ae7d0-89a7-48ec-abb6-67d19fbc85f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa4af5-0562-4b7c-b13f-99d4f7f81095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567319a6-69a0-41dd-8590-66108a76ae40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a978dee-8ba0-48a3-9f5d-10ae2999b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting just the MgII emission for each of the ReStacked Spectra for each of the redshift ranges.\n",
    "\"\"\"\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_025_035 = ReStacked_Spec_Continuum_Scaled_025_035[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_025_035 >2500, ReStacked_Wave_Continuum_Scaled_025_035 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_035_045 = ReStacked_Spec_Continuum_Scaled_035_045[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_035_045 >2500, ReStacked_Wave_Continuum_Scaled_035_045 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_045_055 = ReStacked_Spec_Continuum_Scaled_045_055[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_045_055 >2500, ReStacked_Wave_Continuum_Scaled_045_055 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_055_065 = ReStacked_Spec_Continuum_Scaled_055_065[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_055_065 >2500, ReStacked_Wave_Continuum_Scaled_055_065 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_065_075 = ReStacked_Spec_Continuum_Scaled_065_075[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_065_075 >2500, ReStacked_Wave_Continuum_Scaled_065_075 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_075_085 = ReStacked_Spec_Continuum_Scaled_075_085[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_075_085 >2500, ReStacked_Wave_Continuum_Scaled_075_085 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_085_096 = ReStacked_Spec_Continuum_Scaled_085_096[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_085_096 >2300, ReStacked_Wave_Continuum_Scaled_085_096 < 2990))[0]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_SD_025_035 = ReStacked_Spec_SD_Continuum_Scaled_025_035[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_025_035 >2500, ReStacked_Wave_Continuum_Scaled_025_035 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_SD_035_045 = ReStacked_Spec_SD_Continuum_Scaled_035_045[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_035_045 >2500, ReStacked_Wave_Continuum_Scaled_035_045 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_SD_045_055 = ReStacked_Spec_SD_Continuum_Scaled_045_055[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_045_055 >2500, ReStacked_Wave_Continuum_Scaled_045_055 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_SD_055_065 = ReStacked_Spec_SD_Continuum_Scaled_055_065[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_055_065 >2500, ReStacked_Wave_Continuum_Scaled_055_065 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_SD_065_075 = ReStacked_Spec_SD_Continuum_Scaled_065_075[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_065_075 >2500, ReStacked_Wave_Continuum_Scaled_065_075 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_SD_075_085 = ReStacked_Spec_SD_Continuum_Scaled_075_085[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_075_085 >2500, ReStacked_Wave_Continuum_Scaled_075_085 < 3100))[0]]\n",
    "MgII_ReStacked_Spec_Continuum_Scaled_SD_085_096 = ReStacked_Spec_SD_Continuum_Scaled_085_096[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_085_096 >2300, ReStacked_Wave_Continuum_Scaled_085_096 < 2990))[0]]\n",
    "\n",
    "\n",
    "print(len(MgII_ReStacked_Spec_Continuum_Scaled_025_035))\n",
    "print(\"\")\n",
    "print(len(MgII_ReStacked_Spec_Continuum_Scaled_SD_025_035))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd65f6-5f3a-4cc7-b96f-1cbf02d0eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting just the MgII Wavelength for each of the ReStacked Spectra for each of the redshift ranges.\n",
    "\"\"\"\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_025_035 = ReStacked_Wave_Continuum_Scaled_025_035[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_025_035 >2500, ReStacked_Wave_Continuum_Scaled_025_035 < 3100))[0]]\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_035_045 = ReStacked_Wave_Continuum_Scaled_035_045[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_035_045 >2500, ReStacked_Wave_Continuum_Scaled_035_045 < 3100))[0]]\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_045_055 = ReStacked_Wave_Continuum_Scaled_045_055[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_045_055 >2500, ReStacked_Wave_Continuum_Scaled_045_055 < 3100))[0]]\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_055_065 = ReStacked_Wave_Continuum_Scaled_055_065[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_055_065 >2500, ReStacked_Wave_Continuum_Scaled_055_065 < 3100))[0]]\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_065_075 = ReStacked_Wave_Continuum_Scaled_065_075[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_065_075 >2500, ReStacked_Wave_Continuum_Scaled_065_075 < 3100))[0]]\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_075_085 = ReStacked_Wave_Continuum_Scaled_075_085[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_075_085 >2500, ReStacked_Wave_Continuum_Scaled_075_085 < 3100))[0]]\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_085_096 = ReStacked_Wave_Continuum_Scaled_085_096[np.where(np.logical_and(ReStacked_Wave_Continuum_Scaled_085_096 >2300, ReStacked_Wave_Continuum_Scaled_085_096 < 2990))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8241e75-fbab-4140-85b4-a5d583903e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcbf63-cff5-4e02-b50b-4e515238bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining the Left and Right side of the MgII emission continuums.\n",
    "\"\"\"\n",
    "MgII_LR_ReStacked_Wave_Continuum_Scaled_025_035 = np.concatenate((MgII_Continuum_ReStacked_Wave_Continuum_Scaled_025_035_Left, MgII_Continuum_ReStacked_Wave_Continuum_Scaled_025_035_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_025_035_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_025_035_Right))\n",
    "\n",
    "MgII_LR_ReStacked_Wave_Continuum_Scaled_035_045 = np.concatenate((MgII_Continuum_ReStacked_Wave_Continuum_Scaled_035_045_Left, MgII_Continuum_ReStacked_Wave_Continuum_Scaled_035_045_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_035_045 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_035_045_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_035_045_Right))\n",
    "\n",
    "MgII_LR_ReStacked_Wave_Continuum_Scaled_045_055 = np.concatenate((MgII_Continuum_ReStacked_Wave_Continuum_Scaled_045_055_Left, MgII_Continuum_ReStacked_Wave_Continuum_Scaled_045_055_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_045_055 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_045_055_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_045_055_Right))\n",
    "\n",
    "MgII_LR_ReStacked_Wave_Continuum_Scaled_055_065 = np.concatenate((MgII_Continuum_ReStacked_Wave_Continuum_Scaled_055_065_Left, MgII_Continuum_ReStacked_Wave_Continuum_Scaled_055_065_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_055_065 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_055_065_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_055_065_Right))\n",
    "\n",
    "MgII_LR_ReStacked_Wave_Continuum_Scaled_065_075 = np.concatenate((MgII_Continuum_ReStacked_Wave_Continuum_Scaled_065_075_Left, MgII_Continuum_ReStacked_Wave_Continuum_Scaled_065_075_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_065_075 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_065_075_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_065_075_Right))\n",
    "\n",
    "MgII_LR_ReStacked_Wave_Continuum_Scaled_075_085 = np.concatenate((MgII_Continuum_ReStacked_Wave_Continuum_Scaled_075_085_Left, MgII_Continuum_ReStacked_Wave_Continuum_Scaled_075_085_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_075_085 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_075_085_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_075_085_Right))\n",
    "\n",
    "MgII_LR_ReStacked_Wave_Continuum_Scaled_085_096 = np.concatenate((MgII_Continuum_ReStacked_Wave_Continuum_Scaled_085_096_Left, MgII_Continuum_ReStacked_Wave_Continuum_Scaled_085_096_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_085_096 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_085_096_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_085_096_Right))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_025_035 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_025_035_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_025_035_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_035_045 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_035_045_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_035_045_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_045_055 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_045_055_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_045_055_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_055_065 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_055_065_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_055_065_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_065_075 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_065_075_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_065_075_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_075_085 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_075_085_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_075_085_Right))\n",
    "MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_085_096 = np.concatenate((MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_085_096_Left, MgII_Continuum_ReStacked_Spec_Continuum_Scaled_SD_085_096_Right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af6a61-21fd-4eb8-9146-f541608d2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def getting_the_SD_from_the_polyfit(x, coeffs, cov):\n",
    "#    fit = np.polyval(coeffs, x)\n",
    "#\n",
    "#    # Construct Jacobian matrix of fit wrt coefficients: J_ij = x_i**(n-j)\n",
    "#    n = len(coeffs)\n",
    "#    J = np.vstack([x**(n - j - 1) for j in range(n)]).T  # Shape (len(x), len(coeffs))\n",
    "#\n",
    "#    # Propagate covariance: Var(fit_i) = J_i @ cov @ J_i.T\n",
    "#    fit_var = np.sum(J @ cov * J, axis=1)  # broadcasting dot products\n",
    "#    fit_std = np.sqrt(fit_var)\n",
    "#\n",
    "#    return fit_std\n",
    "#\n",
    "#print(MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035[0:3])\n",
    "#print(MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_025_035[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a5103-bdce-4f68-a6d1-b9e9f99605f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fitting the Left and Right side of the MgII emission. This is to get the continuum over this region.\n",
    "\"\"\"\n",
    "MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035, MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_025_035 = np.polyfit(MgII_LR_ReStacked_Wave_Continuum_Scaled_025_035, MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035, 3, \n",
    "                                                                                                                        w=MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_025_035, cov=True)\n",
    "MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_025_035 = np.sqrt(np.diag(MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_025_035))\n",
    "\n",
    "\n",
    "MgII_LR_Polyfit_ReStacked_Continuum_Scaled_035_045, MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_035_045 = np.polyfit(MgII_LR_ReStacked_Wave_Continuum_Scaled_035_045, MgII_LR_ReStacked_Spec_Continuum_Scaled_035_045, 3, \n",
    "                                                                                                                        w=1/MgII_LR_ReStacked_Spec_Continuum_Scaled_035_045, cov=True)\n",
    "MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_035_045 = np.sqrt(np.diag(MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_035_045))\n",
    "\n",
    "\n",
    "MgII_LR_Polyfit_ReStacked_Continuum_Scaled_045_055, MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_045_055 = np.polyfit(MgII_LR_ReStacked_Wave_Continuum_Scaled_045_055, MgII_LR_ReStacked_Spec_Continuum_Scaled_045_055, 3, \n",
    "                                                                                                                        w=1/MgII_LR_ReStacked_Spec_Continuum_Scaled_045_055, cov=True)\n",
    "MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_045_055 = np.sqrt(np.diag(MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_045_055))\n",
    "\n",
    "\n",
    "MgII_LR_Polyfit_ReStacked_Continuum_Scaled_055_065, MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_055_065 = np.polyfit(MgII_LR_ReStacked_Wave_Continuum_Scaled_055_065, MgII_LR_ReStacked_Spec_Continuum_Scaled_055_065, 3, \n",
    "                                                                                                                        w=1/MgII_LR_ReStacked_Spec_Continuum_Scaled_055_065, cov=True)\n",
    "MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_055_065 = np.sqrt(np.diag(MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_055_065))\n",
    "\n",
    "\n",
    "MgII_LR_Polyfit_ReStacked_Continuum_Scaled_065_075, MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_065_075 = np.polyfit(MgII_LR_ReStacked_Wave_Continuum_Scaled_065_075, MgII_LR_ReStacked_Spec_Continuum_Scaled_065_075, 3, \n",
    "                                                                                                                        w=1/MgII_LR_ReStacked_Spec_Continuum_Scaled_065_075, cov=True)\n",
    "MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_065_075 = np.sqrt(np.diag(MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_065_075))\n",
    "\n",
    "\n",
    "MgII_LR_Polyfit_ReStacked_Continuum_Scaled_075_085, MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_075_085 = np.polyfit(MgII_LR_ReStacked_Wave_Continuum_Scaled_075_085, MgII_LR_ReStacked_Spec_Continuum_Scaled_075_085, 3, \n",
    "                                                                                                                        w=1/MgII_LR_ReStacked_Spec_Continuum_Scaled_075_085, cov=True)\n",
    "MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_075_085 = np.sqrt(np.diag(MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_075_085))\n",
    "\n",
    "\n",
    "MgII_LR_Polyfit_ReStacked_Continuum_Scaled_085_096, MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_085_096 = np.polyfit(MgII_LR_ReStacked_Wave_Continuum_Scaled_085_096, MgII_LR_ReStacked_Spec_Continuum_Scaled_085_096, 3, \n",
    "                                                                                                                        w=1/MgII_LR_ReStacked_Spec_Continuum_Scaled_085_096, cov=True)\n",
    "MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_085_096 = np.sqrt(np.diag(MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_085_096))\n",
    "\n",
    "\n",
    "print(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035[0:3])\n",
    "print(MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_025_035[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c00f23-753c-4966-9703-661c1ebf4f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def polyval_with_std(wave, coeffs, coeffs_std):\n",
    "    \"\"\"\n",
    "    Evaluate a polynomial and estimate the standard deviation of the result\n",
    "    using error propagation.\n",
    "\n",
    "    Parameters:\n",
    "        wave (np.ndarray): The x-values at which to evaluate the polynomial.\n",
    "        coeffs (np.ndarray): Polynomial coefficients (highest power first).\n",
    "        coeffs_std (np.ndarray): Standard deviation of the polynomial coefficients.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (polyval_result, stddev_result)\n",
    "    \"\"\"\n",
    "    polyval_result = np.polyval(coeffs, wave)\n",
    "    \n",
    "    # Construct the Jacobian matrix of the polynomial w.r.t. its coefficients\n",
    "    powers = np.arange(len(coeffs))[::-1]  # descending powers\n",
    "    jacobian = np.array([wave**p for p in powers])  # shape: (n_coeffs, len(wave))\n",
    "    \n",
    "    # Propagate uncertainty: variance = sum_j (df/dc_j)^2 * var(c_j)\n",
    "    variance = np.sum((jacobian.T * coeffs_std)**2, axis=1)\n",
    "    stddev_result = np.sqrt(variance)\n",
    "\n",
    "    return polyval_result, stddev_result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Getting the continuum fit from the polyfits.\n",
    "\"\"\"\n",
    "MgII_LR_Polyvall_ReStacked_Continuum_Scaled_025_035, MgII_LR_Polyvall_ReStacked_Continuum_Scaled_SD_025_035 = polyval_with_std(MgII_ReStacked_Wave_Continuum_Scaled_025_035, MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_025_035)\n",
    "MgII_LR_Polyvall_ReStacked_Continuum_Scaled_035_045, MgII_LR_Polyvall_ReStacked_Continuum_Scaled_SD_035_045 = polyval_with_std(MgII_ReStacked_Wave_Continuum_Scaled_035_045, MgII_LR_Polyfit_ReStacked_Continuum_Scaled_035_045, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_035_045)\n",
    "MgII_LR_Polyvall_ReStacked_Continuum_Scaled_045_055, MgII_LR_Polyvall_ReStacked_Continuum_Scaled_SD_045_055 = polyval_with_std(MgII_ReStacked_Wave_Continuum_Scaled_045_055, MgII_LR_Polyfit_ReStacked_Continuum_Scaled_045_055, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_045_055)\n",
    "MgII_LR_Polyvall_ReStacked_Continuum_Scaled_055_065, MgII_LR_Polyvall_ReStacked_Continuum_Scaled_SD_055_065 = polyval_with_std(MgII_ReStacked_Wave_Continuum_Scaled_055_065, MgII_LR_Polyfit_ReStacked_Continuum_Scaled_055_065, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_055_065)\n",
    "MgII_LR_Polyvall_ReStacked_Continuum_Scaled_065_075, MgII_LR_Polyvall_ReStacked_Continuum_Scaled_SD_065_075 = polyval_with_std(MgII_ReStacked_Wave_Continuum_Scaled_065_075, MgII_LR_Polyfit_ReStacked_Continuum_Scaled_065_075, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_065_075)\n",
    "MgII_LR_Polyvall_ReStacked_Continuum_Scaled_075_085, MgII_LR_Polyvall_ReStacked_Continuum_Scaled_SD_075_085 = polyval_with_std(MgII_ReStacked_Wave_Continuum_Scaled_075_085, MgII_LR_Polyfit_ReStacked_Continuum_Scaled_075_085, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_075_085)\n",
    "MgII_LR_Polyvall_ReStacked_Continuum_Scaled_085_096, MgII_LR_Polyvall_ReStacked_Continuum_Scaled_SD_085_096 = polyval_with_std(MgII_ReStacked_Wave_Continuum_Scaled_085_096, MgII_LR_Polyfit_ReStacked_Continuum_Scaled_085_096, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8fbeb-c4e2-4759-8560-9d7e9290960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getting_the_sd_on_the_polyequation(x, cov, coeffs):\n",
    "#    # Construct Jacobian matrix: shape (N, 4)\n",
    "#    J = np.vstack([x**3, x**2, x, np.ones_like(x)]).T  # shape (N, 4)\n",
    "#    \n",
    "#    # Calculate variance at each x\n",
    "#    fit_var = np.einsum('ij,jk,ik->i', J, cov, J)  # shape (N,)\n",
    "#    \n",
    "#    # Standard deviation (1-sigma error)\n",
    "#    fit_std = np.sqrt(fit_var)\n",
    "#    \n",
    "#    # Your polynomial evaluated at x (for completeness)\n",
    "#    standard_deviation = (\n",
    "#        coeffs[0]*x**3 + coeffs[1]*x**2 + coeffs[2]*x + coeffs[3]\n",
    "#    )\n",
    "#\n",
    "#    return standard_deviation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def polynomial_with_error_propagation(\n",
    "    coefficients,\n",
    "    x_values,\n",
    "    coefficient_uncertainties=None,\n",
    "    covariance_matrix=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate a polynomial and propagate uncertainty from coefficients.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    coefficients : array-like\n",
    "        Polynomial coefficients [a, b, ..., z] from highest to lowest degree\n",
    "    x_values : array-like\n",
    "        The x values to evaluate the polynomial at\n",
    "    coefficient_uncertainties : array-like, optional\n",
    "        Standard deviation of each coefficient (assumes uncorrelated errors)\n",
    "    covariance_matrix : 2D array-like, optional\n",
    "        Covariance matrix of the polynomial coefficients\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    y_values : array-like\n",
    "        The polynomial values\n",
    "    y_uncertainties : array-like\n",
    "        The propagated uncertainties\n",
    "    \"\"\"\n",
    "    coefficients = np.asarray(coefficients)\n",
    "    x_values = np.asarray(x_values)\n",
    "\n",
    "    # Evaluate the polynomial\n",
    "    y_values = np.polyval(coefficients, x_values)\n",
    "\n",
    "    # Compute the Jacobian matrix of partial derivatives\n",
    "    powers = np.arange(len(coefficients))[::-1]  # descending powers\n",
    "    jacobian = np.array([x_values**p for p in powers]).T  # shape: (n_points, n_coeffs)\n",
    "\n",
    "    if covariance_matrix is not None:\n",
    "        # Full error propagation with covariance\n",
    "        covariance_matrix = np.asarray(covariance_matrix)\n",
    "        y_var = np.einsum('ij,jk,ik->i', jacobian, covariance_matrix, jacobian)\n",
    "    elif coefficient_uncertainties is not None:\n",
    "        # Diagonal-only propagation (uncorrelated errors)\n",
    "        coefficient_uncertainties = np.asarray(coefficient_uncertainties)\n",
    "        y_var = np.sum((jacobian * coefficient_uncertainties)**2, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"You must provide either coefficient_uncertainties or covariance_matrix.\")\n",
    "\n",
    "    y_uncertainties = np.sqrt(y_var)\n",
    "    return y_values, y_uncertainties\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Taking the Polyfit outputs (the coefficients) and putting them into a polynomial equation.\n",
    "\"\"\"\n",
    "#MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035 = MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035[0]*MgII_ReStacked_Wave_Continuum_Scaled_025_035**3 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035[1]*MgII_ReStacked_Wave_Continuum_Scaled_025_035**2 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035[2]*MgII_ReStacked_Wave_Continuum_Scaled_025_035**1 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035[3]*MgII_ReStacked_Wave_Continuum_Scaled_025_035**0\n",
    "#MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_035_045 = MgII_LR_Polyfit_ReStacked_Continuum_Scaled_035_045[0]*MgII_ReStacked_Wave_Continuum_Scaled_035_045**3 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_035_045[1]*MgII_ReStacked_Wave_Continuum_Scaled_035_045**2 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_035_045[2]*MgII_ReStacked_Wave_Continuum_Scaled_035_045**1 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_035_045[3]*MgII_ReStacked_Wave_Continuum_Scaled_035_045**0\n",
    "#MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_045_055 = MgII_LR_Polyfit_ReStacked_Continuum_Scaled_045_055[0]*MgII_ReStacked_Wave_Continuum_Scaled_045_055**3 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_045_055[1]*MgII_ReStacked_Wave_Continuum_Scaled_045_055**2 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_045_055[2]*MgII_ReStacked_Wave_Continuum_Scaled_045_055**1 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_045_055[3]*MgII_ReStacked_Wave_Continuum_Scaled_045_055**0\n",
    "#MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_055_065 = MgII_LR_Polyfit_ReStacked_Continuum_Scaled_055_065[0]*MgII_ReStacked_Wave_Continuum_Scaled_055_065**3 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_055_065[1]*MgII_ReStacked_Wave_Continuum_Scaled_055_065**2 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_055_065[2]*MgII_ReStacked_Wave_Continuum_Scaled_055_065**1 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_055_065[3]*MgII_ReStacked_Wave_Continuum_Scaled_055_065**0\n",
    "#MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_065_075 = MgII_LR_Polyfit_ReStacked_Continuum_Scaled_065_075[0]*MgII_ReStacked_Wave_Continuum_Scaled_065_075**3 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_065_075[1]*MgII_ReStacked_Wave_Continuum_Scaled_065_075**2 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_065_075[2]*MgII_ReStacked_Wave_Continuum_Scaled_065_075**1 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_065_075[3]*MgII_ReStacked_Wave_Continuum_Scaled_065_075**0\n",
    "#MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_075_085 = MgII_LR_Polyfit_ReStacked_Continuum_Scaled_075_085[0]*MgII_ReStacked_Wave_Continuum_Scaled_075_085**3 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_075_085[1]*MgII_ReStacked_Wave_Continuum_Scaled_075_085**2 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_075_085[2]*MgII_ReStacked_Wave_Continuum_Scaled_075_085**1 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_075_085[3]*MgII_ReStacked_Wave_Continuum_Scaled_075_085**0\n",
    "#MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_085_096 = MgII_LR_Polyfit_ReStacked_Continuum_Scaled_085_096[0]*MgII_ReStacked_Wave_Continuum_Scaled_085_096**3 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_085_096[1]*MgII_ReStacked_Wave_Continuum_Scaled_085_096**2 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_085_096[2]*MgII_ReStacked_Wave_Continuum_Scaled_085_096**1 + MgII_LR_Polyfit_ReStacked_Continuum_Scaled_085_096[3]*MgII_ReStacked_Wave_Continuum_Scaled_085_096**0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_025_035 = polynomial_with_error_propagation(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035, \n",
    "                                                                                                                                                                 MgII_ReStacked_Wave_Continuum_Scaled_025_035, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_025_035,\n",
    "                                                                                                                                                                MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_025_035)\n",
    "\n",
    "MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_035_045, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_035_045 = polynomial_with_error_propagation(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_035_045, \n",
    "                                                                                                                                                                 MgII_ReStacked_Wave_Continuum_Scaled_035_045, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_035_045,\n",
    "                                                                                                                                                                MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_035_045)\n",
    "\n",
    "MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_045_055, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_045_055 = polynomial_with_error_propagation(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_045_055, \n",
    "                                                                                                                                                                 MgII_ReStacked_Wave_Continuum_Scaled_045_055, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_045_055,\n",
    "                                                                                                                                                                MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_045_055)\n",
    "\n",
    "MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_055_065, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_055_065 = polynomial_with_error_propagation(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_055_065, \n",
    "                                                                                                                                                                 MgII_ReStacked_Wave_Continuum_Scaled_055_065, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_055_065,\n",
    "                                                                                                                                                                MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_055_065)\n",
    "\n",
    "MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_065_075, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_065_075 = polynomial_with_error_propagation(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_065_075, \n",
    "                                                                                                                                                                 MgII_ReStacked_Wave_Continuum_Scaled_065_075, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_065_075,\n",
    "                                                                                                                                                                MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_065_075)\n",
    "\n",
    "MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_075_085, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_075_085 = polynomial_with_error_propagation(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_075_085, \n",
    "                                                                                                                                                                 MgII_ReStacked_Wave_Continuum_Scaled_075_085, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_075_085,\n",
    "                                                                                                                                                                MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_075_085)\n",
    "\n",
    "MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_085_096, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_085_096 = polynomial_with_error_propagation(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_085_096, \n",
    "                                                                                                                                                                 MgII_ReStacked_Wave_Continuum_Scaled_085_096, MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_085_096,\n",
    "                                                                                                                                                                MgII_LR_Polyfit_COV_ReStacked_Continuum_Scaled_085_096)\n",
    "\n",
    "\n",
    "\n",
    "print(MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035[0:3])\n",
    "print(\"\")\n",
    "print(MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_025_035[0:3])\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(MgII_LR_Polyfit_ReStacked_Continuum_Scaled_025_035[0:3])\n",
    "print(MgII_LR_Polyfit_SD_ReStacked_Continuum_Scaled_025_035[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d0d21-4437-422a-9527-4a1c64692a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Checking the Polyfits to the MgII LR continuum and the polynomial equation.\n",
    "\n",
    "# Create figure with MNRAS-compliant dimensions and styling\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10), facecolor='white')\n",
    "\n",
    "# Color scheme from the first code\n",
    "colors = {\n",
    "    'spectrum': \"#a714ff\",      # Purple (deep/cool)\n",
    "    'uncertainty': \"#d4a7ff\",   # Light purple\n",
    "    'polyfit_bg': \"#C4C4C4\",    # Light grey background\n",
    "    'polyfit': \"#FF5757\"        # Red (warm) for the polynomial fit\n",
    "}\n",
    "\n",
    "# Plot uncertainty band first (lowest z-order)\n",
    "uncertainty_fill = ax.fill_between(\n",
    "    MgII_LR_ReStacked_Wave_Continuum_Scaled_025_035, \n",
    "    MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035 - MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_025_035, \n",
    "    MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035 + MgII_LR_ReStacked_Spec_Continuum_Scaled_SD_025_035, \n",
    "    color=colors['uncertainty'], alpha=0.4, zorder=1,\n",
    "    label=r'Spectrum $\\pm 1\\sigma$'\n",
    ")\n",
    "\n",
    "# Plot spectrum\n",
    "spectrum_line = ax.plot(\n",
    "    MgII_LR_ReStacked_Wave_Continuum_Scaled_025_035, \n",
    "    MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035, \n",
    "    color=colors['spectrum'], linewidth=2.0, zorder=4,\n",
    "    label=r'Mg\\,{\\sc ii} Continuum Spectrum'\n",
    ")\n",
    "\n",
    "# Plot polynomial fit with background effect\n",
    "polyfit_bg = ax.plot(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_025_035, \n",
    "    MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035, \n",
    "    color=colors['polyfit_bg'], linewidth=8, alpha=0.6, zorder=2,\n",
    "    label='Polynomial Fit (Background)'\n",
    ")\n",
    "\n",
    "# Plot polynomial fit main line\n",
    "polyfit_line = ax.plot(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_025_035, \n",
    "    MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035, \n",
    "    color=colors['polyfit'], linewidth=2.5, zorder=3,\n",
    "    label='Polynomial Continuum Fit'\n",
    ")\n",
    "\n",
    "# Add Mg II emission line marker\n",
    "ax.axvline(x=2799, color='black', linestyle='--', \n",
    "          linewidth=2.5, alpha=0.8, zorder=5,\n",
    "          label=r'Mg\\,{\\sc ii} $\\lambda$2799')\n",
    "\n",
    "# Print length information (diagnostic)\n",
    "print(f\"Spectrum length: {len(MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035)}\")\n",
    "print(f\"Polynomial fit length: {len(MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035)}\")\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Rest Wavelength [\\AA]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Flux [erg s$^{-1}$ cm$^{-2}$ \\AA$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(r\"Mg\\,{\\sc ii} Continuum Polynomial Fit Validation ($0.25 < z < 0.35$)\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='best',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.5,\n",
    "    labelspacing=0.8,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"MgII_Polyfit_Validation_MNRAS.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"MgII_Polyfit_Validation_MNRAS.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffc1e5-4bc4-4eaa-b675-5cf09bfb00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to create a function to make this more reusable:\n",
    "def propagate_subtraction_error(array1, array1_err, array2, array2_err):\n",
    "    \"\"\"\n",
    "    Calculate the differenc and Propagate uncertainty when subtracting two arrays (A - B)\n",
    "    \n",
    "    Parameters:\n",
    "    array1 (numpy.ndarray): Array of the original restack.\n",
    "    array1_err (numpy.ndarray): Standard deviation of first array.\n",
    "    \n",
    "    array2 (numpy.ndarray) : Array of the continuum fits.\n",
    "    array2_err (numpy.ndarray): Standard deviation of second array.\n",
    "    \n",
    "    Returns:\n",
    "    dif (numpy.ndarray) : Difference of the stacked spectra minus the continuum fit for the stack.\n",
    "    dif_sd (numpy.ndarray) : Propagated standard deviation\n",
    "    \"\"\"\n",
    "\n",
    "    dif = array1 - array2\n",
    "    dif_sd = np.sqrt(array1_err**2 + array2_err**2)\n",
    "    \n",
    "    return dif, dif_sd\n",
    "\n",
    "# This function can then be used like:\n",
    "# result_err = propagate_subtraction_error(array1_err, array2_err)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Subtracting the results of the Poly equation from the MgII LR spectra. This removes the continuum and leaves the MgII continuum at or about zero.\n",
    "\"\"\"\n",
    "MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035 = propagate_subtraction_error(MgII_ReStacked_Spec_Continuum_Scaled_025_035, MgII_ReStacked_Spec_Continuum_Scaled_SD_025_035, \n",
    "                                                                                                                        MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_025_035)\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045 = propagate_subtraction_error(MgII_ReStacked_Spec_Continuum_Scaled_035_045, MgII_ReStacked_Spec_Continuum_Scaled_SD_035_045, \n",
    "                                                                                                                        MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_035_045, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_035_045)\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055 = propagate_subtraction_error(MgII_ReStacked_Spec_Continuum_Scaled_045_055, MgII_ReStacked_Spec_Continuum_Scaled_SD_045_055, \n",
    "                                                                                                                        MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_045_055, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_045_055)\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065 = propagate_subtraction_error(MgII_ReStacked_Spec_Continuum_Scaled_055_065, MgII_ReStacked_Spec_Continuum_Scaled_SD_055_065, \n",
    "                                                                                                                        MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_055_065, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_055_065)\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075 = propagate_subtraction_error(MgII_ReStacked_Spec_Continuum_Scaled_065_075, MgII_ReStacked_Spec_Continuum_Scaled_SD_065_075, \n",
    "                                                                                                                        MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_065_075, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_065_075)\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085 = propagate_subtraction_error(MgII_ReStacked_Spec_Continuum_Scaled_075_085, MgII_ReStacked_Spec_Continuum_Scaled_SD_075_085, \n",
    "                                                                                                                        MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_075_085, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_075_085)\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096 = propagate_subtraction_error(MgII_ReStacked_Spec_Continuum_Scaled_085_096, MgII_ReStacked_Spec_Continuum_Scaled_SD_085_096, \n",
    "                                                                                                                        MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_085_096, MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273365f3-54fd-435f-932d-6cfed311078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MgII_ReStacked_Spec_Continuum_Scaled_025_035[0:3])\n",
    "print(\"\")\n",
    "print(MgII_ReStacked_Spec_Continuum_Scaled_SD_025_035[0:3])\n",
    "print(\"\")\n",
    "print(MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035[0:3])\n",
    "print(\"\")\n",
    "print(MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_SD_025_035[0:3])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83275e04-686d-4880-a2f7-3669ed864a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking to make sure that the removal of the MgII continuum worked right. \n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Color scheme (matching the second code)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Additional colors for different components\n",
    "plot_colors = {\n",
    "    'original': '#2E86AB',      # Blue for original spectrum\n",
    "    'lr_data': '#A23B72',       # Magenta for LR data\n",
    "    'poly_fit': 'black',        # Black for polynomial fit\n",
    "    'continuum_removed': 'lightseagreen'  # Light sea green for continuum removed\n",
    "}\n",
    "\n",
    "# Labels for redshift bins\n",
    "redshift_labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Create figure with MNRAS-compliant styling\n",
    "fig = plt.figure(figsize=(15, 10), facecolor='white')\n",
    "fig.suptitle(\"MgII Continuum Removal Verification\", fontsize=16, fontweight='bold', y=0.95)\n",
    "\n",
    "# Dataset configuration for each subplot\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Wave_Continuum_Scaled_025_035, MgII_ReStacked_Spec_Continuum_Scaled_025_035,\n",
    "     MgII_LR_ReStacked_Wave_Continuum_Scaled_025_035, MgII_LR_ReStacked_Spec_Continuum_Scaled_025_035,\n",
    "     MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_025_035, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035),\n",
    "    ('035_045', MgII_ReStacked_Wave_Continuum_Scaled_035_045, MgII_ReStacked_Spec_Continuum_Scaled_035_045,\n",
    "     MgII_LR_ReStacked_Wave_Continuum_Scaled_035_045, MgII_LR_ReStacked_Spec_Continuum_Scaled_035_045,\n",
    "     MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_035_045, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045),\n",
    "    ('045_055', MgII_ReStacked_Wave_Continuum_Scaled_045_055, MgII_ReStacked_Spec_Continuum_Scaled_045_055,\n",
    "     MgII_LR_ReStacked_Wave_Continuum_Scaled_045_055, MgII_LR_ReStacked_Spec_Continuum_Scaled_045_055,\n",
    "     MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_045_055, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055),\n",
    "    ('055_065', MgII_ReStacked_Wave_Continuum_Scaled_055_065, MgII_ReStacked_Spec_Continuum_Scaled_055_065,\n",
    "     MgII_LR_ReStacked_Wave_Continuum_Scaled_055_065, MgII_LR_ReStacked_Spec_Continuum_Scaled_055_065,\n",
    "     MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_055_065, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065),\n",
    "    ('065_075', MgII_ReStacked_Wave_Continuum_Scaled_065_075, MgII_ReStacked_Spec_Continuum_Scaled_065_075,\n",
    "     MgII_LR_ReStacked_Wave_Continuum_Scaled_065_075, MgII_LR_ReStacked_Spec_Continuum_Scaled_065_075,\n",
    "     MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_065_075, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075),\n",
    "    ('075_085', MgII_ReStacked_Wave_Continuum_Scaled_075_085, MgII_ReStacked_Spec_Continuum_Scaled_075_085,\n",
    "     MgII_LR_ReStacked_Wave_Continuum_Scaled_075_085, MgII_LR_ReStacked_Spec_Continuum_Scaled_075_085,\n",
    "     MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_075_085, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085),\n",
    "    ('085_096', MgII_ReStacked_Wave_Continuum_Scaled_085_096, MgII_ReStacked_Spec_Continuum_Scaled_085_096,\n",
    "     MgII_LR_ReStacked_Wave_Continuum_Scaled_085_096, MgII_LR_ReStacked_Spec_Continuum_Scaled_085_096,\n",
    "     MgII_LR_PolyEquation_ReStacked_Continuum_Scaled_085_096, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096)\n",
    "]\n",
    "\n",
    "# Create subplots in 3x3 grid\n",
    "for i, (key, wave, spec, lr_wave, lr_spec, poly_eq, cont_removed) in enumerate(datasets):\n",
    "    ax = plt.subplot(3, 3, i+1)\n",
    "    \n",
    "    # Plot original spectrum\n",
    "    ax.plot(wave, spec, \n",
    "            color=plot_colors['original'], \n",
    "            linewidth=1.5, \n",
    "            alpha=0.8, \n",
    "            label='Original Spectrum')\n",
    "    \n",
    "    # Plot LR restacked data\n",
    "    ax.plot(lr_wave, lr_spec, \n",
    "            color=plot_colors['lr_data'], \n",
    "            linewidth=2.0, \n",
    "            alpha=0.9, \n",
    "            zorder=5,\n",
    "            label='LR Restacked')\n",
    "    \n",
    "    # Plot polynomial fit\n",
    "    ax.plot(wave, poly_eq, \n",
    "            linewidth=3.0, \n",
    "            color=plot_colors['poly_fit'], \n",
    "            alpha=0.9,\n",
    "            zorder=6,\n",
    "            label='Polynomial Fit')\n",
    "    \n",
    "    # Plot continuum removed spectrum\n",
    "    ax.plot(wave, cont_removed, \n",
    "            linewidth=2.5, \n",
    "            color=plot_colors['continuum_removed'], \n",
    "            alpha=1.0,\n",
    "            zorder=7,\n",
    "            label='Continuum Removed')\n",
    "    \n",
    "    # Set subplot title with redshift range\n",
    "    ax.set_title(redshift_labels[i], fontsize=11, fontweight='bold', pad=8)\n",
    "    \n",
    "    # Configure grid\n",
    "    ax.grid(visible=True, which='both', axis='both', \n",
    "            linestyle='--', alpha=0.5, zorder=-10)\n",
    "    \n",
    "    # Set minor ticks\n",
    "    ax.minorticks_on()\n",
    "    \n",
    "    # Configure spine thickness\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2.0)\n",
    "    \n",
    "    # Configure tick parameters\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10,\n",
    "                   length=6, width=1.5, direction='in')\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=8,\n",
    "                   length=3, width=1.0, direction='in')\n",
    "    \n",
    "    # Enable ticks on all sides\n",
    "    ax.tick_params(top=True, right=True)\n",
    "    \n",
    "    # Set axis labels for bottom row\n",
    "    if i >= 6:  # Bottom row\n",
    "        ax.set_xlabel(r'Wavelength [Å]', fontsize=11)\n",
    "    \n",
    "    # Set axis labels for left column\n",
    "    if i % 3 == 0:  # Left column\n",
    "        ax.set_ylabel(r'Flux', fontsize=11)\n",
    "\n",
    "# Create a single legend for the entire figure\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels,  \n",
    "           bbox_to_anchor=(0.8, 0.05),\n",
    "           ncol=4, \n",
    "           fontsize=11,\n",
    "           frameon=True,\n",
    "           fancybox=True,\n",
    "           shadow=True,\n",
    "           borderpad=0.8,\n",
    "           handletextpad=0.6,\n",
    "           columnspacing=1.5)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0.08, 1, 0.93])\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"MgII_Continuum_Removal_Verification_MNRAS.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"MgII_Continuum_Removal_Verification_MNRAS.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8246db-9b08-4e27-966b-3d0f3861c823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39cd3a6-77a3-4d2d-82ba-810fc02bf12d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4afcd7-bbe6-4705-b700-b7103015c1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ab1b4-a5f3-4531-b205-84b8f95600aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035[0:5])\n",
    "print(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d8189-648c-4cec-b99a-ee45e0c62136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10), facecolor='white')\n",
    "\n",
    "# Color scheme (using colors from the first code)\n",
    "colors = {\n",
    "    'main_spectrum': \"#a714ff\",  # Purple for main spectrum\n",
    "    'error_fill': \"black\",       # Black for error region\n",
    "    'MgII': \"black\",\n",
    "    'HeI': \"black\", \n",
    "    'FeIV_1': \"#ff14f5\",        # Pink\n",
    "    'FeIV_2': \"#FF5757\",        # Red (maroon equivalent)\n",
    "    'ArIV_1': \"#14D8FF\",        # Teal (skyblue equivalent)\n",
    "    'ArIV_2': \"#60B5FF\",        # Blue\n",
    "    'HeII': \"#ffbb14\"           # Orange (gold equivalent)\n",
    "}\n",
    "\n",
    "# Plot main spectrum with step function\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_035_045, \n",
    "        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, \n",
    "        color=colors['main_spectrum'], \n",
    "        linewidth=2, \n",
    "        linestyle=\"-\", \n",
    "        alpha=1.0)\n",
    "\n",
    "# Add error region with fill_between\n",
    "ax.fill_between(MgII_ReStacked_Wave_Continuum_Scaled_035_045, \n",
    "                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045 - MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045, \n",
    "                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045 + MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045, \n",
    "                color=colors['error_fill'], \n",
    "                alpha=0.5, \n",
    "                zorder=0)\n",
    "\n",
    "# Spectral line markers with organized approach\n",
    "spectral_lines = [\n",
    "    (2799, colors['MgII'], \"--\", \"MgII\"),\n",
    "    (2945.106, colors['HeI'], \":\", \"HeI\"),\n",
    "    (2829.360, colors['FeIV_1'], \":\", \"FeIV\"),\n",
    "    (2835.740, colors['FeIV_2'], \":\", \"FeIV\"),\n",
    "    (2853.670, colors['ArIV_1'], \":\", \"ArIV\"),\n",
    "    (2868.210, colors['ArIV_2'], \":\", \"ArIV\"),\n",
    "    (2733.289, colors['HeII'], \":\", \"HeII\")\n",
    "]\n",
    "\n",
    "# Plot spectral line markers\n",
    "for wavelength, color, linestyle, label in spectral_lines:\n",
    "    linewidth = 2 if linestyle == \"--\" else 2\n",
    "    ax.axvline(x=wavelength, \n",
    "               color=color, \n",
    "               linestyle=linestyle, \n",
    "               linewidth=linewidth,\n",
    "               label=label)\n",
    "\n",
    "# Configure axes labels\n",
    "ax.set_ylabel(r\"Flux [erg $\\AA^{-1} s^{-1} cm^{-2}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_xlabel(r\"Rest Wavelength [$\\AA$]\", fontsize=14, color=\"black\")\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='best',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"MgII_Spectrum_MNRAS_Ready.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"MgII_Spectrum_MNRAS_Ready.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501abc0-df5c-4c7e-ad77-97a0100a1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overplotting the MgII emission region with the continuum removed.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary with hex colors from first code)\n",
    "colors = {\n",
    "    'z_025_035': \"#FF5757\",   # Red\n",
    "    'z_035_045': \"#ffbb14\",   # Orange\n",
    "    'z_045_055': \"#00FF9C\",   # Gold equivalent (green)\n",
    "    'z_055_065': \"#60B5FF\",   # Blue\n",
    "    'z_065_075': \"#a714ff\",   # Purple\n",
    "    'z_075_085': \"#ff14f5\",   # Violet (pink)\n",
    "    'z_085_096': \"black\",     # Black\n",
    "    'reference_lines': \"black\"\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "redshift_labels = [\n",
    "    r'$z = 0.25-0.35$',\n",
    "    r'$z = 0.35-0.45$',\n",
    "    r'$z = 0.45-0.55$',\n",
    "    r'$z = 0.55-0.65$',\n",
    "    r'$z = 0.65-0.75$',\n",
    "    r'$z = 0.75-0.85$',\n",
    "    r'$z = 0.85-0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting\n",
    "datasets = [\n",
    "    ('z_025_035', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_025_035, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035,\n",
    "     redshift_labels[0]),\n",
    "    ('z_035_045', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_035_045, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045,\n",
    "     redshift_labels[1]),\n",
    "    ('z_045_055', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_045_055, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055,\n",
    "     redshift_labels[2]),\n",
    "    ('z_055_065', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_055_065, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065,\n",
    "     redshift_labels[3]),\n",
    "    ('z_065_075', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_065_075, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075,\n",
    "     redshift_labels[4]),\n",
    "    ('z_075_085', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_075_085, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085,\n",
    "     redshift_labels[5]),\n",
    "    ('z_085_096', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_085_096, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096,\n",
    "     redshift_labels[6])\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, wave, flux, error, label) in enumerate(datasets):\n",
    "    color = colors[key]\n",
    "    \n",
    "    # Plot uncertainty band (optional - currently commented out)\n",
    "    # ax.fill_between(wave, flux - error, flux + error, \n",
    "    #                 color=color, alpha=0.2, zorder=i*2, \n",
    "    #                 label=f'±1σ {label}' if i == 0 else \"\")\n",
    "    \n",
    "    # Plot main spectrum line\n",
    "    ax.step(wave, flux, \n",
    "            color=color, \n",
    "            linewidth=1.5, \n",
    "            linestyle=\"-\", \n",
    "            alpha=1.0, \n",
    "            zorder=i*2+1,\n",
    "            label=label)\n",
    "\n",
    "# Reference spectral lines configuration\n",
    "reference_lines = [\n",
    "    (2799, \"--\", 2, r\"Mg II $\\lambda$2799\"),\n",
    "    (2945.106, \":\", 2, r\"He I $\\lambda$2945\")\n",
    "]\n",
    "\n",
    "# Plot reference lines\n",
    "for wavelength, linestyle, linewidth, label in reference_lines:\n",
    "    ax.axvline(x=wavelength, \n",
    "               color=colors['reference_lines'], \n",
    "               linestyle=linestyle, \n",
    "               linewidth=linewidth,\n",
    "               label=label, \n",
    "               zorder=100)\n",
    "\n",
    "# Configure axes labels\n",
    "ax.set_ylabel(r\"Flux [erg s$^{-1}$ cm$^{-2}$ $\\AA^{-1}$]\", fontsize=16, color=\"black\")\n",
    "ax.set_xlabel(r\"Rest Wavelength [$\\AA$]\", fontsize=16, color=\"black\")\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper right',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1,\n",
    "    ncol=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='major', axis='both', \n",
    "        linestyle='--', alpha=0.3, zorder=-10, linewidth=0.8)\n",
    "ax.grid(visible=True, which='minor', axis='both', \n",
    "        linestyle=':', alpha=0.2, zorder=-10, linewidth=0.5)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=14,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=12,\n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Optional: Set specific axis limits if needed for better presentation\n",
    "# ax.set_xlim([2700, 3100])  # Uncomment and adjust as needed\n",
    "# ax.set_ylim([min_flux, max_flux])  # Uncomment and adjust as needed\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"Multi_Redshift_Spectra_MNRAS_Ready.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"Multi_Redshift_Spectra_MNRAS_Ready.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffafbab-3f76-4d29-bd5f-e89d469eabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overplotting the MgII emission region with the continuum removed. \n",
    "These are offset from each other.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary using hex colors from first code)\n",
    "colors = {\n",
    "    'z_025_035': \"#FF5757\",   # Red\n",
    "    'z_035_045': \"#ffbb14\",   # Orange\n",
    "    'z_045_055': \"#00FF9C\",   # Gold equivalent (green)\n",
    "    'z_055_065': \"#60B5FF\",   # Blue\n",
    "    'z_065_075': \"#a714ff\",   # Purple\n",
    "    'z_075_085': \"#ff14f5\",   # Violet (pink)\n",
    "    'z_085_096': \"black\",     # Black\n",
    "    'reference_lines': \"black\"\n",
    "}\n",
    "\n",
    "# Vertical offsets for stacked presentation\n",
    "offset_values = [0, 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]\n",
    "offset_multiplier = 2.5e-16  # Scaling factor for offsets\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "redshift_labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting with offsets\n",
    "datasets = [\n",
    "    ('z_025_035', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_025_035, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, \n",
    "     redshift_labels[0], 0),\n",
    "    ('z_035_045', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_035_045, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, \n",
    "     redshift_labels[1], 1),\n",
    "    ('z_045_055', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_045_055, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055, \n",
    "     redshift_labels[2], 2),\n",
    "    ('z_055_065', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_055_065, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065, \n",
    "     redshift_labels[3], 3),\n",
    "    ('z_065_075', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_065_075, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075, \n",
    "     redshift_labels[4], 4),\n",
    "    ('z_075_085', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_075_085, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085, \n",
    "     redshift_labels[5], 5),\n",
    "    ('z_085_096', \n",
    "     MgII_ReStacked_Wave_Continuum_Scaled_085_096, \n",
    "     MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096, \n",
    "     redshift_labels[6], 6)\n",
    "]\n",
    "\n",
    "# Plot each dataset with vertical offset\n",
    "for i, (key, wave, flux, label, offset_idx) in enumerate(datasets):\n",
    "    color = colors[key]\n",
    "    offset = offset_values[offset_idx] * offset_multiplier\n",
    "    \n",
    "    # Plot spectrum with offset\n",
    "    ax.step(wave, flux + offset, \n",
    "            color=color, \n",
    "            linewidth=1.5, \n",
    "            linestyle=\"-\", \n",
    "            alpha=1.0, \n",
    "            zorder=10+i,\n",
    "            label=label)\n",
    "\n",
    "# Reference spectral lines configuration\n",
    "reference_lines = [\n",
    "    (2799, \"--\", 2, r\"Mg II $\\lambda$2799\"),\n",
    "    (2945.106, \":\", 2, r\"He I $\\lambda$2945\")\n",
    "]\n",
    "\n",
    "# Plot reference lines\n",
    "for wavelength, linestyle, linewidth, label in reference_lines:\n",
    "    ax.axvline(x=wavelength, \n",
    "               color=colors['reference_lines'], \n",
    "               linestyle=linestyle, \n",
    "               linewidth=linewidth,\n",
    "               label=label, \n",
    "               zorder=100)\n",
    "\n",
    "# Configure axes labels\n",
    "ax.set_ylabel(r\"Flux with offset [erg s$^{-1}$ cm$^{-2}$ $\\AA^{-1}$]\", fontsize=16, color=\"black\")\n",
    "ax.set_xlabel(r\"Rest Wavelength [$\\AA$]\", fontsize=16, color=\"black\")\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1,\n",
    "    ncol=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='major', axis='both', \n",
    "        linestyle='--', alpha=0.3, zorder=-10, linewidth=0.8)\n",
    "ax.grid(visible=True, which='minor', axis='both', \n",
    "        linestyle=':', alpha=0.2, zorder=-10, linewidth=0.5)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=14,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=12,\n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout for publication\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Optional: Set specific axis limits if needed for better presentation\n",
    "# ax.set_xlim([2700, 3100])  # Uncomment and adjust as needed\n",
    "# ax.set_ylim([min_flux, max_flux])  # Uncomment and adjust as needed\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"Stacked_Multi_Redshift_Spectra_MNRAS_Ready.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"Stacked_Multi_Redshift_Spectra_MNRAS_Ready.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1dc59-20be-45f2-8fac-6b25f9a7047b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a66b62d3-86c0-4c02-8486-ae1e21f17b52",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Taking the continuum subtracted MgII emission regions and scaling them to compare the FWHM of the MgII emission</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ad566-57ec-4684-b40a-0a88a8c271fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5191a4-4420-40dd-9011-b5b38f02e721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc5de6-a384-4092-b3b6-2359a3266d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b2c13-9a2d-4c24-95af-accd3eefd894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcad2a-69da-4cdc-ad7f-6fbf2d810e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2d62293-7ded-4e8c-a47a-26a1e300a12d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949ca8d-2133-48e2-8ab9-a152a616b20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef5bef-403c-4fc5-b352-60000decf2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting Just the MgII emission.\n",
    "Takeing that and finding the max value of the spectra for the ReStacked spectra.\n",
    "\"\"\"\n",
    "MgII_Max_ReStacked_Spec_Index_Continuum_Scaled = np.where(np.logical_and(2700 > MgII_LR_ReStacked_Wave_Continuum_Scaled_025_035, MgII_LR_ReStacked_Wave_Continuum_Scaled_025_035 < 2900))[0] \n",
    "MgII_Max_ReStacked_Spec_Index_Of_Max_Continuum_Scaled = np.argmax(ReStacked_Spec_Continuum_Scaled[MgII_Max_ReStacked_Spec_Index_Continuum_Scaled])\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled = ReStacked_Spec_Continuum_Scaled[MgII_Max_ReStacked_Spec_Index_Continuum_Scaled][MgII_Max_ReStacked_Spec_Index_Of_Max_Continuum_Scaled]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD = ReStacked_Spec_SD_Continuum_Scaled[MgII_Max_ReStacked_Spec_Index_Continuum_Scaled][MgII_Max_ReStacked_Spec_Index_Of_Max_Continuum_Scaled]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd571dac-bd3a-4258-b55a-5cf6f4eb3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the max of the MgII emission for each of the redshift bins.\n",
    "\"\"\"\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_025_035 = np.argmax(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035)\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_035_045 = np.argmax(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045)\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_045_055 = np.argmax(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055)\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_055_065 = np.argmax(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065)\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_065_075 = np.argmax(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075)\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_075_085 = np.argmax(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085)\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_085_096 = np.argmax(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096)\n",
    "\n",
    "\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_025_035 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_025_035]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_035_045 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_035_045]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_045_055 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_045_055]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_055_065 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_055_065]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_065_075 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_065_075]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_075_085 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_075_085]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_085_096 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_085_096]\n",
    "\n",
    "\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_025_035 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_025_035]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_035_045 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_035_045]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_045_055 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_045_055]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_055_065 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_055_065]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_065_075 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_065_075]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_075_085 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_075_085]\n",
    "MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_085_096 = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096[MgII_Max_ReStacked_Spec_Continuum_Scaled_Max_Index_085_096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb0967-a0d2-4c27-b9ca-8c7d822f727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def propagate_ratio_std(A, sigma_A, B, sigma_B):\n",
    "    \"\"\"\n",
    "    Compute the ratio R = A / B and propagate standard deviation assuming independent errors.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    A : array_like or float\n",
    "        Numerator values.\n",
    "    sigma_A : array_like or float\n",
    "        Standard deviation of numerator values.\n",
    "    B : array_like or float\n",
    "        Denominator values.\n",
    "    sigma_B : array_like or float\n",
    "        Standard deviation of denominator values.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    R : array_like or float\n",
    "        Ratio A / B.\n",
    "    sigma_R : array_like or float\n",
    "        Propagated standard deviation on the ratio.\n",
    "    \"\"\"\n",
    "    R = A / B\n",
    "    relative_error_squared = (sigma_A / A)**2 + (sigma_B / B)**2\n",
    "    sigma_R = np.abs(R) * np.sqrt(relative_error_squared)\n",
    "    return R, sigma_R\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Dividing the max of the MgII emission of the restacked spectra over the max of the MgII emisson of the restacked spectra for each of the redshifts.\n",
    "\"\"\"\n",
    "MgII_Maxes_ReStacked_Dif_Continuum_Scaled_025_035, MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_025_035 = propagate_ratio_std(MgII_Max_ReStacked_Spec_Continuum_Scaled, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD, \n",
    "                                                                                                                              MgII_Max_ReStacked_Spec_Continuum_Scaled_025_035, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_025_035)\n",
    "\n",
    "MgII_Maxes_ReStacked_Dif_Continuum_Scaled_035_045, MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_035_045 = propagate_ratio_std(MgII_Max_ReStacked_Spec_Continuum_Scaled, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD, \n",
    "                                                                                                                              MgII_Max_ReStacked_Spec_Continuum_Scaled_035_045, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_035_045)\n",
    "\n",
    "MgII_Maxes_ReStacked_Dif_Continuum_Scaled_045_055, MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_045_055 = propagate_ratio_std(MgII_Max_ReStacked_Spec_Continuum_Scaled, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD, \n",
    "                                                                                                                              MgII_Max_ReStacked_Spec_Continuum_Scaled_045_055, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_045_055)\n",
    "\n",
    "MgII_Maxes_ReStacked_Dif_Continuum_Scaled_055_065, MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_055_065 = propagate_ratio_std(MgII_Max_ReStacked_Spec_Continuum_Scaled, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD, \n",
    "                                                                                                                              MgII_Max_ReStacked_Spec_Continuum_Scaled_055_065, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_055_065)\n",
    "\n",
    "MgII_Maxes_ReStacked_Dif_Continuum_Scaled_065_075, MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_065_075 = propagate_ratio_std(MgII_Max_ReStacked_Spec_Continuum_Scaled, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD, \n",
    "                                                                                                                              MgII_Max_ReStacked_Spec_Continuum_Scaled_065_075, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_065_075)\n",
    "\n",
    "MgII_Maxes_ReStacked_Dif_Continuum_Scaled_075_085, MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_075_085 = propagate_ratio_std(MgII_Max_ReStacked_Spec_Continuum_Scaled, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD, \n",
    "                                                                                                                              MgII_Max_ReStacked_Spec_Continuum_Scaled_075_085, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_075_085)\n",
    "\n",
    "MgII_Maxes_ReStacked_Dif_Continuum_Scaled_085_096, MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_085_096 = propagate_ratio_std(MgII_Max_ReStacked_Spec_Continuum_Scaled, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD, \n",
    "                                                                                                                              MgII_Max_ReStacked_Spec_Continuum_Scaled_085_096, MgII_Max_ReStacked_Spec_Continuum_Scaled_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7403dedc-0af8-4ac0-9ad7-d8990ddc94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def propagate_product_std(X, sigma_X, Y, sigma_Y):\n",
    "    \"\"\"\n",
    "    Propagate standard deviation through Z = X * abs(Y), assuming independent uncertainties.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array_like or float\n",
    "        First factor (e.g., flux-like quantity).\n",
    "    sigma_X : array_like or float\n",
    "        Standard deviation of X.\n",
    "    Y : array_like or float\n",
    "        Second factor (e.g., scaling factor, will take abs(Y)).\n",
    "    sigma_Y : array_like or float\n",
    "        Standard deviation of Y.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Z : array_like or float\n",
    "        Resulting product Z = X * abs(Y)\n",
    "    sigma_Z : array_like or float\n",
    "        Propagated standard deviation of Z.\n",
    "    \"\"\"\n",
    "    Y_abs = np.abs(Y)\n",
    "    Z = X * Y_abs\n",
    "    rel_error_sq = (sigma_X / X)**2 + (sigma_Y / Y_abs)**2\n",
    "    sigma_Z = np.abs(Z) * np.sqrt(rel_error_sq)\n",
    "    return Z, sigma_Z\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Multiplying the MgII continuum removed with the difference of the MgII emission of the restacked spectrum over the max of the MgII emisson of the restacked spectra for each of the redshifts.\n",
    "\"\"\"\n",
    "MgII_Scaled_ReStacked_Continuum_Scaled_025_035, MgII_Scaled_ReStacked_Continuum_Scaled_SD_025_035 = propagate_product_std(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035, \n",
    "                                                                                                                          abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_025_035), abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_025_035))\n",
    "\n",
    "MgII_Scaled_ReStacked_Continuum_Scaled_035_045, MgII_Scaled_ReStacked_Continuum_Scaled_SD_035_045 = propagate_product_std(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045, \n",
    "                                                                                                                          abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_035_045), abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_035_045))\n",
    "\n",
    "MgII_Scaled_ReStacked_Continuum_Scaled_045_055, MgII_Scaled_ReStacked_Continuum_Scaled_SD_045_055 = propagate_product_std(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055, \n",
    "                                                                                                                          abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_045_055), abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_045_055))\n",
    "\n",
    "MgII_Scaled_ReStacked_Continuum_Scaled_055_065, MgII_Scaled_ReStacked_Continuum_Scaled_SD_055_065 = propagate_product_std(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065, \n",
    "                                                                                                                          abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_055_065), abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_055_065))\n",
    "\n",
    "MgII_Scaled_ReStacked_Continuum_Scaled_065_075, MgII_Scaled_ReStacked_Continuum_Scaled_SD_065_075 = propagate_product_std(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075, \n",
    "                                                                                                                          abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_065_075), abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_065_075))\n",
    "\n",
    "MgII_Scaled_ReStacked_Continuum_Scaled_075_085, MgII_Scaled_ReStacked_Continuum_Scaled_SD_075_085 = propagate_product_std(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085, \n",
    "                                                                                                                          abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_075_085), abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_075_085))\n",
    "\n",
    "MgII_Scaled_ReStacked_Continuum_Scaled_085_096, MgII_Scaled_ReStacked_Continuum_Scaled_SD_085_096 = propagate_product_std(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096, \n",
    "                                                                                                                          abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_085_096), abs(MgII_Maxes_ReStacked_Dif_Continuum_Scaled_SD_085_096))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b89367-47de-4dcc-9bfd-ce8ccbc9c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overplotting the scaled MgII emissions.\n",
    "This allows for us to look at the differences in the FWHM of the MgII emissions.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Color scheme from the first code\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7), facecolor='white')\n",
    "\n",
    "# Plot step functions for each redshift bin\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_025_035, MgII_Scaled_ReStacked_Continuum_Scaled_025_035, \n",
    "        where='mid', color=colors['025_035'], linewidth=2, \n",
    "        label=\"r 0.25 $\\leq$ z $\\leq$ 0.35; Scale = \"+str('%.3f'%MgII_Maxes_ReStacked_Dif_Continuum_Scaled_025_035))\n",
    "\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_035_045, MgII_Scaled_ReStacked_Continuum_Scaled_035_045, \n",
    "        where='mid', color=colors['035_045'], linewidth=2, \n",
    "        label=\"r 0.35 $\\leq$ z $\\leq$ 0.45; Scale = \"+str('%.3f'%MgII_Maxes_ReStacked_Dif_Continuum_Scaled_035_045))\n",
    "\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_045_055, MgII_Scaled_ReStacked_Continuum_Scaled_045_055, \n",
    "        where='mid', color=colors['045_055'], linewidth=2, \n",
    "        label=\"r 0.45 $\\leq$ z $\\leq$ 0.55; Scale = \"+str('%.3f'%MgII_Maxes_ReStacked_Dif_Continuum_Scaled_045_055))\n",
    "\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_055_065, MgII_Scaled_ReStacked_Continuum_Scaled_055_065, \n",
    "        where='mid', color=colors['055_065'], linewidth=2, \n",
    "        label=\"r 0.55 $\\leq$ z $\\leq$ 0.65; Scale = \"+str('%.3f'%MgII_Maxes_ReStacked_Dif_Continuum_Scaled_055_065))\n",
    "\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_065_075, MgII_Scaled_ReStacked_Continuum_Scaled_065_075, \n",
    "        where='mid', color=colors['065_075'], linewidth=2, \n",
    "        label=\"r 0.65 $\\leq$ z $\\leq$ 0.75; Scale = \"+str('%.3f'%MgII_Maxes_ReStacked_Dif_Continuum_Scaled_065_075))\n",
    "\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_075_085, MgII_Scaled_ReStacked_Continuum_Scaled_075_085, \n",
    "        where='mid', color=colors['075_085'], linewidth=2, \n",
    "        label=\"r 0.75 $\\leq$ z $\\leq$ 0.85; Scale = \"+str('%.3f'%MgII_Maxes_ReStacked_Dif_Continuum_Scaled_075_085))\n",
    "\n",
    "ax.step(MgII_ReStacked_Wave_Continuum_Scaled_085_096, MgII_Scaled_ReStacked_Continuum_Scaled_085_096, \n",
    "        where='mid', color=colors['085_096'], linewidth=2, \n",
    "        label=\"r 0.85 $\\leq$ z $\\leq$ 0.96; Scale = \"+str('%.3f'%MgII_Maxes_ReStacked_Dif_Continuum_Scaled_085_096))\n",
    "\n",
    "# Add MgII reference line\n",
    "ax.axvline(x=2799, color='black', linestyle=\"--\", linewidth=2, label=\"MgII\")\n",
    "\n",
    "# Configure axes labels\n",
    "ax.set_ylabel(r\"Flux [erg $\\AA^{-1} s^{-1} cm^{-2}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_xlabel(r\"Rest Wavelength [$\\AA$]\", fontsize=14, color=\"black\")\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='best',\n",
    "    fontsize=10,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=0.8,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"MgII_Spectral_Stack_MNRAS_Ready.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"MgII_Spectral_Stack_MNRAS_Ready.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c5886-a564-415e-904f-a0dede129c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8be902-a73f-44b1-8c6b-9915b1954cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcaae7-4032-4530-bec2-ac5fdd289213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6499087-a56a-4e9c-91ca-a7bf211523db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_MgII_spectrum(x, y, y_err=None, plot=True, \n",
    "                    mask=None,  # NEW: mask parameter\n",
    "                    mask_ranges=None,  # NEW: alternative way to specify mask ranges\n",
    "                    g1_amp=None,\n",
    "                    g2_amp=None,\n",
    "                    g1_sigma=None,\n",
    "                    g2_sigma=None,\n",
    "                    g1_center=None,\n",
    "                    g2_center=None,\n",
    "                    g1_amp_bounds=None,\n",
    "                    g2_amp_bounds=None,\n",
    "                    g1_sigma_bounds=None,\n",
    "                    g2_sigma_bounds=None,\n",
    "                    g1_center_bounds=None,\n",
    "                    g2_center_bounds=None,\n",
    "                    title=\"0.25 < z < 0.35 - MgII Doublet Fit\",\n",
    "                    n_random_starts=50,  # Number of random starting points to try\n",
    "                    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "                    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "                    verbose=True):\n",
    "    \"\"\"\n",
    "    Enhanced MgII doublet fitting with two Gaussians.\n",
    "    Includes multiple optimization strategies and masking capability.\n",
    "    \n",
    "    This function tries multiple approaches:\n",
    "    1. Grid search over parameter space\n",
    "    2. Random starting points\n",
    "    3. Differential evolution (global optimizer)\n",
    "    4. Returns the best fit among all attempts\n",
    "    5. Supports masking to ignore specific data regions during fitting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array-like\n",
    "        Wavelength data\n",
    "    y : array-like\n",
    "        Flux data\n",
    "    y_err : array-like, optional\n",
    "        Flux uncertainties\n",
    "    plot : bool, optional\n",
    "        Whether to create plots\n",
    "    mask : array-like of bool, optional\n",
    "        Boolean mask where True indicates points to INCLUDE in fit.\n",
    "        If None, all points are used.\n",
    "    mask_ranges : list of tuples, optional\n",
    "        List of (min, max) tuples defining ranges to EXCLUDE from fit.\n",
    "        E.g., [(2750, 2780), (2850, 2900)] excludes these wavelength ranges.\n",
    "        This is an alternative to providing a mask array directly.\n",
    "    title : str, optional\n",
    "        Title for the plot (default: \"0.25 < z < 0.35 - MgII Doublet Fit\")\n",
    "    \n",
    "    Model Parameters with defaults:\n",
    "    ------------------------------\n",
    "    g1_amp : float, optional\n",
    "        Initial guess for amplitude of first Gaussian (defaults to 65% of max flux)\n",
    "    g1_center : float, optional\n",
    "        Initial guess for center of first Gaussian (default: 2800)\n",
    "    g1_sigma : float, optional\n",
    "        Initial guess for sigma of first Gaussian (default: 5)\n",
    "    g2_amp : float, optional\n",
    "        Initial guess for amplitude of second Gaussian (defaults to 40% of max flux)\n",
    "    g2_center : float, optional\n",
    "        Initial guess for center of second Gaussian (default: 2800)\n",
    "    g2_sigma : float, optional\n",
    "        Initial guess for sigma of second Gaussian (default: 45)\n",
    "    \n",
    "    Parameter Bounds:\n",
    "    ----------------\n",
    "    g1_amp_bounds : tuple, optional\n",
    "        (lower, upper) bounds for g1_amp (default: (10% of max flux, None))\n",
    "    g1_center_bounds : tuple, optional\n",
    "        (lower, upper) bounds for g1_center (default: (2700, 2900))\n",
    "    g1_sigma_bounds : tuple, optional\n",
    "        (lower, upper) bounds for g1_sigma (default: (0.1, 15))\n",
    "    g2_amp_bounds : tuple, optional\n",
    "        (lower, upper) bounds for g2_amp (default: (20% of max flux, None))\n",
    "    g2_center_bounds : tuple, optional\n",
    "        (lower, upper) bounds for g2_center (default: (2700, 2900))\n",
    "    g2_sigma_bounds : tuple, optional\n",
    "        (lower, upper) bounds for g2_sigma (default: (30, 65))\n",
    "        \n",
    "    Additional Parameters:\n",
    "    ---------------------\n",
    "    n_random_starts : int, optional\n",
    "        Number of random starting points to try (default: 50)\n",
    "    use_grid_search : bool, optional\n",
    "        Whether to perform grid search over parameter space (default: True)\n",
    "    use_differential_evolution : bool, optional\n",
    "        Whether to use differential evolution global optimizer (default: True)\n",
    "    verbose : bool, optional\n",
    "        Whether to print detailed optimization progress (default: True)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing fit results, parameters, uncertainties and fit components\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle masking\n",
    "    if mask_ranges is not None:\n",
    "        # Create mask from ranges\n",
    "        mask = np.ones(len(x), dtype=bool)  # Start with all True (include all)\n",
    "        for min_val, max_val in mask_ranges:\n",
    "            mask = mask & ~((x >= min_val) & (x <= max_val))  # Exclude ranges\n",
    "        if verbose:\n",
    "            excluded_points = len(x) - np.sum(mask)\n",
    "            print(f\"Masking {excluded_points} points from {len(mask_ranges)} ranges: {mask_ranges}\")\n",
    "    \n",
    "    elif mask is not None:\n",
    "        # Use provided mask\n",
    "        mask = np.array(mask, dtype=bool)\n",
    "        if len(mask) != len(x):\n",
    "            raise ValueError(\"Mask length must match data length\")\n",
    "        if verbose:\n",
    "            excluded_points = len(x) - np.sum(mask)\n",
    "            print(f\"Using provided mask: excluding {excluded_points} points\")\n",
    "    else:\n",
    "        # No masking - include all points\n",
    "        mask = np.ones(len(x), dtype=bool)\n",
    "        if verbose:\n",
    "            print(\"No masking applied - using all data points\")\n",
    "    \n",
    "    # Apply mask to data\n",
    "    x_fit = x[mask]\n",
    "    y_fit = y[mask]\n",
    "    y_err_fit = y_err[mask] if y_err is not None else None\n",
    "    \n",
    "    if len(x_fit) == 0:\n",
    "        raise ValueError(\"No data points remaining after masking!\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Fitting {len(x_fit)} out of {len(x)} data points\")\n",
    "    \n",
    "    # Scale y values by 1e17 for fitting\n",
    "    y_scaled = y_fit * 1e17\n",
    "    y_err_scaled = y_err_fit * 1e17 if y_err_fit is not None else None\n",
    "    \n",
    "    # Set default parameter values based on data if not provided\n",
    "    max_flux = np.max(y_fit)\n",
    "    \n",
    "    if g1_amp is None:\n",
    "        g1_amp = 0.65 * max_flux\n",
    "    if g2_amp is None:\n",
    "        g2_amp = 0.40 * max_flux\n",
    "    if g1_center is None:\n",
    "        g1_center = 2800\n",
    "    if g2_center is None:\n",
    "        g2_center = 2800\n",
    "    if g1_sigma is None:\n",
    "        g1_sigma = 5\n",
    "    if g2_sigma is None:\n",
    "        g2_sigma = 45\n",
    "    \n",
    "    # Set default bounds if not provided\n",
    "    if g1_amp_bounds is None:\n",
    "        g1_amp_bounds = (0.10 * max_flux, None)\n",
    "    if g2_amp_bounds is None:\n",
    "        g2_amp_bounds = (0.20 * max_flux, None)\n",
    "    if g1_center_bounds is None:\n",
    "        g1_center_bounds = (2700, 2900)\n",
    "    if g2_center_bounds is None:\n",
    "        g2_center_bounds = (2700, 2900)\n",
    "    if g1_sigma_bounds is None:\n",
    "        g1_sigma_bounds = (0.1, 15)\n",
    "    if g2_sigma_bounds is None:\n",
    "        g2_sigma_bounds = (30, 65)\n",
    "    \n",
    "    # Scale amplitude parameters and bounds by 1e17\n",
    "    g1_amp_scaled = g1_amp * 1e17\n",
    "    g2_amp_scaled = g2_amp * 1e17\n",
    "    \n",
    "    g1_amp_bounds_scaled = (g1_amp_bounds[0] * 1e17, g1_amp_bounds[1] * 1e17 if g1_amp_bounds[1] is not None else None)\n",
    "    g2_amp_bounds_scaled = (g2_amp_bounds[0] * 1e17, g2_amp_bounds[1] * 1e17 if g2_amp_bounds[1] is not None else None)\n",
    "    \n",
    "    # Define objective function for optimization (uses masked data)\n",
    "    def objective_function(params):\n",
    "        try:\n",
    "            model_values = double_gaussian_model(x_fit, *params)\n",
    "            if y_err_scaled is not None:\n",
    "                chi_squared = np.sum(((y_scaled - model_values) / y_err_scaled)**2)\n",
    "            else:\n",
    "                chi_squared = np.sum((y_scaled - model_values)**2)\n",
    "            return chi_squared\n",
    "        except:\n",
    "            return np.inf\n",
    "    \n",
    "    # Parameter bounds for optimization\n",
    "    # Format: [g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma]\n",
    "    bounds = [\n",
    "        (g1_amp_bounds_scaled[0], g1_amp_bounds_scaled[1]),\n",
    "        (g1_center_bounds[0], g1_center_bounds[1]),\n",
    "        (g1_sigma_bounds[0], g1_sigma_bounds[1]),\n",
    "        (g2_amp_bounds_scaled[0], g2_amp_bounds_scaled[1]),\n",
    "        (g2_center_bounds[0], g2_center_bounds[1]),\n",
    "        (g2_sigma_bounds[0], g2_sigma_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    best_result = None\n",
    "    best_chi_squared = np.inf\n",
    "    all_attempts = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Starting multi-strategy optimization...\")\n",
    "        print(f\"Parameter bounds: {bounds}\")\n",
    "\n",
    "    # Strategy 1: Grid Search\n",
    "    if use_grid_search:\n",
    "        if verbose:\n",
    "            print(\"\\n1. Performing grid search...\")\n",
    "        \n",
    "        # Create grid of starting points (reduced grid size due to 8 parameters)\n",
    "        n_grid_points = 2  # Reduced from 3 since we have 8 parameters now\n",
    "        grid_ranges = []\n",
    "        for lower, upper in bounds:\n",
    "            if upper is None:\n",
    "                upper = lower * 3  # Reasonable upper bound if None\n",
    "            grid_ranges.append(np.linspace(lower, upper, n_grid_points))\n",
    "        \n",
    "        grid_count = 0\n",
    "        for grid_point in product(*grid_ranges):\n",
    "            try:\n",
    "                popt, pcov = curve_fit(double_gaussian_model, x_fit, y_scaled, p0=list(grid_point), \n",
    "                                     bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                     method='trf', max_nfev=5000)\n",
    "                \n",
    "                chi_squared = objective_function(popt)\n",
    "                all_attempts.append(('grid', grid_point, popt, chi_squared))\n",
    "                \n",
    "                if chi_squared < best_chi_squared:\n",
    "                    best_chi_squared = chi_squared\n",
    "                    best_result = (popt, pcov)\n",
    "                    if verbose:\n",
    "                        print(f\"  New best from grid search: χ² = {chi_squared:.6f}\")\n",
    "                \n",
    "                grid_count += 1\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Grid search completed: {grid_count} successful fits\")\n",
    "    \n",
    "    # Strategy 2: Random Starting Points\n",
    "    if verbose:\n",
    "        print(f\"\\n2. Trying {n_random_starts} random starting points...\")\n",
    "    \n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    random_count = 0\n",
    "    \n",
    "    for i in range(n_random_starts):\n",
    "        # Generate random starting point within bounds\n",
    "        random_start = []\n",
    "        for lower, upper in bounds:\n",
    "            if upper is None:\n",
    "                upper = lower * 3\n",
    "            random_start.append(np.random.uniform(lower, upper))\n",
    "        \n",
    "        try:\n",
    "            popt, pcov = curve_fit(double_gaussian_model, x_fit, y_scaled, p0=random_start, \n",
    "                                 bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                 method='trf', max_nfev=5000)\n",
    "            \n",
    "            chi_squared = objective_function(popt)\n",
    "            all_attempts.append(('random', random_start, popt, chi_squared))\n",
    "            \n",
    "            if chi_squared < best_chi_squared:\n",
    "                best_chi_squared = chi_squared\n",
    "                best_result = (popt, pcov)\n",
    "                if verbose:\n",
    "                    print(f\"  New best from random start {i+1}: χ² = {chi_squared:.6f}\")\n",
    "            \n",
    "            random_count += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Random starts completed: {random_count} successful fits\")\n",
    "    \n",
    "    # Strategy 3: Differential Evolution (Global Optimizer)\n",
    "    if use_differential_evolution:\n",
    "        if verbose:\n",
    "            print(\"\\n3. Running differential evolution global optimizer...\")\n",
    "        \n",
    "        try:\n",
    "            # Use differential evolution to find global minimum\n",
    "            de_bounds = [(lower, upper if upper is not None else lower * 3) for lower, upper in bounds]\n",
    "            \n",
    "            result = differential_evolution(objective_function, de_bounds, \n",
    "                                          maxiter=1000, popsize=15, seed=42)\n",
    "            \n",
    "            if result.success:\n",
    "                # Refine with curve_fit\n",
    "                try:\n",
    "                    popt, pcov = curve_fit(double_gaussian_model, x_fit, y_scaled, p0=result.x, \n",
    "                                         bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                         method='trf', max_nfev=5000)\n",
    "                    \n",
    "                    chi_squared = objective_function(popt)\n",
    "                    all_attempts.append(('differential_evolution', result.x, popt, chi_squared))\n",
    "                    \n",
    "                    if chi_squared < best_chi_squared:\n",
    "                        best_chi_squared = chi_squared\n",
    "                        best_result = (popt, pcov)\n",
    "                        if verbose:\n",
    "                            print(f\"  New best from differential evolution: χ² = {chi_squared:.6f}\")\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Differential evolution failed: {e}\")\n",
    "    \n",
    "    # Strategy 4: Try the original starting point too\n",
    "    if verbose:\n",
    "        print(\"\\n4. Trying original starting point...\")\n",
    "    \n",
    "    original_p0 = [g1_amp_scaled, g1_center, g1_sigma, g2_amp_scaled, g2_center, g2_sigma]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(double_gaussian_model, x_fit, y_scaled, p0=original_p0, \n",
    "                             bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                             method='trf', max_nfev=10000)\n",
    "        \n",
    "        chi_squared = objective_function(popt)\n",
    "        all_attempts.append(('original', original_p0, popt, chi_squared))\n",
    "        \n",
    "        if chi_squared < best_chi_squared:\n",
    "            best_chi_squared = chi_squared\n",
    "            best_result = (popt, pcov)\n",
    "            if verbose:\n",
    "                print(f\"  Original starting point: χ² = {chi_squared:.6f}\")\n",
    "    except:\n",
    "        if verbose:\n",
    "            print(\"  Original starting point failed\")\n",
    "    \n",
    "    if best_result is None:\n",
    "        print(\"All optimization attempts failed!\")\n",
    "        print(\"Consider adjusting your initial parameter guesses or bounds.\")\n",
    "        print(\"Current values:\")\n",
    "        param_names = [\"g1_amp\", \"g1_center\", \"g1_sigma\", \"g2_amp\", \"g2_center\", \"g2_sigma\"]\n",
    "        \n",
    "        print(\"\\nInitial parameter values:\")\n",
    "        for name, val in zip(param_names, original_p0):\n",
    "            print(f\"{name} = {val}\")\n",
    "            \n",
    "        print(\"\\nParameter bounds:\")\n",
    "        for i, name in enumerate(param_names):\n",
    "            print(f\"{name}: ({bounds[i][0]}, {bounds[i][1]})\")\n",
    "            \n",
    "        print(\"\\nSuggestions:\")\n",
    "        print(\"- Try adjusting sigma values\")\n",
    "        print(\"- Make sure amplitude values match the scale of your flux\")\n",
    "        print(\"- Try using mask_ranges to exclude problematic regions\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    popt, pcov = best_result\n",
    "    if verbose:\n",
    "        print(f\"\\nOptimization complete!\")\n",
    "        print(f\"Best χ² = {best_chi_squared:.6f}\")\n",
    "        print(f\"Total successful attempts: {len(all_attempts)}\")\n",
    "        # Show top 5 results\n",
    "        all_attempts.sort(key=lambda x: x[3])  # Sort by chi-squared\n",
    "        print(f\"\\nTop 5 results:\")\n",
    "        for i, (method, start, final, chi2) in enumerate(all_attempts[:5]):\n",
    "            print(f\"  {i+1}. {method}: χ² = {chi2:.6f}\")\n",
    "    \n",
    "    # Continue with original processing code...\n",
    "    try:\n",
    "        # Calculate standard deviations (uncertainties) of parameters\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        \n",
    "        # Calculate best fit using scaled parameters and ORIGINAL x array\n",
    "        best_fit_scaled = double_gaussian_model(x, *popt)\n",
    "        \n",
    "        # Unscale the fitted results back to original units\n",
    "        best_fit = best_fit_scaled / 1e17\n",
    "        \n",
    "        # Unscale amplitude parameters and uncertainties\n",
    "        popt_unscaled = popt.copy()\n",
    "        popt_unscaled[0] /= 1e17  # g1_amp\n",
    "        popt_unscaled[3] /= 1e17  # g2_amp\n",
    "        \n",
    "        perr_unscaled = perr.copy()\n",
    "        perr_unscaled[0] /= 1e17  # g1_amp uncertainty\n",
    "        perr_unscaled[3] /= 1e17  # g2_amp uncertainty\n",
    "        # Calculate residuals and percent error using original scale and ALL data points\n",
    "        residuals = y - best_fit\n",
    "        percent_error = 100 * residuals / np.where(y != 0, y, np.inf)  # Avoid division by zero\n",
    "        \n",
    "        # Calculate R-squared using original y values\n",
    "        ss_total = np.sum((y - np.mean(y))**2)\n",
    "        ss_residual = np.sum(residuals**2)\n",
    "        r_squared = 1 - (ss_residual / ss_total)\n",
    "\n",
    "        # Calculate chi-squared using original y values and uncertainties\n",
    "        if y_err is not None:\n",
    "            chi_squared = np.sum((residuals / y_err)**2)\n",
    "            reduced_chi_squared = chi_squared / (len(x) - len(popt))\n",
    "        else:\n",
    "            chi_squared = np.sum(residuals**2)\n",
    "            reduced_chi_squared = chi_squared / (len(x) - len(popt))\n",
    "\n",
    "        # Also calculate chi-squared for ONLY the fitted points\n",
    "        if y_err is not None:\n",
    "            chi_squared_fitted = np.sum((residuals[mask] / y_err[mask])**2)\n",
    "            reduced_chi_squared_fitted = chi_squared_fitted / (len(x_fit) - len(popt))\n",
    "        else:\n",
    "            chi_squared_fitted = np.sum(residuals[mask]**2)\n",
    "            reduced_chi_squared_fitted = chi_squared_fitted / (len(x_fit) - len(popt))\n",
    "        \n",
    "        # Calculate individual components - need to unscale amplitude parameters\n",
    "        components = calc_components_No_Exponential(x, popt_unscaled)\n",
    "        \n",
    "        # Create output report\n",
    "        param_names = ['g1_amplitude', 'g1_center', 'g1_sigma', \n",
    "                      'g2_amplitude', 'g2_center', 'g2_sigma']\n",
    "        \n",
    "        fit_report = \"Multi-Strategy Fit Results with Masking:\\n\"\n",
    "        fit_report += f\"Data points used for fitting: {len(x_fit)}/{len(x)}\\n\"\n",
    "        fit_report += f\"R-squared (all data): {r_squared:.6f}\\n\"\n",
    "        fit_report += f\"Chi-squared (all data): {chi_squared:.6f}\\n\"\n",
    "        fit_report += f\"Reduced chi-squared (all data): {reduced_chi_squared:.6f}\\n\"\n",
    "        fit_report += f\"Chi-squared (fitted data only): {chi_squared_fitted:.6f}\\n\"\n",
    "        fit_report += f\"Reduced chi-squared (fitted data only): {reduced_chi_squared_fitted:.6f}\\n\"\n",
    "        fit_report += f\"Total optimization attempts: {len(all_attempts)}\\n\\n\"\n",
    "        fit_report += \"Parameters:\\n\"\n",
    "        \n",
    "        for name, val, err in zip(param_names, popt_unscaled, perr_unscaled):\n",
    "            fit_report += f\"{name} = {val:.6g} ± {err:.6g}\\n\"\n",
    "        \n",
    "        print(fit_report)\n",
    "        \n",
    "        if plot:\n",
    "            # Create figure\n",
    "            plt.rcParams['axes.grid'] = True\n",
    "            plt.rcParams['grid.alpha'] = 0.7\n",
    "            plt.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "            fig1 = plt.figure(figsize=(15, 12))\n",
    "            \n",
    "            # Create individual subplots with specific spacing\n",
    "            # First plot takes up first 3/7 of vertical space\n",
    "            ax0 = fig1.add_axes([0.1, 0.45, 0.8, 0.45])  # [left, bottom, width, height]\n",
    "            \n",
    "            # Second plot below with some space\n",
    "            ax1 = fig1.add_axes([0.1, 0.25, 0.8, 0.15], sharex=ax0)\n",
    "            \n",
    "            # Third plot immediately below second plot with no gap\n",
    "            ax2 = fig1.add_axes([0.1, 0.1, 0.8, 0.15], sharex=ax0)\n",
    "            \n",
    "            # Hide x-labels for first two plots\n",
    "            plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "            plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "            \n",
    "            # Store axes in a list for easy access later\n",
    "            axes = [ax0, ax1, ax2]\n",
    "            \n",
    "            # Plot 1: Overall fit with components\n",
    "            # Plot all data points\n",
    "            axes[0].step(x, y, where='mid', linewidth=2.25, color='#60B5FF', label='All Data', zorder=1)\n",
    "            axes[0].fill_between(x, y - y_err, y + y_err, color=\"#60B5FF\", alpha=0.3, zorder=0, step='mid', label=r\"2$\\sigma$ Error\")\n",
    "\n",
    "            # Highlight masked (excluded) regions as separate step plots\n",
    "            if not np.all(mask):\n",
    "                # Find continuous masked regions\n",
    "                masked_indices = np.where(~mask)[0]\n",
    "                if len(masked_indices) > 0:\n",
    "                    # Group consecutive indices\n",
    "                    groups = []\n",
    "                    current_group = [masked_indices[0]]\n",
    "                    \n",
    "                    for i in range(1, len(masked_indices)):\n",
    "                        if masked_indices[i] == masked_indices[i-1] + 1:\n",
    "                            current_group.append(masked_indices[i])\n",
    "                        else:\n",
    "                            groups.append(current_group)\n",
    "                            current_group = [masked_indices[i]]\n",
    "                    groups.append(current_group)\n",
    "                    \n",
    "                    # Plot each group separately\n",
    "                    for i, group in enumerate(groups):\n",
    "                        label = 'Masked Data' if i == 0 else None\n",
    "                        axes[0].step(x[group], y[group], where='mid', linewidth=2.25, color='red', alpha=0.7, \n",
    "                                   label=label, zorder=2)\n",
    "                        axes[0].fill_between(x[group], y[group] - y_err[group], y[group] + y_err[group], \n",
    "                                           color=\"red\", alpha=0.2, zorder=0, step='mid')\n",
    "            \n",
    "            axes[0].plot(x, best_fit, '-', linewidth=2.25, color='black', label='Best fit', zorder=4)\n",
    "            axes[0].plot(x, components['gaussian1'], '-', linewidth=4.5, color='#a714ff', label='Narrow component', zorder=2)\n",
    "            axes[0].plot(x, components['gaussian2'], '-', linewidth=4.5, color='#ff14f5', label='Broad component', zorder=3)\n",
    "            axes[0].axhline(y=0, linestyle='-', linewidth=3.0, color='#ffbb14', label='Exponential component', zorder=1)\n",
    "            \n",
    "            # Mark the centers of the Gaussian components\n",
    "            axes[0].axvline(x=popt_unscaled[1], color='#a714ff', linestyle=':', alpha=0.7)\n",
    "            axes[0].axvline(x=popt_unscaled[4], color='#ff14f5', linestyle=':', alpha=0.7)\n",
    "            \n",
    "            axes[0].legend(facecolor=\"white\", labelcolor=\"black\", fontsize=12, frameon=True, fancybox=True, shadow=True, \n",
    "                           edgecolor=\"black\", borderpad=1, handlelength=4.0)  \n",
    "                           \n",
    "            axes[0].set_ylabel(r'Flux [$erg s^{-1} cm^{-2} \\AA^{-1}$]', size='14', color=\"black\")\n",
    "            axes[0].set_title(title, fontsize=14)\n",
    "            \n",
    "            # Plot 2: Residuals\n",
    "            axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot residuals for fitted points\n",
    "            axes[1].scatter(x[mask], residuals[mask], marker='o', s=30, c='#00FF9C', edgecolors=\"black\", alpha=0.7, label='Fitted')\n",
    "            \n",
    "            # Plot residuals for masked points (if any)\n",
    "            if not np.all(mask):\n",
    "                axes[1].scatter(x[~mask], residuals[~mask], marker='x', s=40, c='red', alpha=0.7, label='Masked')\n",
    "            \n",
    "            axes[1].fill_between(x, 0 - y_err, 0 + y_err, color=\"#60B5FF\", alpha=0.3, zorder=0)\n",
    "            \n",
    "            if not np.all(mask):\n",
    "                axes[1].legend(fontsize=10)\n",
    "            \n",
    "            axes[1].set_ylabel('Residuals', size='14', color='black')\n",
    "            \n",
    "            # Plot 3: Percent error\n",
    "            axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot percent error for fitted points\n",
    "            axes[2].scatter(x[mask], percent_error[mask], marker='o', s=30, c='#00FF9C', edgecolors=\"black\", alpha=0.7, label='Fitted')\n",
    "            \n",
    "            # Plot percent error for masked points (if any)\n",
    "            if not np.all(mask):\n",
    "                axes[2].scatter(x[~mask], percent_error[~mask], marker='x', s=40, c='red', alpha=0.7, label='Masked')\n",
    "\n",
    "            # Filter out infinite or very large percent errors for better visualization\n",
    "            valid_percent = np.where(np.abs(percent_error) < 1000, percent_error, np.nan)\n",
    "            max_err = np.nanmax(np.abs(valid_percent))\n",
    "            if np.isfinite(max_err) and max_err > 0:\n",
    "                y_limit = min(max_err * 1.2, 130)  # Limit to max error or 130%, whichever is smaller\n",
    "                axes[2].set_ylim(-y_limit, y_limit)\n",
    "            \n",
    "            if not np.all(mask):\n",
    "                axes[2].legend(fontsize=10)\n",
    "            \n",
    "            axes[2].set_xlabel(r'Rest Wavelength [$\\AA$]', size='14', color='black')\n",
    "            axes[2].set_ylabel('Percent Error [%]', size='14')\n",
    "            \n",
    "            # Make the axes thicker\n",
    "            for ax in axes:\n",
    "                ax.spines['top'].set_linewidth(2.5)     # Top border\n",
    "                ax.spines['right'].set_linewidth(2.5)   # Right border\n",
    "                ax.spines['left'].set_linewidth(2.5)    # Left border\n",
    "                ax.spines['bottom'].set_linewidth(2.5)  # Bottom border\n",
    "            \n",
    "                # You can also adjust the tick marks if needed\n",
    "                ax.tick_params(axis='both', which='major', width=2)  # Increase tick width\n",
    "                ax.tick_params(axis='both', which='minor', width=1)  # Minor ticks\n",
    "\n",
    "                ax.grid(visible=True, which='both', axis='both', linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "            # Use Times New Roman for a more formal look in publications\n",
    "            plt.rcParams['font.family'] = 'serif'\n",
    "            plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "            \n",
    "            # Set tick label size\n",
    "            for ax in axes:\n",
    "                ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "                ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "                ax.grid(visible=True, which='major', axis='both', linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        # Return results with unscaled parameters\n",
    "        results = {\n",
    "            'parameters': dict(zip(param_names, popt_unscaled)),\n",
    "            'uncertainties': dict(zip(param_names, perr_unscaled)),\n",
    "            'fit': best_fit,\n",
    "            'residuals': residuals,\n",
    "            'percent_error': percent_error,\n",
    "            'r_squared': r_squared,\n",
    "            'chi_squared': chi_squared,\n",
    "            'reduced_chi_squared': reduced_chi_squared,\n",
    "            'components': components\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error during results processing: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################################################################################\n",
    "def fit_MgII_spectrum_velocity(x, y, y_err=None, plot=True, \n",
    "                    mask=None,  # NEW: mask parameter\n",
    "                    mask_ranges=None,  # NEW: alternative way to specify mask ranges\n",
    "                    g1_amp=None,\n",
    "                    g2_amp=None,\n",
    "                    g1_sigma=None,\n",
    "                    g2_sigma=None,\n",
    "                    g1_center=None,\n",
    "                    g2_center=None,\n",
    "                    g1_amp_bounds=None,\n",
    "                    g2_amp_bounds=None,\n",
    "                    g1_sigma_bounds=None,  # Now used as g1_sigma is free\n",
    "                    g2_sigma_bounds=None,\n",
    "                    g1_center_bounds=None,\n",
    "                    g2_center_bounds=None,\n",
    "                    title=\"0.25 < z < 0.35 - MgII Doublet Fit\",\n",
    "                    n_random_starts=50,  # Number of random starting points to try\n",
    "                    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "                    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "                    verbose=True):\n",
    "    \"\"\"\n",
    "    Enhanced MgII doublet fitting with multiple optimization strategies and masking capability.\n",
    "    \n",
    "    This function tries multiple approaches:\n",
    "    1. Grid search over parameter space\n",
    "    2. Random starting points\n",
    "    3. Differential evolution (global optimizer)\n",
    "    4. Returns the best fit among all attempts\n",
    "    5. Supports masking to ignore specific data regions during fitting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array-like\n",
    "        Independent variable (velocity)\n",
    "    y : array-like\n",
    "        Dependent variable (flux)\n",
    "    y_err : array-like, optional\n",
    "        Uncertainties in y\n",
    "    plot : bool, optional\n",
    "        Whether to create plots (default: True)\n",
    "    mask : array-like of bool, optional\n",
    "        Boolean mask where True indicates points to INCLUDE in fit.\n",
    "        If None, all points are used.\n",
    "    mask_ranges : list of tuples, optional\n",
    "        List of (min, max) tuples defining ranges to EXCLUDE from fit.\n",
    "        E.g., [(-100, 100), (500, 600)] excludes -100 to 100 and 500 to 600.\n",
    "        This is an alternative to providing a mask array directly.\n",
    "    \n",
    "    Additional Parameters:\n",
    "    ---------------------\n",
    "    n_random_starts : int, optional\n",
    "        Number of random starting points to try (default: 50)\n",
    "    use_grid_search : bool, optional\n",
    "        Whether to perform grid search over parameter space (default: True)\n",
    "    use_differential_evolution : bool, optional\n",
    "        Whether to use differential evolution global optimizer (default: True)\n",
    "    verbose : bool, optional\n",
    "        Whether to print detailed optimization progress (default: True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle masking\n",
    "    if mask_ranges is not None:\n",
    "        # Create mask from ranges\n",
    "        mask = np.ones(len(x), dtype=bool)  # Start with all True (include all)\n",
    "        for min_val, max_val in mask_ranges:\n",
    "            mask = mask & ~((x >= min_val) & (x <= max_val))  # Exclude ranges\n",
    "        if verbose:\n",
    "            excluded_points = len(x) - np.sum(mask)\n",
    "            print(f\"Masking {excluded_points} points from {len(mask_ranges)} ranges: {mask_ranges}\")\n",
    "    \n",
    "    elif mask is not None:\n",
    "        # Use provided mask\n",
    "        mask = np.array(mask, dtype=bool)\n",
    "        if len(mask) != len(x):\n",
    "            raise ValueError(\"Mask length must match data length\")\n",
    "        if verbose:\n",
    "            excluded_points = len(x) - np.sum(mask)\n",
    "            print(f\"Using provided mask: excluding {excluded_points} points\")\n",
    "    else:\n",
    "        # No masking - include all points\n",
    "        mask = np.ones(len(x), dtype=bool)\n",
    "        if verbose:\n",
    "            print(\"No masking applied - using all data points\")\n",
    "    \n",
    "    # Apply mask to data\n",
    "    x_fit = x[mask]\n",
    "    y_fit = y[mask]\n",
    "    y_err_fit = y_err[mask] if y_err is not None else None\n",
    "    \n",
    "    if len(x_fit) == 0:\n",
    "        raise ValueError(\"No data points remaining after masking!\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Fitting {len(x_fit)} out of {len(x)} data points\")\n",
    "    \n",
    "    # Scale y values and uncertainties by 1e17 for fitting\n",
    "    y_scaled = y_fit * 1e17\n",
    "    y_err_scaled = y_err_fit * 1e17 if y_err_fit is not None else None\n",
    "    \n",
    "    # Scale amplitude guesses and bounds by 1e17\n",
    "    g1_amp_scaled = g1_amp * 1e17 if g1_amp is not None else None\n",
    "    g2_amp_scaled = g2_amp * 1e17 if g2_amp is not None else None\n",
    "    \n",
    "    g1_amp_bounds_scaled = None\n",
    "    if g1_amp_bounds is not None:\n",
    "        g1_amp_bounds_scaled = (g1_amp_bounds[0] * 1e17, \n",
    "                               g1_amp_bounds[1] * 1e17 if g1_amp_bounds[1] is not None else None)\n",
    "    \n",
    "    g2_amp_bounds_scaled = None\n",
    "    if g2_amp_bounds is not None:\n",
    "        g2_amp_bounds_scaled = (g2_amp_bounds[0] * 1e17, \n",
    "                               g2_amp_bounds[1] * 1e17 if g2_amp_bounds[1] is not None else None)\n",
    "    \n",
    "    # Define objective function for optimization (uses masked data)\n",
    "    def objective_function(params):\n",
    "        try:\n",
    "            model_values = double_gaussian_model_velocity(x_fit, *params)\n",
    "            if y_err_scaled is not None:\n",
    "                chi_squared = np.sum(((y_scaled - model_values) / y_err_scaled)**2)\n",
    "            else:\n",
    "                chi_squared = np.sum((y_scaled - model_values)**2)\n",
    "            return chi_squared\n",
    "        except:\n",
    "            return np.inf\n",
    "    \n",
    "    # Parameter bounds for optimization\n",
    "    # Order: [g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma]\n",
    "    bounds = [\n",
    "        (g1_amp_bounds_scaled[0], g1_amp_bounds_scaled[1]),\n",
    "        (g1_center_bounds[0], g1_center_bounds[1]),\n",
    "        (g1_sigma_bounds[0], g1_sigma_bounds[1]),\n",
    "        (g2_amp_bounds_scaled[0], g2_amp_bounds_scaled[1]),\n",
    "        (g2_center_bounds[0], g2_center_bounds[1]),\n",
    "        (g2_sigma_bounds[0], g2_sigma_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    best_result = None\n",
    "    best_chi_squared = np.inf\n",
    "    all_attempts = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Starting multi-strategy optimization...\")\n",
    "        print(f\"Parameter bounds: {bounds}\")\n",
    "    \n",
    "    # Strategy 1: Grid Search\n",
    "    if use_grid_search:\n",
    "        if verbose:\n",
    "            print(\"\\n1. Performing grid search...\")\n",
    "        \n",
    "        # Create grid of starting points\n",
    "        n_grid_points = 3  # Reduced from 5 since we have 6 parameters now\n",
    "        grid_ranges = []\n",
    "        for lower, upper in bounds:\n",
    "            if upper is None:\n",
    "                upper = lower * 3  # Reasonable upper bound if None\n",
    "            grid_ranges.append(np.linspace(lower, upper, n_grid_points))\n",
    "        \n",
    "        grid_count = 0\n",
    "        for grid_point in product(*grid_ranges):\n",
    "            try:\n",
    "                popt, pcov = curve_fit(double_gaussian_model_velocity, x_fit, y_scaled, p0=list(grid_point), \n",
    "                                     bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                     method='trf', max_nfev=5000)\n",
    "                \n",
    "                chi_squared = objective_function(popt)\n",
    "                all_attempts.append(('grid', grid_point, popt, chi_squared))\n",
    "                \n",
    "                if chi_squared < best_chi_squared:\n",
    "                    best_chi_squared = chi_squared\n",
    "                    best_result = (popt, pcov)\n",
    "                    if verbose:\n",
    "                        print(f\"  New best from grid search: χ² = {chi_squared:.6f}\")\n",
    "                \n",
    "                grid_count += 1\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Grid search completed: {grid_count} successful fits\")\n",
    "    \n",
    "    # Strategy 2: Random Starting Points\n",
    "    if verbose:\n",
    "        print(f\"\\n2. Trying {n_random_starts} random starting points...\")\n",
    "    \n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    random_count = 0\n",
    "    \n",
    "    for i in range(n_random_starts):\n",
    "        # Generate random starting point within bounds\n",
    "        random_start = []\n",
    "        for lower, upper in bounds:\n",
    "            if upper is None:\n",
    "                upper = lower * 3\n",
    "            random_start.append(np.random.uniform(lower, upper))\n",
    "        \n",
    "        try:\n",
    "            popt, pcov = curve_fit(double_gaussian_model_velocity, x_fit, y_scaled, p0=random_start, \n",
    "                                 bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                 method='trf', max_nfev=5000)\n",
    "            \n",
    "            chi_squared = objective_function(popt)\n",
    "            all_attempts.append(('random', random_start, popt, chi_squared))\n",
    "            \n",
    "            if chi_squared < best_chi_squared:\n",
    "                best_chi_squared = chi_squared\n",
    "                best_result = (popt, pcov)\n",
    "                if verbose:\n",
    "                    print(f\"  New best from random start {i+1}: χ² = {chi_squared:.6f}\")\n",
    "            \n",
    "            random_count += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Random starts completed: {random_count} successful fits\")\n",
    "    \n",
    "    # Strategy 3: Differential Evolution (Global Optimizer)\n",
    "    if use_differential_evolution:\n",
    "        if verbose:\n",
    "            print(\"\\n3. Running differential evolution global optimizer...\")\n",
    "        \n",
    "        try:\n",
    "            # Use differential evolution to find global minimum\n",
    "            de_bounds = [(lower, upper if upper is not None else lower * 3) for lower, upper in bounds]\n",
    "            \n",
    "            result = differential_evolution(objective_function, de_bounds, \n",
    "                                          maxiter=1000, popsize=15, seed=42)\n",
    "            \n",
    "            if result.success:\n",
    "                # Refine with curve_fit\n",
    "                try:\n",
    "                    popt, pcov = curve_fit(double_gaussian_model_velocity, x_fit, y_scaled, p0=result.x, \n",
    "                                         bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                         method='trf', max_nfev=5000)\n",
    "                    \n",
    "                    chi_squared = objective_function(popt)\n",
    "                    all_attempts.append(('differential_evolution', result.x, popt, chi_squared))\n",
    "                    \n",
    "                    if chi_squared < best_chi_squared:\n",
    "                        best_chi_squared = chi_squared\n",
    "                        best_result = (popt, pcov)\n",
    "                        if verbose:\n",
    "                            print(f\"  New best from differential evolution: χ² = {chi_squared:.6f}\")\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Differential evolution failed: {e}\")\n",
    "    \n",
    "    # Strategy 4: Try the original starting point too\n",
    "    if verbose:\n",
    "        print(\"\\n4. Trying original starting point...\")\n",
    "    \n",
    "    original_p0 = [g1_amp_scaled, g1_center, g1_sigma, g2_amp_scaled, g2_center, g2_sigma]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(double_gaussian_model_velocity, x_fit, y_scaled, p0=original_p0, \n",
    "                             bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                             method='trf', max_nfev=10000)\n",
    "        \n",
    "        chi_squared = objective_function(popt)\n",
    "        all_attempts.append(('original', original_p0, popt, chi_squared))\n",
    "        \n",
    "        if chi_squared < best_chi_squared:\n",
    "            best_chi_squared = chi_squared\n",
    "            best_result = (popt, pcov)\n",
    "            if verbose:\n",
    "                print(f\"  Original starting point: χ² = {chi_squared:.6f}\")\n",
    "    except:\n",
    "        if verbose:\n",
    "            print(\"  Original starting point failed\")\n",
    "    \n",
    "    if best_result is None:\n",
    "        print(\"All optimization attempts failed!\")\n",
    "        return None\n",
    "    \n",
    "    popt, pcov = best_result\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nOptimization complete!\")\n",
    "        print(f\"Best χ² = {best_chi_squared:.6f}\")\n",
    "        print(f\"Total successful attempts: {len(all_attempts)}\")\n",
    "        \n",
    "        # Show top 5 results\n",
    "        all_attempts.sort(key=lambda x: x[3])  # Sort by chi-squared\n",
    "        print(f\"\\nTop 5 results:\")\n",
    "        for i, (method, start, final, chi2) in enumerate(all_attempts[:5]):\n",
    "            print(f\"  {i+1}. {method}: χ² = {chi2:.6f}\")\n",
    "    \n",
    "    # Continue with original processing code...\n",
    "    try:\n",
    "        # Calculate standard deviations (uncertainties) of parameters\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        \n",
    "        # Scale amplitude parameters and uncertainties back to original scale\n",
    "        popt_unscaled = popt.copy()\n",
    "        popt_unscaled[0] /= 1e17  # g1_amp\n",
    "        popt_unscaled[3] /= 1e17  # g2_amp\n",
    "        \n",
    "        perr_unscaled = perr.copy()\n",
    "        perr_unscaled[0] /= 1e17  # g1_amp uncertainty\n",
    "        perr_unscaled[3] /= 1e17  # g2_amp uncertainty\n",
    "\n",
    "        # Calculate best fit using unscaled parameters and ORIGINAL x array\n",
    "        best_fit = double_gaussian_model_velocity(x, *popt_unscaled)\n",
    "        \n",
    "        # Calculate residuals and percent error using original y values and ALL data points\n",
    "        residuals = y - best_fit\n",
    "        percent_error = 100 * residuals / np.where(y != 0, y, np.inf)\n",
    "        \n",
    "        # Calculate R-squared using original y values\n",
    "        ss_total = np.sum((y - np.mean(y))**2)\n",
    "        ss_residual = np.sum(residuals**2)\n",
    "        r_squared = 1 - (ss_residual / ss_total)\n",
    "        \n",
    "        # Calculate chi-squared using original y values and uncertainties\n",
    "        if y_err is not None:\n",
    "            chi_squared = np.sum((residuals / y_err)**2)\n",
    "            reduced_chi_squared = chi_squared / (len(x) - len(popt))\n",
    "        else:\n",
    "            chi_squared = np.sum(residuals**2)\n",
    "            reduced_chi_squared = chi_squared / (len(x) - len(popt))\n",
    "        \n",
    "        # Also calculate chi-squared for ONLY the fitted points\n",
    "        if y_err is not None:\n",
    "            chi_squared_fitted = np.sum((residuals[mask] / y_err[mask])**2)\n",
    "            reduced_chi_squared_fitted = chi_squared_fitted / (len(x_fit) - len(popt))\n",
    "        else:\n",
    "            chi_squared_fitted = np.sum(residuals[mask]**2)\n",
    "            reduced_chi_squared_fitted = chi_squared_fitted / (len(x_fit) - len(popt))\n",
    "        \n",
    "        # Calculate individual components using unscaled parameters\n",
    "        components = calc_components_velocity(x, popt_unscaled)\n",
    "        \n",
    "        # Create output report\n",
    "        param_names = ['g1_amplitude', 'g1_center', 'g1_sigma', \n",
    "                      'g2_amplitude', 'g2_center', 'g2_sigma']\n",
    "        \n",
    "        fit_report = \"Multi-Strategy Fit Results with Masking:\\n\"\n",
    "        fit_report += f\"Data points used for fitting: {len(x_fit)}/{len(x)}\\n\"\n",
    "        fit_report += f\"R-squared (all data): {r_squared:.6f}\\n\"\n",
    "        fit_report += f\"Chi-squared (all data): {chi_squared:.6f}\\n\"\n",
    "        fit_report += f\"Reduced chi-squared (all data): {reduced_chi_squared:.6f}\\n\"\n",
    "        fit_report += f\"Chi-squared (fitted data only): {chi_squared_fitted:.6f}\\n\"\n",
    "        fit_report += f\"Reduced chi-squared (fitted data only): {reduced_chi_squared_fitted:.6f}\\n\"\n",
    "        fit_report += f\"Total optimization attempts: {len(all_attempts)}\\n\\n\"\n",
    "        fit_report += \"Parameters:\\n\"\n",
    "        \n",
    "        for name, val, err in zip(param_names, popt_unscaled, perr_unscaled):\n",
    "            fit_report += f\"{name} = {val:.6g} ± {err:.6g}\\n\"\n",
    "        \n",
    "        print(fit_report)\n",
    "        \n",
    "        if plot:\n",
    "            # Create figure\n",
    "            plt.rcParams['axes.grid'] = True\n",
    "            plt.rcParams['grid.alpha'] = 0.7\n",
    "            plt.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "            fig1 = plt.figure(figsize=(15, 12))\n",
    "            \n",
    "            # Create individual subplots with specific spacing\n",
    "            ax0 = fig1.add_axes([0.1, 0.45, 0.8, 0.45])  # [left, bottom, width, height]\n",
    "            ax1 = fig1.add_axes([0.1, 0.25, 0.8, 0.15], sharex=ax0)\n",
    "            ax2 = fig1.add_axes([0.1, 0.1, 0.8, 0.15], sharex=ax0)\n",
    "            \n",
    "            # Hide x-labels for first two plots\n",
    "            plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "            plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "            \n",
    "            axes = [ax0, ax1, ax2]\n",
    "            \n",
    "            # Plot 1: Overall fit with components (using original y values)\n",
    "            # Plot all data points\n",
    "            axes[0].step(x, y, where='mid', linewidth=2.25, color='#60B5FF', label='All Data', zorder=1)\n",
    "            axes[0].fill_between(x, y - y_err, y + y_err, color=\"#60B5FF\", alpha=0.3, zorder=0, step='mid', label=r\"2$\\sigma$ Error\")\n",
    "\n",
    "            # Highlight masked (excluded) regions as separate step plots\n",
    "            if not np.all(mask):\n",
    "                # Find continuous masked regions\n",
    "                masked_indices = np.where(~mask)[0]\n",
    "                if len(masked_indices) > 0:\n",
    "                    # Group consecutive indices\n",
    "                    groups = []\n",
    "                    current_group = [masked_indices[0]]\n",
    "                    \n",
    "                    for i in range(1, len(masked_indices)):\n",
    "                        if masked_indices[i] == masked_indices[i-1] + 1:\n",
    "                            current_group.append(masked_indices[i])\n",
    "                        else:\n",
    "                            groups.append(current_group)\n",
    "                            current_group = [masked_indices[i]]\n",
    "                    groups.append(current_group)\n",
    "                    \n",
    "                    # Plot each group separately\n",
    "                    for i, group in enumerate(groups):\n",
    "                        label = 'Masked Data' if i == 0 else None\n",
    "                        axes[0].step(x[group], y[group], where='mid', linewidth=2.25, color='red', alpha=0.7, \n",
    "                                   label=label, zorder=2)\n",
    "                        axes[0].fill_between(x[group], y[group] - y_err[group], y[group] + y_err[group], \n",
    "                                           color=\"red\", alpha=0.2, zorder=0, step='mid')\n",
    "            \n",
    "            axes[0].plot(x, best_fit, '-', linewidth=2.25, color='black', label='Best fit', zorder=4)\n",
    "            axes[0].plot(x, components['gaussian1'], '-', linewidth=4.5, color='#a714ff', label='Narrow component', zorder=2)\n",
    "            axes[0].plot(x, components['gaussian2'], '-', linewidth=4.5, color='#ff14f5', label='Broad component', zorder=3)\n",
    "            \n",
    "            # Mark the centers of the Gaussian components\n",
    "            axes[0].plot(x, np.full(len(x), 0), color='#ffbb14', linestyle='-', linewidth=4.5, zorder=1, label=\"Exponential Component\")\n",
    "\n",
    "            axes[0].axvline(x=popt_unscaled[1], color='#a714ff', linestyle=':', alpha=0.7)\n",
    "            axes[0].axvline(x=popt_unscaled[4], color='#ff14f5', linestyle=':', alpha=0.7)\n",
    "            \n",
    "            axes[0].legend(facecolor=\"white\", labelcolor=\"black\", fontsize=12, frameon=True, fancybox=True, shadow=True, \n",
    "                           edgecolor=\"black\", borderpad=1, handlelength=4.0)  \n",
    "                           \n",
    "            axes[0].set_ylabel(r'Flux [$erg s^{-1} cm^{-2} \\AA^{-1}$]', size='14', color=\"black\")\n",
    "            axes[0].set_title(title, fontsize=14)\n",
    "            \n",
    "            # Plot 2: Residuals (using original scale)\n",
    "            axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot residuals for fitted points\n",
    "            axes[1].scatter(x[mask], residuals[mask], marker='o', s=30, c='#00FF9C', edgecolors=\"black\", alpha=0.7, label='Fitted')\n",
    "            \n",
    "            # Plot residuals for masked points (if any)\n",
    "            if not np.all(mask):\n",
    "                axes[1].scatter(x[~mask], residuals[~mask], marker='x', s=40, c='red', alpha=0.7, label='Masked')\n",
    "            \n",
    "            axes[1].fill_between(x, 0 - y_err, 0 + y_err, color=\"#60B5FF\", alpha=0.3, zorder=0)\n",
    "            \n",
    "            if not np.all(mask):\n",
    "                axes[1].legend(fontsize=10)\n",
    "            \n",
    "            axes[1].set_ylabel('Residuals', size='14', color='black')\n",
    "            \n",
    "            # Plot 3: Percent error\n",
    "            axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot percent error for fitted points\n",
    "            axes[2].scatter(x[mask], percent_error[mask], marker='o', s=30, c='#00FF9C', edgecolors=\"black\", alpha=0.7, label='Fitted')\n",
    "            \n",
    "            # Plot percent error for masked points (if any)\n",
    "            if not np.all(mask):\n",
    "                axes[2].scatter(x[~mask], percent_error[~mask], marker='x', s=40, c='red', alpha=0.7, label='Masked')\n",
    "\n",
    "            # Filter out infinite or very large percent errors for better visualization\n",
    "            valid_percent = np.where(np.abs(percent_error) < 1000, percent_error, np.nan)\n",
    "            max_err = np.nanmax(np.abs(valid_percent))\n",
    "            if np.isfinite(max_err) and max_err > 0:\n",
    "                y_limit = min(max_err * 1.2, 130)\n",
    "                axes[2].set_ylim(-y_limit, y_limit)\n",
    "            \n",
    "            if not np.all(mask):\n",
    "                axes[2].legend(fontsize=10)\n",
    "            \n",
    "            axes[2].set_xlabel(r'Velocity [km $s^{-1}$]', size='14', color='black')\n",
    "            axes[2].set_ylabel('Percent Error [%]', size='14')\n",
    "            \n",
    "            # Make the axes thicker\n",
    "            for ax in axes:\n",
    "                ax.spines['top'].set_linewidth(2.5)\n",
    "                ax.spines['right'].set_linewidth(2.5)\n",
    "                ax.spines['left'].set_linewidth(2.5)\n",
    "                ax.spines['bottom'].set_linewidth(2.5)\n",
    "            \n",
    "                ax.tick_params(axis='both', which='major', width=2)\n",
    "                ax.tick_params(axis='both', which='minor', width=1)\n",
    "                ax.grid(visible=True, which='both', axis='both', linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "            # Use Times New Roman for a more formal look in publications\n",
    "            plt.rcParams['font.family'] = 'serif'\n",
    "            plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "            \n",
    "            # Set tick label size\n",
    "            for ax in axes:\n",
    "                ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "                ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "                ax.grid(visible=True, which='major', axis='both', linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        # Return results with additional information about optimization attempts and masking\n",
    "        results = {\n",
    "            'parameters': dict(zip(param_names, popt_unscaled)),\n",
    "            'uncertainties': dict(zip(param_names, perr_unscaled)),\n",
    "            'fit': best_fit,\n",
    "            'residuals': residuals,\n",
    "            'percent_error': percent_error,\n",
    "            'r_squared': r_squared,\n",
    "            'chi_squared': chi_squared,\n",
    "            'reduced_chi_squared': reduced_chi_squared,\n",
    "            'chi_squared_fitted_only': chi_squared_fitted,\n",
    "            'reduced_chi_squared_fitted_only': reduced_chi_squared_fitted,\n",
    "            'components': components,\n",
    "            'optimization_attempts': len(all_attempts),\n",
    "            'best_chi_squared': best_chi_squared,\n",
    "            'all_attempts': all_attempts,\n",
    "            'mask': mask,\n",
    "            'n_fitted_points': len(x_fit),\n",
    "            'n_total_points': len(x)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during results processing: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_emission_line_wavelength_bounds(wavelength, flux, \n",
    "                             sigma_threshold=3.0, \n",
    "                             min_wavelength_width=200, \n",
    "                             max_wavelength_width=500,\n",
    "                             fractional_intensity=0.05,\n",
    "                             continuum_regions=None,\n",
    "                             smooth_kernel_size=3,\n",
    "                             return_diagnostics=False):\n",
    "    \"\"\"\n",
    "    Determine the boundaries of an emission line for spectral masking using wavelength arrays.\n",
    "    \n",
    "    This function implements a multi-criteria approach combining:\n",
    "    - Signal-to-noise ratio thresholding\n",
    "    - Wavelength-based limits\n",
    "    - Fractional peak intensity\n",
    "    - Derivative-based detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    wavelength : array-like\n",
    "        Wavelength array in Angstroms (absolute wavelength values)\n",
    "    flux : array-like\n",
    "        Flux array corresponding to wavelength\n",
    "    sigma_threshold : float, default=3.0\n",
    "        Number of sigma above continuum noise for detection\n",
    "    min_wavelength_width : float, default=200\n",
    "        Minimum wavelength width (Angstroms) to include around line center (±Angstroms)\n",
    "    max_wavelength_width : float, default=500\n",
    "        Maximum wavelength width (Angstroms) to consider for line boundaries (±Angstroms)\n",
    "    fractional_intensity : float, default=0.05\n",
    "        Fraction of peak intensity (0.05 = 5%) for boundary detection\n",
    "    continuum_regions : list of tuples, optional\n",
    "        [(wave_start1, wave_end1), (wave_start2, wave_end2)] for continuum estimation\n",
    "        If None, uses regions far from the line center (> max_wavelength_width * 1.5)\n",
    "    smooth_kernel_size : int, default=3\n",
    "        Size of smoothing kernel for derivative calculation\n",
    "    return_diagnostics : bool, default=False\n",
    "        If True, returns additional diagnostic information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bounds : tuple\n",
    "        (lower_wavelength, upper_wavelength) defining the emission line region in Angstroms\n",
    "    diagnostics : dict (optional)\n",
    "        Dictionary containing diagnostic information if return_diagnostics=True\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    wavelength = np.array(wavelength)\n",
    "    flux = np.array(flux)\n",
    "    \n",
    "    # First, find the approximate line center by locating the peak\n",
    "    peak_idx_initial = np.argmax(flux)\n",
    "    line_center = wavelength[peak_idx_initial]\n",
    "\n",
    "    # Define search region based on maximum wavelength width around the line center\n",
    "    search_mask = np.abs(wavelength - line_center) <= max_wavelength_width\n",
    "    search_indices = np.where(search_mask)[0]\n",
    "    \n",
    "    if len(search_indices) < 10:\n",
    "        raise ValueError(\"Search region too small. Check wavelength range and max_wavelength_width.\")\n",
    "    \n",
    "    # Estimate continuum and noise\n",
    "    if continuum_regions is None:\n",
    "        # Automatically define continuum regions far from the line center\n",
    "        continuum_mask = np.abs(wavelength - line_center) > max_wavelength_width * 1.5\n",
    "        if np.sum(continuum_mask) < 20:\n",
    "            # Fallback: use outer regions of the wavelength array\n",
    "            n_points = len(flux)\n",
    "            edge_fraction = 0.1\n",
    "            continuum_mask = np.zeros(n_points, dtype=bool)\n",
    "            continuum_mask[:int(n_points * edge_fraction)] = True\n",
    "            continuum_mask[-int(n_points * edge_fraction):] = True\n",
    "    else:\n",
    "        continuum_mask = np.zeros(len(wavelength), dtype=bool)\n",
    "        for wave_start, wave_end in continuum_regions:\n",
    "            region_mask = (wavelength >= wave_start) & (wavelength <= wave_end)\n",
    "            continuum_mask |= region_mask\n",
    "    \n",
    "    # Calculate continuum level and noise\n",
    "    continuum_flux = flux[continuum_mask]\n",
    "    if len(continuum_flux) < 5:\n",
    "        warnings.warn(\"Very few continuum points available. Results may be unreliable.\")\n",
    "        continuum_level = np.median(flux)\n",
    "        noise_level = np.std(flux) * 0.1  # Conservative estimate\n",
    "    else:\n",
    "        continuum_level = np.median(continuum_flux)\n",
    "        # Use median absolute deviation for robust noise estimation\n",
    "        noise_level = median_abs_deviation(continuum_flux, scale='normal')\n",
    "    \n",
    "    # Method 1: Signal-to-noise threshold\n",
    "    snr_threshold = continuum_level + sigma_threshold * noise_level\n",
    "    snr_mask = flux > snr_threshold\n",
    "    \n",
    "    # Method 2: Find peak and apply fractional intensity threshold\n",
    "    search_flux = flux[search_mask]\n",
    "    peak_idx_local = np.argmax(search_flux)\n",
    "    peak_idx_global = search_indices[peak_idx_local]\n",
    "    peak_flux = flux[peak_idx_global]\n",
    "    \n",
    "    fractional_threshold = continuum_level + fractional_intensity * (peak_flux - continuum_level)\n",
    "    fractional_mask = flux > fractional_threshold\n",
    "    \n",
    "    # Method 3: Derivative-based detection (smoothed)\n",
    "    if smooth_kernel_size > 1:\n",
    "        smoothed_flux = ndimage.uniform_filter1d(flux, smooth_kernel_size)\n",
    "    else:\n",
    "        smoothed_flux = flux.copy()\n",
    "    \n",
    "    # Calculate derivative\n",
    "    derivative = np.gradient(smoothed_flux, wavelength)\n",
    "    derivative_threshold = 3 * np.std(derivative[continuum_mask])\n",
    "    \n",
    "    # Find regions where derivative is significant\n",
    "    significant_derivative = np.abs(derivative) > derivative_threshold\n",
    "    \n",
    "    # Combine all methods\n",
    "    # Start with SNR detection as primary criterion\n",
    "    combined_mask = snr_mask.copy()\n",
    "    \n",
    "    # Expand to include fractional intensity regions\n",
    "    combined_mask |= fractional_mask\n",
    "    \n",
    "    # Further expand to include significant derivative regions near the line\n",
    "    nearby_mask = np.abs(wavelength - line_center) <= max_wavelength_width\n",
    "    combined_mask |= (significant_derivative & nearby_mask)\n",
    "    \n",
    "    # Find connected components and select the one containing the peak\n",
    "    labeled_regions, n_regions = ndimage.label(combined_mask)\n",
    "    \n",
    "    if n_regions == 0:\n",
    "        # Fallback: use minimum wavelength width around peak\n",
    "        peak_wavelength = wavelength[peak_idx_global]\n",
    "        min_wave_mask = np.abs(wavelength - peak_wavelength) <= min_wavelength_width\n",
    "        bounds_indices = np.where(min_wave_mask)[0]\n",
    "        lower_bound = wavelength[bounds_indices[0]]\n",
    "        upper_bound = wavelength[bounds_indices[-1]]\n",
    "    else:\n",
    "        # Select region containing the peak\n",
    "        peak_region_label = labeled_regions[peak_idx_global]\n",
    "        if peak_region_label == 0:\n",
    "            # Peak not in any detected region, use closest region\n",
    "            region_centers = []\n",
    "            for i in range(1, n_regions + 1):\n",
    "                region_indices = np.where(labeled_regions == i)[0]\n",
    "                region_center = np.mean(region_indices)\n",
    "                region_centers.append((i, region_center))\n",
    "            \n",
    "            # Find closest region to peak\n",
    "            distances = [abs(center - peak_idx_global) for _, center in region_centers]\n",
    "            closest_region_idx = np.argmin(distances)\n",
    "            peak_region_label = region_centers[closest_region_idx][0]\n",
    "        \n",
    "        # Get boundaries of the selected region\n",
    "        region_mask = labeled_regions == peak_region_label\n",
    "        region_indices = np.where(region_mask)[0]\n",
    "        \n",
    "        # Ensure minimum wavelength width\n",
    "        peak_wavelength = wavelength[peak_idx_global]\n",
    "        min_lower_wave = peak_wavelength - min_wavelength_width\n",
    "        min_upper_wave = peak_wavelength + min_wavelength_width\n",
    "        \n",
    "        # Get actual bounds\n",
    "        lower_bound = wavelength[region_indices[0]]\n",
    "        upper_bound = wavelength[region_indices[-1]]\n",
    "        \n",
    "        # Apply minimum width constraint\n",
    "        lower_bound = min(lower_bound, min_lower_wave)\n",
    "        upper_bound = max(upper_bound, min_upper_wave)\n",
    "        \n",
    "        # Apply maximum width constraint\n",
    "        max_lower_wave = peak_wavelength - max_wavelength_width\n",
    "        max_upper_wave = peak_wavelength + max_wavelength_width\n",
    "        \n",
    "        lower_bound = max(lower_bound, max_lower_wave)\n",
    "        upper_bound = min(upper_bound, max_upper_wave)\n",
    "    \n",
    "    bounds = (lower_bound, upper_bound)\n",
    "    \n",
    "    if return_diagnostics:\n",
    "        # Calculate final wavelength range\n",
    "        final_lower_wave = lower_bound\n",
    "        final_upper_wave = upper_bound\n",
    "        \n",
    "        diagnostics = {\n",
    "            'continuum_level': continuum_level,\n",
    "            'noise_level': noise_level,\n",
    "            'snr_threshold': snr_threshold,\n",
    "            'peak_flux': peak_flux,\n",
    "            'fractional_threshold': fractional_threshold,\n",
    "            'peak_wavelength': wavelength[peak_idx_global],\n",
    "            'line_center': line_center,\n",
    "            'wavelength_range_angstrom': (final_lower_wave, final_upper_wave),\n",
    "            'line_width_angstrom': final_upper_wave - final_lower_wave,\n",
    "            'masks': {\n",
    "                'snr_mask': snr_mask,\n",
    "                'fractional_mask': fractional_mask,\n",
    "                'derivative_mask': significant_derivative,\n",
    "                'combined_mask': combined_mask,\n",
    "                'final_mask': (wavelength >= lower_bound) & (wavelength <= upper_bound)\n",
    "            }\n",
    "        }\n",
    "        return bounds, diagnostics\n",
    "    \n",
    "    return bounds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Bounds_025_035 = find_emission_line_wavelength_bounds(\n",
    "                                                                                        MgII_ReStacked_Wave_Continuum_Scaled_025_035, \n",
    "                                                                                        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, \n",
    "                                                                                        sigma_threshold=3.0, \n",
    "                                                                                        min_wavelength_width=50, \n",
    "                                                                                        max_wavelength_width=200,\n",
    "                                                                                        fractional_intensity=0.05,\n",
    "                                                                                        continuum_regions=None,\n",
    "                                                                                        smooth_kernel_size=3,\n",
    "                                                                                        return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Bounds_035_045 = find_emission_line_wavelength_bounds(\n",
    "                                                                                        MgII_ReStacked_Wave_Continuum_Scaled_035_045, \n",
    "                                                                                        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, \n",
    "                                                                                        sigma_threshold=3.0, \n",
    "                                                                                        min_wavelength_width=200, \n",
    "                                                                                        max_wavelength_width=500,\n",
    "                                                                                        fractional_intensity=0.05,\n",
    "                                                                                        continuum_regions=None,\n",
    "                                                                                        smooth_kernel_size=3,\n",
    "                                                                                        return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Bounds_045_055 = find_emission_line_wavelength_bounds(\n",
    "                                                                                        MgII_ReStacked_Wave_Continuum_Scaled_045_055, \n",
    "                                                                                        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055, \n",
    "                                                                                        sigma_threshold=3.0, \n",
    "                                                                                        min_wavelength_width=200, \n",
    "                                                                                        max_wavelength_width=500,\n",
    "                                                                                        fractional_intensity=0.05,\n",
    "                                                                                        continuum_regions=None,\n",
    "                                                                                        smooth_kernel_size=3,\n",
    "                                                                                        return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Bounds_055_065 = find_emission_line_wavelength_bounds(\n",
    "                                                                                        MgII_ReStacked_Wave_Continuum_Scaled_055_065, \n",
    "                                                                                        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065, \n",
    "                                                                                        sigma_threshold=3.0, \n",
    "                                                                                        min_wavelength_width=200, \n",
    "                                                                                        max_wavelength_width=500,\n",
    "                                                                                        fractional_intensity=0.05,\n",
    "                                                                                        continuum_regions=None,\n",
    "                                                                                        smooth_kernel_size=3,\n",
    "                                                                                        return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Bounds_065_075 = find_emission_line_wavelength_bounds(\n",
    "                                                                                        MgII_ReStacked_Wave_Continuum_Scaled_065_075, \n",
    "                                                                                        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075, \n",
    "                                                                                        sigma_threshold=3.0, \n",
    "                                                                                        min_wavelength_width=200, \n",
    "                                                                                        max_wavelength_width=500,\n",
    "                                                                                        fractional_intensity=0.05,\n",
    "                                                                                        continuum_regions=None,\n",
    "                                                                                        smooth_kernel_size=3,\n",
    "                                                                                        return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Bounds_075_085 = find_emission_line_wavelength_bounds(\n",
    "                                                                                        MgII_ReStacked_Wave_Continuum_Scaled_075_085, \n",
    "                                                                                        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085, \n",
    "                                                                                        sigma_threshold=3.0, \n",
    "                                                                                        min_wavelength_width=200, \n",
    "                                                                                        max_wavelength_width=500,\n",
    "                                                                                        fractional_intensity=0.05,\n",
    "                                                                                        continuum_regions=None,\n",
    "                                                                                        smooth_kernel_size=3,\n",
    "                                                                                        return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Bounds_085_096 = find_emission_line_wavelength_bounds(\n",
    "                                                                                        MgII_ReStacked_Wave_Continuum_Scaled_085_096, \n",
    "                                                                                        MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096, \n",
    "                                                                                        sigma_threshold=3.0, \n",
    "                                                                                        min_wavelength_width=200, \n",
    "                                                                                        max_wavelength_width=500,\n",
    "                                                                                        fractional_intensity=0.05,\n",
    "                                                                                        continuum_regions=None,\n",
    "                                                                                        smooth_kernel_size=3,\n",
    "                                                                                        return_diagnostics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec200a-6504-4f80-87d3-c52809a5cce9",
   "metadata": {},
   "source": [
    "# <font color='#e55730' size=5 >Fitting the MgII</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92474b-053f-44c9-9c85-276f9b72eb74",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Fitting (in rest wavelength) the MgII emission from the continuum subtract spectra. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ae3fa-2f56-41a4-acd0-b056402bd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035 = fit_MgII_spectrum(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_025_035,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035,\n",
    "    # If you have error data, uncomment the next line:\n",
    "    y_err = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035 * 2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.1,\n",
    "    g1_sigma=7,              # Set narrow component width\n",
    "    g2_sigma=30,             # Set broad component width\n",
    "    g1_center=2800,          # Set narrow component center\n",
    "    g2_center=2794,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.3, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.05, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.9),      \n",
    "    g1_sigma_bounds=(0.1, 15),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(10, 50),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(2799, 2801),\n",
    "    g2_center_bounds=(2793, 2801),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.25 $\\leq$ z $\\less$ 0.35)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Wave_Continuum_Scaled_025_035), MgII_ReStacked_Wave_Continuum_Scaled_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Wave_Continuum_Scaled_Bounds_025_035[1], max(MgII_ReStacked_Wave_Continuum_Scaled_025_035))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ba0c3-26e3-4f77-967f-bc416f5a129d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c894b8-bb51-409a-8969-553007c4e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045 = fit_MgII_spectrum(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_035_045,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045,\n",
    "    # If you have error data, uncomment the next line:\n",
    "    y_err= MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045 *2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.80,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.1,\n",
    "    g1_sigma=9,              # Set narrow component width\n",
    "    g2_sigma=38,             # Set broad component width\n",
    "    g1_center=2800,          # Set narrow component center\n",
    "    g2_center=2799,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.6, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.01, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.5),      \n",
    "    g1_sigma_bounds=(0.1, 15),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 35),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(2799, 2801),\n",
    "    g2_center_bounds=(2798, 2801),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.35 $\\leq$ z $\\less$ 0.45)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Wave_Continuum_Scaled_035_045), MgII_ReStacked_Wave_Continuum_Scaled_Bounds_035_045[0]),\n",
    "        (MgII_ReStacked_Wave_Continuum_Scaled_Bounds_035_045[1], max(MgII_ReStacked_Wave_Continuum_Scaled_035_045))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f38f4-c637-499e-9646-a3a3eb1b2835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde6c9b-b41e-4871-af7e-60e983da112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055 = fit_MgII_spectrum(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_045_055,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055,\n",
    "    # If you have error data, uncomment the next line:\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055 *2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.80,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.28,\n",
    "    g1_sigma=9,              # Set narrow component width\n",
    "    g2_sigma=40,             # Set broad component width\n",
    "    g1_center=2800,          # Set narrow component center\n",
    "    g2_center=2795,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.55, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.4),      \n",
    "    g1_sigma_bounds=(0.1, 15),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(30, 65),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(2799, 2801),\n",
    "    g2_center_bounds=(2793, 2801),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.45 $\\leq$ z $\\less$ 0.55)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Wave_Continuum_Scaled_045_055), MgII_ReStacked_Wave_Continuum_Scaled_Bounds_045_055[0]),\n",
    "        (MgII_ReStacked_Wave_Continuum_Scaled_Bounds_045_055[1], max(MgII_ReStacked_Wave_Continuum_Scaled_045_055))]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d562ca9-e200-490d-abd3-fceaab370171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe5616-df7a-481d-9c5f-6ce167edb813",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065 = fit_MgII_spectrum(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_055_065,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065,\n",
    "    # If you have error data, uncomment the next line:\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065 *2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.70,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.20,\n",
    "    g1_sigma=9,              # Set narrow component width\n",
    "    g2_sigma=45,             # Set broad component width\n",
    "    g1_center=2800,          # Set narrow component center\n",
    "    g2_center=2798,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.5, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.30),      \n",
    "    g1_sigma_bounds=(0.1, 15),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(30, 65),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(2799, 2801),\n",
    "    g2_center_bounds=(2797, 2801),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.55 $\\leq$ z $\\less$ 0.65)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Wave_Continuum_Scaled_055_065), MgII_ReStacked_Wave_Continuum_Scaled_Bounds_055_065[0]),\n",
    "        (MgII_ReStacked_Wave_Continuum_Scaled_Bounds_055_065[1], max(MgII_ReStacked_Wave_Continuum_Scaled_055_065))]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e85433-199d-4325-ad08-6b4576a8ae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4427c1-bb95-4e98-8603-91c298921405",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075 = fit_MgII_spectrum(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_065_075,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075,\n",
    "    # If you have error data, uncomment the next line:\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075 *2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.23,\n",
    "    g1_sigma=9,              # Set narrow component width\n",
    "    g2_sigma=45,             # Set broad component width\n",
    "    g1_center=2800,          # Set narrow component center\n",
    "    g2_center=2795,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.05, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.25),      \n",
    "    g1_sigma_bounds=(0.1, 15),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 41),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(2799, 2805),\n",
    "    g2_center_bounds=(2790, 2805),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.65 $\\leq$ z $\\less$ 0.75)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Wave_Continuum_Scaled_065_075), MgII_ReStacked_Wave_Continuum_Scaled_Bounds_065_075[0]),\n",
    "        (MgII_ReStacked_Wave_Continuum_Scaled_Bounds_065_075[1], max(MgII_ReStacked_Wave_Continuum_Scaled_065_075))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3202718-8526-4c1a-88fa-a4c9cdca1eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266bf1e-7b85-4e94-9978-2a008c3122bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085 = fit_MgII_spectrum(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_075_085,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085,\n",
    "    # If you have error data, uncomment the next line:\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085 *2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.26,\n",
    "    g1_sigma=8.5,              # Set narrow component width\n",
    "    g2_sigma=45,             # Set broad component width\n",
    "    g1_center=2800,          # Set narrow component center\n",
    "    g2_center=2800,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.6, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.4),      \n",
    "    g1_sigma_bounds=(0.1, 15),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(30, 65),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(2799, 2801),\n",
    "    g2_center_bounds=(2799, 2801),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.75 $\\leq$ z $\\less$ 0.85)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Wave_Continuum_Scaled_075_085), MgII_ReStacked_Wave_Continuum_Scaled_Bounds_075_085[0]),\n",
    "        (MgII_ReStacked_Wave_Continuum_Scaled_Bounds_075_085[1], max(MgII_ReStacked_Wave_Continuum_Scaled_075_085))]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240310ca-a61c-43ff-bbb2-1bbe38256add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f561e-f2b2-4c58-a653-916cfe804ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096 = fit_MgII_spectrum(\n",
    "    MgII_ReStacked_Wave_Continuum_Scaled_085_096,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096,\n",
    "    # If you have error data, uncomment the next line:\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096 *2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.63,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.37,\n",
    "    g1_sigma=9,              # Set narrow component width\n",
    "    g2_sigma=45,             # Set broad component width\n",
    "    g1_center=2800,          # Set narrow component center\n",
    "    g2_center=2801,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.35, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.65),      \n",
    "    g1_sigma_bounds=(0.1, 15),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 42),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(2790, 2805),\n",
    "    g2_center_bounds=(2790, 2805),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.85 $\\leq$ z $\\leq$ 0.96)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Wave_Continuum_Scaled_085_096), MgII_ReStacked_Wave_Continuum_Scaled_Bounds_085_096[0]),\n",
    "        (MgII_ReStacked_Wave_Continuum_Scaled_Bounds_085_096[1], max(MgII_ReStacked_Wave_Continuum_Scaled_085_096))]),\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "plt.xlim(2550, 2960)  # Set your desired limits\n",
    "#plt.ylim(-0.5e-16, 1.25e-16)\n",
    "\n",
    "# Get current axes and set limits\n",
    "fig = plt.gcf()  # Get current figure\n",
    "axes = fig.get_axes()  # Get all axes\n",
    "\n",
    "axes[0].set_ylim(-0.5e-16, 1.5e-16)  # Set y-limits for first panel (adjust values as needed)\n",
    "axes[1].set_ylim(-0.3e-16, 0.3e-16)  # Set y-limits for second panel (adjust values as needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b564c2-fb83-4fa1-bbc9-2231f76b1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the returns from the fit_MgII_Spectrum.\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['residuals']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_025_035['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_035_045['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_045_055['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_055_065['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_065_075['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_075_085['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_085_096['uncertainties']['g2_amplitude']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6b048-e556-4afb-9561-51c3524ff20b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## <font color='#00879E' size=5 >Getting all the parameters from the rest wavelength two gaussian fits. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee0553-bfe0-42b8-9fde-b3e07ebc25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making arrays of the outputs of the Fit_MgII_Spectrum for all of the redshift ranges. \n",
    "These are used to make the panel plot below as well as for the velocities.\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Wave_Continuum_Scaled_Array = [MgII_ReStacked_Wave_Continuum_Scaled_025_035, MgII_ReStacked_Wave_Continuum_Scaled_035_045, MgII_ReStacked_Wave_Continuum_Scaled_045_055, MgII_ReStacked_Wave_Continuum_Scaled_055_065,\n",
    "                                                       MgII_ReStacked_Wave_Continuum_Scaled_065_075, MgII_ReStacked_Wave_Continuum_Scaled_075_085, MgII_ReStacked_Wave_Continuum_Scaled_085_096]\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Spec_Continuum_Scaled_Array = [MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055,\n",
    "                                                                         MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075,\n",
    "                                                                         MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096]\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Spec_Continuum_Scaled_SD_Array = [MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055,\n",
    "                                                                         MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075,\n",
    "                                                                         MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096]\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Spec_BestFit_Scaled_Array = [MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_035_045, \n",
    "                                                                       MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_055_065,\n",
    "                                                                       MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_075_085,\n",
    "                                                                       MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_085_096]\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Residuals_Continuum_Scaled_Array = [MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_035_045,\n",
    "                                                                              MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_055_065,\n",
    "                                                                              MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_075_085,\n",
    "                                                                              MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Residuals_085_096]\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Narrow_Gaussian_Fit_Continuum_Scaled_Array = [MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_035_045,\n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_055_065,\n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_075_085,\n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Narrow_Gaussian_085_096]\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Broad_Gaussian_Fit_Continuum_Scaled_Array = [MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_035_045,\n",
    "                                                                                       MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_055_065,\n",
    "                                                                                       MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_075_085,\n",
    "                                                                                       MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_BestFit_Broad_Gaussian_085_096]\n",
    "\n",
    "#MgII_Continuum_Removed_ReStacked_Broad_Gaussian_Expo_Continuum_Scaled_Array = [MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Expo_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Expo_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Expo_045_055,\n",
    "#                                                                              MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Expo_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Expo_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Expo_075_085,\n",
    "#                                                                              MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Expo_085_096]\n",
    "#\n",
    "MgII_Continuum_Removed_ReStacked_Narrow_Gaussian_Fit_Center_Continuum_Scaled_Array = [MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_035_045,\n",
    "                                                                                     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_055_065,\n",
    "                                                                                     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_075_085,\n",
    "                                                                                     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_085_096]\n",
    "\n",
    "MgII_Continuum_Removed_ReStacked_Broad_Gaussian_Fit_Center_Continuum_Scaled_Array = [MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_035_045,\n",
    "                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_055_065,\n",
    "                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_075_085,\n",
    "                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_085_096]\n",
    "\n",
    "redshift_labels = [\"Redshift: 0.25–0.35\", \"Redshift: 0.35–0.45\", \"Redshift: 0.45–0.55\", \"Redshift: 0.55–0.65\", \"Redshift: 0.65–0.75\", \"Redshift: 0.75–0.85\", \"Redshift: 0.85–0.96\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276254e-c926-4211-b6b1-75fdd77c1734",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Making a panel plot from the rest wavelength two gaussian fits. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d492ee-5cf2-413e-af91-dbff540bae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "n_bins = len(MgII_ReStacked_Wave_Continuum_Scaled_Array)\n",
    "n_cols = int(np.ceil(np.sqrt(n_bins)))\n",
    "n_rows = int(np.ceil(n_bins / n_cols))\n",
    "\n",
    "# Increase figure size to enlarge individual panels\n",
    "fig_Paper_Grid = plt.figure(figsize=(n_cols * 7.5, n_rows * 6.5))\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "\n",
    "# Calculate the indices of the last three plots\n",
    "last_three_indices = list(range(n_bins - 3, n_bins)) if n_bins >= 3 else list(range(n_bins))\n",
    "\n",
    "# No need to pre-compute global min/max values since we're not sharing axes between plots\n",
    "\n",
    "# Now create the plots with shared axes\n",
    "for i in range(n_bins):\n",
    "    x_data = MgII_ReStacked_Wave_Continuum_Scaled_Array[i]\n",
    "    y_data = MgII_Continuum_Removed_ReStacked_Spec_Continuum_Scaled_Array[i]\n",
    "    y_data_sd = MgII_Continuum_Removed_ReStacked_Spec_Continuum_Scaled_SD_Array[i] * 2\n",
    "    y_best_fit = MgII_Continuum_Removed_ReStacked_Spec_BestFit_Scaled_Array[i]\n",
    "    residuals = MgII_Continuum_Removed_ReStacked_Residuals_Continuum_Scaled_Array[i]\n",
    "    y_data_narrow = MgII_Continuum_Removed_ReStacked_Narrow_Gaussian_Fit_Continuum_Scaled_Array[i]\n",
    "    y_data_broad = MgII_Continuum_Removed_ReStacked_Broad_Gaussian_Fit_Continuum_Scaled_Array[i]\n",
    "    #y_data_expo = MgII_Continuum_Removed_ReStacked_Broad_Gaussian_Expo_Continuum_Scaled_Array[i]\n",
    "    center_narrow = MgII_Continuum_Removed_ReStacked_Narrow_Gaussian_Fit_Center_Continuum_Scaled_Array[i]\n",
    "    center_broad = MgII_Continuum_Removed_ReStacked_Broad_Gaussian_Fit_Center_Continuum_Scaled_Array[i]\n",
    "    redshift_label = redshift_labels[i]\n",
    "\n",
    "    # Create outer grid for rows and columns\n",
    "    outer_gs = fig_Paper_Grid.add_gridspec(n_rows, n_cols, wspace=0.1, hspace=0.1)\n",
    "    row, col = divmod(i, n_cols)\n",
    "\n",
    "    # Determine whether to show x-tick labels for the bottom panel\n",
    "    show_bottom_xticks = i in last_three_indices\n",
    "\n",
    "    # Create subgridspec for top and bottom panels (model and residuals)\n",
    "    inner_gs = outer_gs[row, col].subgridspec(2, 1, height_ratios=[3, 1], hspace=0.15)\n",
    "\n",
    "    # For the last three plots, don't share x-axis to avoid tick label conflicts\n",
    "    ax_top = fig_Paper_Grid.add_subplot(inner_gs[0])\n",
    "    ax_bottom = fig_Paper_Grid.add_subplot(inner_gs[1], sharex=ax_top)\n",
    "\n",
    "    # --- Top Panel (Model) ---\n",
    "    ax_top.step(x_data, y_data, color=\"#60B5FF\", linewidth=1.5, where=\"mid\", zorder=0, linestyle='-', label=\"Observed Data\")\n",
    "    ax_top.fill_between(x_data, y_data - y_data_sd, \n",
    "                 y_data + y_data_sd, color=\"#60B5FF\", alpha=0.3, zorder=0, step='mid', label=r\"2$\\sigma$ Error\")\n",
    "    \n",
    "    ax_top.plot(x_data, y_best_fit, color=\"black\", linewidth=2.5, label=\"Combined Model Fit\", zorder=4, linestyle='-')\n",
    "    ax_top.plot(x_data, y_data_narrow, color=\"#a714ff\", linewidth=4.5, label=\"Narrow Component\", zorder=2, linestyle='-')\n",
    "    ax_top.plot(x_data, y_data_broad, color=\"#ff14f5\", linewidth=4.5, label=\"Broad Component\", zorder=3, linestyle='-')\n",
    "\n",
    "    ax_top.plot(x_data, np.full(len(x_data), 0), color='#ffbb14', linestyle='-', linewidth=4.5, zorder=1, label=\"Exponential Component\")\n",
    "    #ax_top.plot(x_data, y_data_expo, '-', linewidth=3.0, color='#ffbb14', label='Exponential component', zorder=1)\n",
    "\n",
    "    # Mark the centers of the Gaussian components\n",
    "    ax_top.axvline(x=center_narrow, color='#a714ff', linestyle=':', alpha=0.7)\n",
    "    ax_top.axvline(x=center_broad, color='#ff14f5', linestyle=':', alpha=0.7)\n",
    "\n",
    "    ax_top.text(0.02, 0.96, redshift_label, transform=ax_top.transAxes,\n",
    "                fontsize=12, verticalalignment='top',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', edgecolor='black'))\n",
    "    \n",
    "    # Only show legend on the first panel (top-left)\n",
    "    if i == 0:\n",
    "        ax_top.legend(loc='upper right', fontsize=12, frameon=True, fancybox=True, shadow=True,\n",
    "                      borderpad=0.5, edgecolor='black', facecolor='w',\n",
    "                      handlelength=1.0, columnspacing=0.5, handleheight=1.0, labelspacing=0.25)\n",
    "\n",
    "    # Always define the labels, but they'll only be displayed based on position\n",
    "    ax_top.set_ylabel(r'Flux [$erg s^{-1} cm^{-2} \\AA^{-1}$]', size='14', color=\"black\")\n",
    "    \n",
    "    # Set individual panel limits\n",
    "    ymin, ymax = ax_top.get_ylim()\n",
    "    ax_top.set_ylim(ymin, ymax * 1.07)\n",
    "    \n",
    "    # Always hide x-tick labels on top panels\n",
    "    plt.setp(ax_top.get_xticklabels(), visible=False)\n",
    "\n",
    "    # --- Bottom Panel (Residuals) ---\n",
    "    ax_bottom.scatter(x_data, residuals, c=\"#00FF9C\", edgecolor=\"black\", s=20, label=\"Residuals\", marker='o')\n",
    "    ax_bottom.fill_between(x_data, 0 - y_data_sd, \n",
    "                 0 + y_data_sd, color=\"#60B5FF\", alpha=0.3, zorder=0)\n",
    "\n",
    "    ax_bottom.axhline(0, color=\"#000000\", linestyle='--', linewidth=1.5)    \n",
    "    \n",
    "    # Set x-axis label for all bottom panels\n",
    "    ax_bottom.set_xlabel(r\"Rest Wavelength [$\\AA$]\", fontsize=14)\n",
    "    ax_bottom.set_ylabel(\"Residuals\", fontsize=14)\n",
    "    \n",
    "    # Hide x-tick labels on bottom panels except for the last three plots\n",
    "    if not show_bottom_xticks:\n",
    "        plt.setp(ax_bottom.get_xticklabels(), visible=False)\n",
    "    \n",
    "    # Set specific y-limits for residuals in first row (row=0), first column (col=0)\n",
    "    if row == 0 and (col == 0):\n",
    "        # Set y-limit to ensure there are tick values above zero\n",
    "        # Adjust these values as needed based on your data range\n",
    "        ax_bottom.set_ylim(-0.40*1e-16, 0.40*1e-16)\n",
    "\n",
    "    # Set specific y-limits for residuals in first row (row=0), second and third columns (col=1, col=2)\n",
    "    if row == 0 and (col == 1):\n",
    "        # Set y-limit to ensure there are tick values above zero\n",
    "        # Adjust these values as needed based on your data range\n",
    "        ax_bottom.set_ylim(-0.10*1e-16, 0.10*1e-16)\n",
    "\n",
    "    # Set specific y-limits for residuals in first row (row=0), second and third columns (col=1, col=2)\n",
    "    if row == 0 and (col == 2):\n",
    "        # Set y-limit to ensure there are tick values above zero\n",
    "        # Adjust these values as needed based on your data range\n",
    "        ax_bottom.set_ylim(-0.15*1e-16, 0.15*1e-16)\n",
    "\n",
    "    # Set specific y-limits for residuals in first row (row=0), second and third columns (col=1, col=2)\n",
    "    if row == 1 and (col == 0):\n",
    "        # Set y-limit to ensure there are tick values above zero\n",
    "        # Adjust these values as needed based on your data range\n",
    "        ax_bottom.set_ylim(-0.20*1e-16, 0.20*1e-16)\n",
    "\n",
    "    # Set specific y-limits for residuals in first row (row=0), second and third columns (col=1, col=2)\n",
    "    if row == 1 and (col == 1):\n",
    "        # Set y-limit to ensure there are tick values above zero\n",
    "        # Adjust these values as needed based on your data range\n",
    "        ax_bottom.set_ylim(-0.15*1e-16, 0.15*1e-16)\n",
    "\n",
    "    # Set specific y-limits for residuals in second row (row=1), third column (col=2)\n",
    "    if row == 1 and col == 2:\n",
    "        # Set y-limit to ensure there are tick values above zero\n",
    "        # Adjust these values as needed based on your data range\n",
    "        ax_bottom.set_ylim(-0.15*1e-16, 0.15*1e-16)\n",
    "\n",
    "    # Set specific y-limits for residuals in second row (row=1), third column (col=2)\n",
    "    if row == 2 and col == 0:\n",
    "        # Set y-limit to ensure there are tick values above zero\n",
    "        # Adjust these values as needed based on your data range\n",
    "        ax_top.set_ylim(-0.5e-16, 1.5e-16)\n",
    "        ax_bottom.set_ylim(-0.25*1e-16, 0.25*1e-16)\n",
    "        \n",
    "        ax_top.set_xlim(2550, 2960)\n",
    "        ax_bottom.set_xlim(2550, 2960)\n",
    "    \n",
    "    ax_bottom.grid(True)\n",
    "\n",
    "    # --- Styling for both axes ---\n",
    "    for ax in [ax_top, ax_bottom]:\n",
    "        ax.spines['top'].set_linewidth(2.5)\n",
    "        ax.spines['right'].set_linewidth(2.5)\n",
    "        ax.spines['left'].set_linewidth(2.5)\n",
    "        ax.spines['bottom'].set_linewidth(2.5)\n",
    "        ax.tick_params(axis='both', which='major', width=2, labelsize=12)\n",
    "        ax.tick_params(axis='both', which='minor', width=1, labelsize=10)\n",
    "        ax.tick_params(axis='both', which='both', direction='in', length=6)\n",
    "    \n",
    "    # Only show y-axis labels on leftmost panels\n",
    "    if col != 0:\n",
    "        ax_top.set_ylabel(\"\")\n",
    "        ax_bottom.set_ylabel(\"\")\n",
    "        ax_top.set_xticklabels([])\n",
    "        \n",
    "    # Show x-axis labels on bottom row panels and specific panels in row 1, columns 1 and 2\n",
    "    # Note: row and col are zero-indexed, so row=1 is second row, col=1 is second column, col=2 is third column\n",
    "    if row != n_rows - 1 and not (row == 1 and (col == 1 or col == 2)) and not show_bottom_xticks:\n",
    "        ax_bottom.set_xlabel(\"\")\n",
    "    \n",
    "    # Final check for visibility\n",
    "    if show_bottom_xticks:\n",
    "        # Make sure x-tick labels are visible on bottom panel\n",
    "        ax_bottom.xaxis.set_tick_params(labelbottom=True)\n",
    "        plt.setp(ax_bottom.get_xticklabels(), visible=True)\n",
    "        # Force matplotlib to draw the ticks\n",
    "        ax_bottom.xaxis.set_major_formatter(plt.ScalarFormatter())\n",
    "    else:\n",
    "        # Hide x-tick labels on bottom panel\n",
    "        ax_bottom.xaxis.set_tick_params(labelbottom=False)\n",
    "        plt.setp(ax_bottom.get_xticklabels(), visible=False)\n",
    "    \n",
    "# Final layout adjustments\n",
    "plt.tight_layout()\n",
    "\n",
    "# One final pass to ensure the last three plots have visible x-tick labels\n",
    "for i in last_three_indices:\n",
    "    row, col = divmod(i, n_cols)\n",
    "    ax = plt.gcf().get_axes()[i*2 + 1]  # Get the bottom panel of the i-th plot\n",
    "    ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    plt.setp(ax.get_xticklabels(), visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeba5a2-e04c-4534-9729-90b1c032a8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f57d0f-4baf-4977-9c18-0613b4acde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_simple_mean_with_std(values, std_values):\n",
    "    \"\"\"\n",
    "    Calculate simple mean and its standard deviation using error propagation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    values : array-like\n",
    "        Array of measurement values.\n",
    "    std_values : array-like\n",
    "        Array of standard deviations for each measurement value.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mean_value : float\n",
    "        Simple mean of the input values.\n",
    "    mean_std : float\n",
    "        Standard deviation of the mean.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays if they aren't already\n",
    "    values = np.array(values)\n",
    "    std_values = np.array(std_values)\n",
    "    \n",
    "    # Calculate simple mean\n",
    "    mean_value = np.mean(values)\n",
    "    \n",
    "    # Calculate standard deviation of the mean using error propagation\n",
    "    # For a mean of measurements with individual uncertainties:\n",
    "    # σ_mean = sqrt(sum(σ_i²)) / n\n",
    "    n = len(values)\n",
    "    mean_std = np.sqrt(np.sum(std_values**2)) / n\n",
    "    \n",
    "    # Alternative: standard error of the mean if your std_values are not measurement errors\n",
    "    # but rather standard deviations of the sample\n",
    "    # mean_std_alt = np.std(values, ddof=1) / np.sqrt(n)\n",
    "    \n",
    "    return mean_value, mean_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb039514-67c1-44a0-ad21-5566135e1c09",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Fitting (in velocity) the MgII emission from the continuum subtract spectra. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef443e-2626-43a9-9b49-210f7b95d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the average of the center of the narrow and the broad from the Fit_MgII_Spectrum.\n",
    "Then getting the velocity of the line.\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_025_035 = calculate_simple_mean_with_std(\n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_025_035]), \n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_025_035]))\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_035_045 = calculate_simple_mean_with_std(\n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_035_045]), \n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_035_045]))\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_045_055 = calculate_simple_mean_with_std(\n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_045_055]), \n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_045_055]))\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_055_065 = calculate_simple_mean_with_std(\n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_055_065]), \n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_055_065]))\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_065_075 = calculate_simple_mean_with_std(\n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_065_075]), \n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_065_075]))\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_075_085 = calculate_simple_mean_with_std(\n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_075_085]), \n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_075_085]))\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_085_096 = calculate_simple_mean_with_std(\n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_085_096]), \n",
    "                                                                                                                            ([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Narrow_Center_SD_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Broad_Center_SD_085_096]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_SD_025_035 = velocity_of_the_center(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_025_035, \n",
    "                                                                                                                 MgII_doublet_unresolved)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_SD_035_045 = velocity_of_the_center(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_035_045, \n",
    "                                                                                                                 MgII_doublet_unresolved)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_SD_045_055 = velocity_of_the_center(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_045_055, \n",
    "                                                                                                                 MgII_doublet_unresolved)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_SD_055_065 = velocity_of_the_center(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_055_065, \n",
    "                                                                                                                 MgII_doublet_unresolved)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_SD_065_075 = velocity_of_the_center(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_065_075, \n",
    "                                                                                                                 MgII_doublet_unresolved)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_SD_075_085 = velocity_of_the_center(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_075_085, \n",
    "                                                                                                                 MgII_doublet_unresolved)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_SD_085_096 = velocity_of_the_center(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Average_Center_SD_085_096, \n",
    "                                                                                                                 MgII_doublet_unresolved)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "These are the rest wavelengths in angstroms for the lines that are important for the fits.\n",
    "\"\"\"\n",
    "HeII_2733 = 2733.289\n",
    "MgII_2800 = 2799.000\n",
    "FeIV_2829 = 2829.36\n",
    "FeIV_2836 = 2835.740\n",
    "ArIV_2854 = 2853.670\n",
    "ArIV_2868 = 2868.210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef99786-b05a-4e76-99be-5cae72c864cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc29b35-9d84-4408-bcd9-255dd75414dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the velocity centered at zero.\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_025_035 = velocity_shift_of_center_to_zero(MgII_ReStacked_Wave_Continuum_Scaled_025_035, MgII_doublet_unresolved, \n",
    "                                                                                                                                                         MgII_ReStacked_Continuum_Scaled_Velocity_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_SD_025_035)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_035_045 = velocity_shift_of_center_to_zero(MgII_ReStacked_Wave_Continuum_Scaled_035_045, MgII_doublet_unresolved, \n",
    "                                                                                                                                                         MgII_ReStacked_Continuum_Scaled_Velocity_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_SD_035_045)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_045_055 = velocity_shift_of_center_to_zero(MgII_ReStacked_Wave_Continuum_Scaled_045_055, MgII_doublet_unresolved, \n",
    "                                                                                                                                                         MgII_ReStacked_Continuum_Scaled_Velocity_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_SD_045_055)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_055_065 = velocity_shift_of_center_to_zero(MgII_ReStacked_Wave_Continuum_Scaled_055_065, MgII_doublet_unresolved, \n",
    "                                                                                                                                                         MgII_ReStacked_Continuum_Scaled_Velocity_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_SD_055_065)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_065_075 = velocity_shift_of_center_to_zero(MgII_ReStacked_Wave_Continuum_Scaled_065_075, MgII_doublet_unresolved, \n",
    "                                                                                                                                                         MgII_ReStacked_Continuum_Scaled_Velocity_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_SD_065_075)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_075_085 = velocity_shift_of_center_to_zero(MgII_ReStacked_Wave_Continuum_Scaled_075_085, MgII_doublet_unresolved, \n",
    "                                                                                                                                                         MgII_ReStacked_Continuum_Scaled_Velocity_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_SD_075_085)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_085_096 = velocity_shift_of_center_to_zero(MgII_ReStacked_Wave_Continuum_Scaled_085_096, MgII_doublet_unresolved, \n",
    "                                                                                                                                                         MgII_ReStacked_Continuum_Scaled_Velocity_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_SD_085_096)\n",
    "\n",
    "\n",
    "##################################################################################################################################################################################\n",
    "HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_025_035 = velocity_shift_of_center_to_zero(\n",
    "    HeII_2733, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_SD_025_035)\n",
    "\n",
    "HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045, HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_035_045 = velocity_shift_of_center_to_zero(\n",
    "    HeII_2733, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_SD_035_045)\n",
    "\n",
    "HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055, HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_045_055 = velocity_shift_of_center_to_zero(\n",
    "    HeII_2733, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_SD_045_055)\n",
    "\n",
    "HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065, HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_055_065 = velocity_shift_of_center_to_zero(\n",
    "    HeII_2733, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_SD_055_065)\n",
    "\n",
    "HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075, HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_065_075 = velocity_shift_of_center_to_zero(\n",
    "    HeII_2733, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_SD_065_075)\n",
    "\n",
    "HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085, HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_075_085 = velocity_shift_of_center_to_zero(\n",
    "    HeII_2733, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_SD_075_085)\n",
    "\n",
    "HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096, HeII_2733_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_085_096 = velocity_shift_of_center_to_zero(\n",
    "    HeII_2733, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_SD_085_096)\n",
    "\n",
    "##################################################################################################################################################################################\n",
    "FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_025_035 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2829, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_SD_025_035)\n",
    "\n",
    "FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045, FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_035_045 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2829, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_SD_035_045)\n",
    "\n",
    "FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055, FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_045_055 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2829, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_SD_045_055)\n",
    "\n",
    "FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065, FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_055_065 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2829, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_SD_055_065)\n",
    "\n",
    "FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075, FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_065_075 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2829, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_SD_065_075)\n",
    "\n",
    "FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085, FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_075_085 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2829, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_SD_075_085)\n",
    "\n",
    "FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096, FeIV_2829_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_085_096 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2829, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_SD_085_096)\n",
    "\n",
    "##################################################################################################################################################################################\n",
    "FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_025_035 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2836, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_SD_025_035)\n",
    "\n",
    "FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045, FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_035_045 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2836, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_SD_035_045)\n",
    "\n",
    "FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055, FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_045_055 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2836, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_SD_045_055)\n",
    "\n",
    "FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065, FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_055_065 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2836, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_SD_055_065)\n",
    "\n",
    "FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075, FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_065_075 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2836, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_SD_065_075)\n",
    "\n",
    "FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085, FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_075_085 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2836, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_SD_075_085)\n",
    "\n",
    "FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096, FeIV_2836_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_085_096 = velocity_shift_of_center_to_zero(\n",
    "    FeIV_2836, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_SD_085_096)\n",
    "\n",
    "##################################################################################################################################################################################\n",
    "ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_025_035 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2854, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_SD_025_035)\n",
    "\n",
    "ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045, ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_035_045 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2854, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_SD_035_045)\n",
    "\n",
    "ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055, ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_045_055 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2854, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_SD_045_055)\n",
    "\n",
    "ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065, ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_055_065 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2854, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_SD_055_065)\n",
    "\n",
    "ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075, ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_065_075 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2854, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_SD_065_075)\n",
    "\n",
    "ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085, ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_075_085 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2854, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_SD_075_085)\n",
    "\n",
    "ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096, ArIV_2854_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_085_096 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2854, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_SD_085_096)\n",
    "\n",
    "##################################################################################################################################################################################\n",
    "ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_025_035 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2868, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_025_035, MgII_ReStacked_Continuum_Scaled_Velocity_SD_025_035)\n",
    "\n",
    "ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045, ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_035_045 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2868, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_035_045, MgII_ReStacked_Continuum_Scaled_Velocity_SD_035_045)\n",
    "\n",
    "ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055, ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_045_055 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2868, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_045_055, MgII_ReStacked_Continuum_Scaled_Velocity_SD_045_055)\n",
    "\n",
    "ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065, ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_055_065 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2868, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_055_065, MgII_ReStacked_Continuum_Scaled_Velocity_SD_055_065)\n",
    "\n",
    "ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075, ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_065_075 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2868, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_065_075, MgII_ReStacked_Continuum_Scaled_Velocity_SD_065_075)\n",
    "\n",
    "ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085, ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_075_085 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2868, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_075_085, MgII_ReStacked_Continuum_Scaled_Velocity_SD_075_085)\n",
    "\n",
    "ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096, ArIV_2868_ReStacked_Continuum_Scaled_Velocity_Shifted_SD_085_096 = velocity_shift_of_center_to_zero(\n",
    "    ArIV_2868, MgII_doublet_unresolved, MgII_ReStacked_Continuum_Scaled_Velocity_085_096, MgII_ReStacked_Continuum_Scaled_Velocity_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97005b-7c4b-4bd7-986f-98804412aed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd564a-67d0-43b4-8e73-725ae1ce231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emission_line_bounds(velocity, flux, \n",
    "                             sigma_threshold=3.0, \n",
    "                             min_velocity_width=200, \n",
    "                             max_velocity_width=500,\n",
    "                             fractional_intensity=0.05,\n",
    "                             continuum_regions=None,\n",
    "                             smooth_kernel_size=3,\n",
    "                             return_diagnostics=False):\n",
    "    \"\"\"\n",
    "    Determine the boundaries of an emission line for spectral masking using velocity arrays.\n",
    "    \n",
    "    This function implements a multi-criteria approach combining:\n",
    "    - Signal-to-noise ratio thresholding\n",
    "    - Velocity-based limits\n",
    "    - Fractional peak intensity\n",
    "    - Derivative-based detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    velocity : array-like\n",
    "        Velocity array in km/s (relative to line center, typically centered at 0)\n",
    "    flux : array-like\n",
    "        Flux array corresponding to velocity\n",
    "    sigma_threshold : float, default=3.0\n",
    "        Number of sigma above continuum noise for detection\n",
    "    min_velocity_width : float, default=200\n",
    "        Minimum velocity width (km/s) to include around line center (±km/s)\n",
    "    max_velocity_width : float, default=500\n",
    "        Maximum velocity width (km/s) to consider for line boundaries (±km/s)\n",
    "    fractional_intensity : float, default=0.05\n",
    "        Fraction of peak intensity (0.05 = 5%) for boundary detection\n",
    "    continuum_regions : list of tuples, optional\n",
    "        [(vel_start1, vel_end1), (vel_start2, vel_end2)] for continuum estimation\n",
    "        If None, uses regions far from the line center (> max_velocity_width * 1.5)\n",
    "    smooth_kernel_size : int, default=3\n",
    "        Size of smoothing kernel for derivative calculation\n",
    "    return_diagnostics : bool, default=False\n",
    "        If True, returns additional diagnostic information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bounds : tuple\n",
    "        (lower_velocity, upper_velocity) defining the emission line region in km/s\n",
    "    diagnostics : dict (optional)\n",
    "        Dictionary containing diagnostic information if return_diagnostics=True\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    velocity = np.array(velocity)\n",
    "    flux = np.array(flux)\n",
    "    \n",
    "    # Define search region based on maximum velocity width\n",
    "    search_mask = np.abs(velocity) <= max_velocity_width\n",
    "    search_indices = np.where(search_mask)[0]\n",
    "    \n",
    "    if len(search_indices) < 10:\n",
    "        raise ValueError(\"Search region too small. Check velocity range and max_velocity_width.\")\n",
    "    \n",
    "    # Estimate continuum and noise\n",
    "    if continuum_regions is None:\n",
    "        # Automatically define continuum regions far from the line center\n",
    "        continuum_mask = np.abs(velocity) > max_velocity_width * 1.5\n",
    "        if np.sum(continuum_mask) < 20:\n",
    "            # Fallback: use outer regions of the velocity array\n",
    "            n_points = len(flux)\n",
    "            edge_fraction = 0.1\n",
    "            continuum_mask = np.zeros(n_points, dtype=bool)\n",
    "            continuum_mask[:int(n_points * edge_fraction)] = True\n",
    "            continuum_mask[-int(n_points * edge_fraction):] = True\n",
    "    else:\n",
    "        continuum_mask = np.zeros(len(velocity), dtype=bool)\n",
    "        for vel_start, vel_end in continuum_regions:\n",
    "            region_mask = (velocity >= vel_start) & (velocity <= vel_end)\n",
    "            continuum_mask |= region_mask\n",
    "    \n",
    "    # Calculate continuum level and noise\n",
    "    continuum_flux = flux[continuum_mask]\n",
    "    if len(continuum_flux) < 5:\n",
    "        warnings.warn(\"Very few continuum points available. Results may be unreliable.\")\n",
    "        continuum_level = np.median(flux)\n",
    "        noise_level = np.std(flux) * 0.1  # Conservative estimate\n",
    "    else:\n",
    "        continuum_level = np.median(continuum_flux)\n",
    "        # Use median absolute deviation for robust noise estimation\n",
    "        noise_level = median_abs_deviation(continuum_flux, scale='normal')\n",
    "    \n",
    "    # Method 1: Signal-to-noise threshold\n",
    "    snr_threshold = continuum_level + sigma_threshold * noise_level\n",
    "    snr_mask = flux > snr_threshold\n",
    "    \n",
    "    # Method 2: Find peak and apply fractional intensity threshold\n",
    "    search_flux = flux[search_mask]\n",
    "    peak_idx_local = np.argmax(search_flux)\n",
    "    peak_idx_global = search_indices[peak_idx_local]\n",
    "    peak_flux = flux[peak_idx_global]\n",
    "    \n",
    "    fractional_threshold = continuum_level + fractional_intensity * (peak_flux - continuum_level)\n",
    "    fractional_mask = flux > fractional_threshold\n",
    "    \n",
    "    # Method 3: Derivative-based detection (smoothed)\n",
    "    if smooth_kernel_size > 1:\n",
    "        smoothed_flux = ndimage.uniform_filter1d(flux, smooth_kernel_size)\n",
    "    else:\n",
    "        smoothed_flux = flux.copy()\n",
    "    \n",
    "    # Calculate derivative\n",
    "    derivative = np.gradient(smoothed_flux, velocity)\n",
    "    derivative_threshold = 3 * np.std(derivative[continuum_mask])\n",
    "    \n",
    "    # Find regions where derivative is significant\n",
    "    significant_derivative = np.abs(derivative) > derivative_threshold\n",
    "    \n",
    "    # Combine all methods\n",
    "    # Start with SNR detection as primary criterion\n",
    "    combined_mask = snr_mask.copy()\n",
    "    \n",
    "    # Expand to include fractional intensity regions\n",
    "    combined_mask |= fractional_mask\n",
    "    \n",
    "    # Further expand to include significant derivative regions near the line\n",
    "    nearby_mask = np.abs(velocity) <= max_velocity_width\n",
    "    combined_mask |= (significant_derivative & nearby_mask)\n",
    "    \n",
    "    # Find connected components and select the one containing the peak\n",
    "    labeled_regions, n_regions = ndimage.label(combined_mask)\n",
    "    \n",
    "    if n_regions == 0:\n",
    "        # Fallback: use minimum velocity width around peak\n",
    "        peak_velocity = velocity[peak_idx_global]\n",
    "        min_vel_mask = np.abs(velocity - peak_velocity) <= min_velocity_width\n",
    "        bounds_indices = np.where(min_vel_mask)[0]\n",
    "        lower_bound = velocity[bounds_indices[0]]\n",
    "        upper_bound = velocity[bounds_indices[-1]]\n",
    "    else:\n",
    "        # Select region containing the peak\n",
    "        peak_region_label = labeled_regions[peak_idx_global]\n",
    "        if peak_region_label == 0:\n",
    "            # Peak not in any detected region, use closest region\n",
    "            region_centers = []\n",
    "            for i in range(1, n_regions + 1):\n",
    "                region_indices = np.where(labeled_regions == i)[0]\n",
    "                region_center = np.mean(region_indices)\n",
    "                region_centers.append((i, region_center))\n",
    "            \n",
    "            # Find closest region to peak\n",
    "            distances = [abs(center - peak_idx_global) for _, center in region_centers]\n",
    "            closest_region_idx = np.argmin(distances)\n",
    "            peak_region_label = region_centers[closest_region_idx][0]\n",
    "        \n",
    "        # Get boundaries of the selected region\n",
    "        region_mask = labeled_regions == peak_region_label\n",
    "        region_indices = np.where(region_mask)[0]\n",
    "        \n",
    "        # Ensure minimum velocity width\n",
    "        peak_velocity = velocity[peak_idx_global]\n",
    "        min_lower_vel = peak_velocity - min_velocity_width\n",
    "        min_upper_vel = peak_velocity + min_velocity_width\n",
    "        \n",
    "        # Get actual bounds\n",
    "        lower_bound = velocity[region_indices[0]]\n",
    "        upper_bound = velocity[region_indices[-1]]\n",
    "        \n",
    "        # Apply minimum width constraint\n",
    "        lower_bound = min(lower_bound, min_lower_vel)\n",
    "        upper_bound = max(upper_bound, min_upper_vel)\n",
    "        \n",
    "        # Apply maximum width constraint\n",
    "        max_lower_vel = peak_velocity - max_velocity_width\n",
    "        max_upper_vel = peak_velocity + max_velocity_width\n",
    "        \n",
    "        lower_bound = max(lower_bound, max_lower_vel)\n",
    "        upper_bound = min(upper_bound, max_upper_vel)\n",
    "    \n",
    "    bounds = (lower_bound, upper_bound)\n",
    "    \n",
    "    if return_diagnostics:\n",
    "        # Calculate final velocity range\n",
    "        final_lower_vel = lower_bound\n",
    "        final_upper_vel = upper_bound\n",
    "        \n",
    "        diagnostics = {\n",
    "            'continuum_level': continuum_level,\n",
    "            'noise_level': noise_level,\n",
    "            'snr_threshold': snr_threshold,\n",
    "            'peak_flux': peak_flux,\n",
    "            'fractional_threshold': fractional_threshold,\n",
    "            'peak_velocity': velocity[peak_idx_global],\n",
    "            'velocity_range_km_s': (final_lower_vel, final_upper_vel),\n",
    "            'line_width_km_s': final_upper_vel - final_lower_vel,\n",
    "            'masks': {\n",
    "                'snr_mask': snr_mask,\n",
    "                'fractional_mask': fractional_mask,\n",
    "                'derivative_mask': significant_derivative,\n",
    "                'combined_mask': combined_mask,\n",
    "                'final_mask': (velocity >= lower_bound) & (velocity <= upper_bound)\n",
    "            }\n",
    "        }\n",
    "        return bounds, diagnostics\n",
    "    \n",
    "    return bounds\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035 = find_emission_line_bounds(\n",
    "                                MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, \n",
    "                                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, \n",
    "                                sigma_threshold=3.0, \n",
    "                                min_velocity_width=200, \n",
    "                                max_velocity_width=20000,\n",
    "                                fractional_intensity=0.05,\n",
    "                                continuum_regions=None,\n",
    "                                smooth_kernel_size=3,\n",
    "                                return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_035_045 = find_emission_line_bounds(\n",
    "                                MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045, \n",
    "                                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045, \n",
    "                                sigma_threshold=3.0, \n",
    "                                min_velocity_width=200, \n",
    "                                max_velocity_width=20000,\n",
    "                                fractional_intensity=0.05,\n",
    "                                continuum_regions=None,\n",
    "                                smooth_kernel_size=3,\n",
    "                                return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_045_055 = find_emission_line_bounds(\n",
    "                                MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055, \n",
    "                                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055, \n",
    "                                sigma_threshold=3.0, \n",
    "                                min_velocity_width=200, \n",
    "                                max_velocity_width=20000,\n",
    "                                fractional_intensity=0.05,\n",
    "                                continuum_regions=None,\n",
    "                                smooth_kernel_size=3,\n",
    "                                return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_055_065 = find_emission_line_bounds(\n",
    "                                MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065, \n",
    "                                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065, \n",
    "                                sigma_threshold=3.0, \n",
    "                                min_velocity_width=200, \n",
    "                                max_velocity_width=20000,\n",
    "                                fractional_intensity=0.05,\n",
    "                                continuum_regions=None,\n",
    "                                smooth_kernel_size=3,\n",
    "                                return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_065_075 = find_emission_line_bounds(\n",
    "                                MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075, \n",
    "                                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075, \n",
    "                                sigma_threshold=3.0, \n",
    "                                min_velocity_width=200, \n",
    "                                max_velocity_width=20000,\n",
    "                                fractional_intensity=0.05,\n",
    "                                continuum_regions=None,\n",
    "                                smooth_kernel_size=3,\n",
    "                                return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_075_085 = find_emission_line_bounds(\n",
    "                                MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085, \n",
    "                                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085, \n",
    "                                sigma_threshold=3.0, \n",
    "                                min_velocity_width=200, \n",
    "                                max_velocity_width=20000,\n",
    "                                fractional_intensity=0.05,\n",
    "                                continuum_regions=None,\n",
    "                                smooth_kernel_size=3,\n",
    "                                return_diagnostics=False)\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_085_096 = find_emission_line_bounds(\n",
    "                                MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096, \n",
    "                                MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096, \n",
    "                                sigma_threshold=3.0, \n",
    "                                min_velocity_width=200, \n",
    "                                max_velocity_width=20000,\n",
    "                                fractional_intensity=0.05,\n",
    "                                continuum_regions=None,\n",
    "                                smooth_kernel_size=3,\n",
    "                                return_diagnostics=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc157fc-8200-4d88-8703-b3c3c3b42a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c01785c-66b8-4bd9-8708-5e31ba6c0097",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Fitting (in velocity) the MgII emission from the continuum subtract spectra. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ffc82-7c97-46e2-a022-6d4da76f056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035 = fit_MgII_spectrum_velocity(\n",
    "            MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035,\n",
    "            MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035,\n",
    "            y_err = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035*2,\n",
    "            g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.70,\n",
    "            g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.4,\n",
    "            g1_sigma=900,              # Set narrow component width\n",
    "            g2_sigma=5000,             # Set broad component width\n",
    "            g1_center=100,          # Set narrow component center\n",
    "            g2_center=-550,          # Set broad component center\n",
    "            g1_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.5, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.9),\n",
    "            g2_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.9),      \n",
    "            g1_sigma_bounds=(0, 7000),  # Set bounds for narrow component width\n",
    "            g2_sigma_bounds=(0, 5450),    # Set bounds for broad component width\n",
    "            g1_center_bounds=(-800, 500),\n",
    "            g2_center_bounds=(-1000, 500),\n",
    "            title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.25 $\\leq$ z $\\less$ 0.35)\",\n",
    "            n_random_starts=150,  # Number of random starting points to try\n",
    "            use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "            use_differential_evolution=True,  # Whether to use differential evolution\n",
    "            verbose=True,\n",
    "            mask_ranges=([\n",
    "                (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "                (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "            plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ebdd24-0ce3-4683-bb27-c8a82882a29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478929c-410c-4903-95cf-182ca3fc4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.70,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.25,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4000,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=0,          # Set broad component center\n",
    "    g1_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.7, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.9),\n",
    "    g2_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.40),      \n",
    "    g1_sigma_bounds=(0, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(2000, 3000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-200, 500),\n",
    "    g2_center_bounds=(-1, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.35 $\\leq$ z $\\less$ 0.45)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_035_045[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_035_045[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045))]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be79f11-a8b4-441b-b851-32a6ac21a722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbb86f-dd4f-42d6-b10f-23f65f927899",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.80,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.15,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=200,          # Set narrow component center\n",
    "    g2_center=-200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.65, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.05, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.45),      \n",
    "    g1_sigma_bounds=(0, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 4000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.45 $\\leq$ z $\\less$ 0.55)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_045_055[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_045_055[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055))]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5db52-1ae2-460c-b845-59259cf50f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b767b9-fa27-4bbd-8337-e34c888bf638",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.65,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.20,\n",
    "    g1_sigma=1000,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=50,          # Set narrow component center\n",
    "    g2_center=-100,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.45, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.35),      \n",
    "    g1_sigma_bounds=(0, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 4800),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.55 $\\leq$ z $\\less$ 0.65)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_055_065[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_055_065[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59138974-50ae-4f63-98b3-caf6ac93c781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c95dd8-ee6c-4d48-b88f-17da317593da",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.23,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=200,          # Set narrow component center\n",
    "    g2_center=-200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.6, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.05, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.25),      \n",
    "    g1_sigma_bounds=(0, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 5000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.65 $\\leq$ z $\\less$ 0.75)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_065_075[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_065_075[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b8c31-4b85-434e-b219-983b7e9f0e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6c82b-52f0-4b83-b4ce-2558404ca66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.25,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4800,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=0,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.9),      \n",
    "    g1_sigma_bounds=(0, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 30000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.75 $\\leq$ z $\\less$ 0.85)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_075_085[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_075_085[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085))]),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e9ccf-d7a1-4735-9968-421befc9dc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d5555-c9d1-463e-8f0c-b0befe3d3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.63,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.37,\n",
    "    g1_sigma=1100,              # Set narrow component width\n",
    "    g2_sigma=4800,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.4, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.6),      \n",
    "    g1_sigma_bounds=(0, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(0, 4500),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model (0.85 $\\leq$ z $\\leq$ 0.96)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_085_096[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_085_096[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096))]),\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "\n",
    "plt.xlim(-20000, 15000)  # Set your desired limits\n",
    "#plt.ylim(-0.5e-16, 1.25e-16)\n",
    "\n",
    "# Get current axes and set limits\n",
    "fig = plt.gcf()  # Get current figure\n",
    "axes = fig.get_axes()  # Get all axes\n",
    "\n",
    "axes[0].set_ylim(-0.5e-16, 1.5e-16)  # Set y-limits for first panel (adjust values as needed)\n",
    "axes[1].set_ylim(-0.3e-16, 0.3e-16)  # Set y-limits for second panel (adjust values as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15bab9-cb78-44e3-83d7-4c211f43ff11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460de53-3084-4eb9-a43a-7478d06210ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the returns from the fit_MgII_Spectrum.\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Velocity_Narrow_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Residuals_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['residuals']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Narrow_Gaussian_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Broad_Gaussian_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_025_035['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Residuals_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Narrow_Gaussian_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Broad_Gaussian_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_035_045['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Residuals_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Narrow_Gaussian_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Broad_Gaussian_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_045_055['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Residuals_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Narrow_Gaussian_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Broad_Gaussian_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_055_065['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Residuals_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Narrow_Gaussian_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Broad_Gaussian_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_065_075['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Residuals_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Narrow_Gaussian_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Broad_Gaussian_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_075_085['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Residuals_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Narrow_Gaussian_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_BestFit_Broad_Gaussian_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_085_096['uncertainties']['g2_amplitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f1e3a-b884-4d67-9695-078e117d96ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de8c14-6e1b-4552-bde9-f5e38c2737f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0bb47-f937-4fa9-8f62-ed279aaeffbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ae4be-4912-4d8d-bd45-3fae0ff86271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f199d0-716b-44c4-8b80-6cf3593b6d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e04be6-910d-4063-ae66-39d723392b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7e79f-e5be-4556-b860-cc16c11e6092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fbbf8-a796-48a6-b0c2-d59c8eec258a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540ed7b-d99e-4eff-b086-ad7a6a325701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a85514-e455-42f7-b876-cdb33807a2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65366529-0c05-4221-98b5-8d652b8fc64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461b1de-2161-4631-98e4-9da4c1c18279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d764fc4-4aa4-48ae-83d8-e4a28b96528d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b42bb-514c-4b63-ad3b-d8b83d9ca2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5cc18-3d5d-4ec8-a082-bf1d580e11b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44fa18-d152-4ed7-a1b1-a78035435b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102f48c-d049-4a1a-8df2-2b49b6769e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c483bef-b515-4454-b747-3798fdc35b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82512962-3b03-4e38-8eb9-87e115097a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1e2be-67b5-4a1e-97ef-40c0588c4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdb806-86c8-408c-8d69-294a9d9e9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Z_025_035))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6912e-813a-485d-aba2-69c3aca9fbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb208c93-ab20-4ab4-ba61-ce033d70fda7",
   "metadata": {},
   "source": [
    "# <font color='#e55730' size=5 >Calculating the BHmass</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8363ff-c67a-4d8c-a161-72f60d9d239c",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Getting the proper motion distance and the luminosity distance given redshift</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cb183-953d-4d09-ac0f-074c3b979062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is getting the proper motion distance and its standard deviation for each of the redshift values in each of the redshift bins.\n",
    "\n",
    "Paper\n",
    "-----\n",
    "https://arxiv.org/pdf/astro-ph/9905116\n",
    "\"\"\"\n",
    "DM_Array_025_035, DM_SD_Array_025_035 = DM_Multiple(Z_025_035)\n",
    "DM_Array_035_045, DM_SD_Array_035_045 = DM_Multiple(Z_035_045)\n",
    "DM_Array_045_055, DM_SD_Array_045_055 = DM_Multiple(Z_045_055)\n",
    "DM_Array_055_065, DM_SD_Array_055_065 = DM_Multiple(Z_055_065)\n",
    "DM_Array_065_075, DM_SD_Array_065_075 = DM_Multiple(Z_065_075)\n",
    "DM_Array_075_085, DM_SD_Array_075_085 = DM_Multiple(Z_075_085)\n",
    "DM_Array_085_096, DM_SD_Array_085_096 = DM_Multiple(Z_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950481e-0e84-4a62-9b71-85f349afd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is getting the Luminosity distances for the redshifts in each of the bins given the proper motion distance and redshift.\n",
    "\n",
    "Paper\n",
    "-----\n",
    "https://arxiv.org/pdf/astro-ph/9905116\n",
    "\"\"\"\n",
    "DL_Array_025_035, DL_SD_Array_025_035 = DL(DM_Array_025_035, DM_SD_Array_025_035, Z_025_035)\n",
    "DL_Array_035_045, DL_SD_Array_035_045 = DL(DM_Array_035_045, DM_SD_Array_035_045, Z_035_045)\n",
    "DL_Array_045_055, DL_SD_Array_045_055 = DL(DM_Array_045_055, DM_SD_Array_045_055, Z_045_055)\n",
    "DL_Array_055_065, DL_SD_Array_055_065 = DL(DM_Array_055_065, DM_SD_Array_055_065, Z_055_065)\n",
    "DL_Array_065_075, DL_SD_Array_065_075 = DL(DM_Array_065_075, DM_SD_Array_065_075, Z_065_075)\n",
    "DL_Array_075_085, DL_SD_Array_075_085 = DL(DM_Array_075_085, DM_SD_Array_075_085, Z_075_085)\n",
    "DL_Array_085_096, DL_SD_Array_085_096 = DL(DM_Array_085_096, DM_SD_Array_085_096, Z_085_096)\n",
    "\n",
    "print(DL_Array_025_035)\n",
    "print(len(DM_SD_Array_025_035))\n",
    "print(len(Z_025_035))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd52b3-3148-4ed9-8dfb-adb224ababd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning the DL units from MpC to C M\n",
    "\"\"\"\n",
    "This turns the luminosity distances from MpC to cm.\n",
    "\n",
    "MpC to cm = 3.086e24\n",
    "\"\"\"\n",
    "DL_Array_cm_025_035, DL_SD_cm_Array_025_035 = np.multiply(DL_Array_025_035 , 3.086e24), np.multiply(DL_SD_Array_025_035 , 3.086e24)\n",
    "DL_Array_cm_035_045, DL_SD_cm_Array_035_045 = np.multiply(DL_Array_035_045 , 3.086e24), np.multiply(DL_SD_Array_035_045 , 3.086e24)\n",
    "DL_Array_cm_045_055, DL_SD_cm_Array_045_055 = np.multiply(DL_Array_045_055 , 3.086e24), np.multiply(DL_SD_Array_045_055 , 3.086e24)\n",
    "DL_Array_cm_055_065, DL_SD_cm_Array_055_065 = np.multiply(DL_Array_055_065 , 3.086e24), np.multiply(DL_SD_Array_055_065 , 3.086e24)\n",
    "DL_Array_cm_065_075, DL_SD_cm_Array_065_075 = np.multiply(DL_Array_065_075 , 3.086e24), np.multiply(DL_SD_Array_065_075 , 3.086e24)\n",
    "DL_Array_cm_075_085, DL_SD_cm_Array_075_085 = np.multiply(DL_Array_075_085 , 3.086e24), np.multiply(DL_SD_Array_075_085 , 3.086e24)\n",
    "DL_Array_cm_085_096, DL_SD_cm_Array_085_096 = np.multiply(DL_Array_085_096 , 3.086e24), np.multiply(DL_SD_Array_085_096 , 3.086e24)\n",
    "\n",
    "print(len(DL_Array_025_035))\n",
    "print(len(DL_Array_cm_025_035))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6600e-9bd8-45a9-b45a-bd1b0452625a",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Calculating the continuum luminosity at 3000 and 2000 angstroms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907e423-ea86-4dae-9fde-445d5e0e7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This gets the continuum luminosity wave index.\n",
    "Then getting the wavelength values for the index.\n",
    "Finally, get the flux for these indexes.\n",
    "\"\"\"\n",
    "L_3000_Index_025_035 = getting_the_L_3000_Index(np.array(Wave_Rest_025_035))\n",
    "L_3000_Index_035_045 = getting_the_L_3000_Index(np.array(Wave_Rest_035_045))\n",
    "L_3000_Index_045_055 = getting_the_L_3000_Index(np.array(Wave_Rest_045_055))\n",
    "L_3000_Index_055_065 = getting_the_L_3000_Index(np.array(Wave_Rest_055_065))\n",
    "L_3000_Index_065_075 = getting_the_L_3000_Index(np.array(Wave_Rest_065_075))\n",
    "L_3000_Index_075_085 = getting_the_L_3000_Index(np.array(Wave_Rest_075_085))\n",
    "#L_3000_Index_085_096 = getting_the_L_3000_Index(np.array(Wave_Rest_085_096))  \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "L_3000_Wave_025_035 = getting_the_L_3000_wave(np.array(Wave_Rest_025_035), L_3000_Index_025_035)\n",
    "L_3000_Wave_035_045 = getting_the_L_3000_wave(np.array(Wave_Rest_035_045), L_3000_Index_035_045)\n",
    "L_3000_Wave_045_055 = getting_the_L_3000_wave(np.array(Wave_Rest_045_055), L_3000_Index_045_055)\n",
    "L_3000_Wave_055_065 = getting_the_L_3000_wave(np.array(Wave_Rest_055_065), L_3000_Index_055_065)\n",
    "L_3000_Wave_065_075 = getting_the_L_3000_wave(np.array(Wave_Rest_065_075), L_3000_Index_065_075)\n",
    "L_3000_Wave_075_085 = getting_the_L_3000_wave(np.array(Wave_Rest_075_085), L_3000_Index_075_085)\n",
    "#L_3000_Wave_085_096 = getting_the_L_3000_wave(np.array(Wave_Rest_085_096), L_3000_Index_085_096)  \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n",
    "\n",
    "\n",
    "L_3000_Flux_025_035, L_3000_Flux_SD_025_035 = getting_the_L_3000_flux(Spec_Rest_025_035, Spec_Rest_SD_025_035, L_3000_Index_025_035)\n",
    "L_3000_Flux_035_045, L_3000_Flux_SD_035_045 = getting_the_L_3000_flux(Spec_Rest_035_045, Spec_Rest_SD_035_045, L_3000_Index_035_045)\n",
    "L_3000_Flux_045_055, L_3000_Flux_SD_045_055 = getting_the_L_3000_flux(Spec_Rest_045_055, Spec_Rest_SD_045_055, L_3000_Index_045_055)\n",
    "L_3000_Flux_055_065, L_3000_Flux_SD_055_065 = getting_the_L_3000_flux(Spec_Rest_055_065, Spec_Rest_SD_055_065, L_3000_Index_055_065)\n",
    "L_3000_Flux_065_075, L_3000_Flux_SD_065_075 = getting_the_L_3000_flux(Spec_Rest_065_075, Spec_Rest_SD_065_075, L_3000_Index_065_075)\n",
    "L_3000_Flux_075_085, L_3000_Flux_SD_075_085 = getting_the_L_3000_flux(Spec_Rest_075_085, Spec_Rest_SD_075_085, L_3000_Index_075_085)\n",
    "#L_3000_Flux_085_096 = getting_the_L_3000_flux(Spec_Rest_085_096, L_3000_Index_085_096) \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804f18c-e684-4ce8-88e9-bd53498d2a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44f0a8-3163-413c-b919-611f51800fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a482bd8-2493-428a-a771-b5bc2e8b914c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we are finding the wavelength index for the luminosity at 2000 angstroms. (Which AGN have rest wavelength values in the 2000 angstrom range.)\n",
    "This is important, because not all of the AGN have wavelengths that extend into the 3000 angstrom range.\n",
    "The results from this are used to find the relationship between 2000 angstrom continuum luminosity to 3000 angstrom continuum luminosity. That way we can determine the 3000 angstrom continuum luminosity for these AGN.\n",
    "\"\"\"\n",
    "L_2000_Index_025_035, L_2000_Wave_Index_025_035 = getting_the_L_2000_Index(np.array(Wave_Rest_025_035))\n",
    "L_2000_Index_035_045, L_2000_Wave_Index_035_045 = getting_the_L_2000_Index(np.array(Wave_Rest_035_045))\n",
    "L_2000_Index_045_055, L_2000_Wave_Index_045_055 = getting_the_L_2000_Index(np.array(Wave_Rest_045_055))\n",
    "L_2000_Index_055_065, L_2000_Wave_Index_055_065 = getting_the_L_2000_Index(np.array(Wave_Rest_055_065))\n",
    "L_2000_Index_065_075, L_2000_Wave_Index_065_075 = getting_the_L_2000_Index(np.array(Wave_Rest_065_075))\n",
    "L_2000_Index_075_085, L_2000_Wave_Index_075_085 = getting_the_L_2000_Index(np.array(Wave_Rest_075_085))\n",
    "L_2000_Index_085_096, L_2000_Wave_Index_085_096 = getting_the_L_2000_Index(np.array(Wave_Rest_085_096))\n",
    "\n",
    "\n",
    "\"\"\" Getting the rest wavelegnth arrays for the AGN that have rest wavelengths with values in to 2000 angstrom range. \"\"\"\n",
    "L_2000_Waves_025_035 = getting_the_L_2000_waves(np.array(Wave_Rest_025_035), L_2000_Index_025_035)\n",
    "L_2000_Waves_035_045 = getting_the_L_2000_waves(np.array(Wave_Rest_035_045), L_2000_Index_035_045)\n",
    "L_2000_Waves_045_055 = getting_the_L_2000_waves(np.array(Wave_Rest_045_055), L_2000_Index_045_055)\n",
    "L_2000_Waves_055_065 = getting_the_L_2000_waves(np.array(Wave_Rest_055_065), L_2000_Index_055_065)\n",
    "L_2000_Waves_065_075 = getting_the_L_2000_waves(np.array(Wave_Rest_065_075), L_2000_Index_065_075)\n",
    "L_2000_Waves_075_085 = getting_the_L_2000_waves(np.array(Wave_Rest_075_085), L_2000_Index_075_085)\n",
    "L_2000_Waves_085_096 = getting_the_L_2000_waves(np.array(Wave_Rest_085_096), L_2000_Index_085_096)\n",
    "\n",
    "\n",
    "\"\"\"Getting the flux arrays fot the AGN that have rest wavelengths with values in the 2000 angstrom range.\"\"\"\n",
    "#L_2000_Flux_025_03, L_2000_Flux_SD_025_035 = getting_the_L_2000_flux(Spec_Rest_025_035, Spec_Rest_SD_025_035, L_2000_Index_025_035) \"\"\"This is too low for the wavelength range.\"\"\"\n",
    "L_2000_Flux_035_045, L_2000_Flux_SD_035_045 = getting_the_L_2000_flux(Spec_Rest_035_045, Spec_Rest_SD_035_045, L_2000_Index_035_045)\n",
    "L_2000_Flux_045_055, L_2000_Flux_SD_045_055 = getting_the_L_2000_flux(Spec_Rest_045_055, Spec_Rest_SD_045_055, L_2000_Index_045_055)\n",
    "L_2000_Flux_055_065, L_2000_Flux_SD_055_065 = getting_the_L_2000_flux(Spec_Rest_055_065, Spec_Rest_SD_055_065, L_2000_Index_055_065)\n",
    "L_2000_Flux_065_075, L_2000_Flux_SD_065_075 = getting_the_L_2000_flux(Spec_Rest_065_075, Spec_Rest_SD_065_075, L_2000_Index_065_075)\n",
    "L_2000_Flux_075_085, L_2000_Flux_SD_075_085 = getting_the_L_2000_flux(Spec_Rest_075_085, Spec_Rest_SD_075_085, L_2000_Index_075_085)\n",
    "L_2000_Flux_085_096, L_2000_Flux_SD_085_096 = getting_the_L_2000_flux(Spec_Rest_085_096, Spec_Rest_SD_085_096, L_2000_Index_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33cd26-e9d7-4c38-9a1e-eb27416ca72b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f18ab-f5ae-460f-8826-d3fc3320992d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15788a83-2a2d-4bf6-a1df-79cfc54814d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ab248-8538-47d2-aecd-882ae50bc1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e91f67-a2a6-4340-bc94-c4bc632b0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_spectrum(args):\n",
    "    \"\"\"\n",
    "    Process a single spectrum, returning only picklable objects\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple\n",
    "        Tuple containing (idx, wave, spec, spec_std, scaling_factor)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing results for this spectrum (without Spectrum1D object)\n",
    "    \"\"\"\n",
    "    idx, wave, spec, spec_std, scaling_factor = args\n",
    "    \n",
    "    # Handle NaN values in spectrum\n",
    "    spec = np.where(np.isnan(spec), 0, spec)\n",
    "    \n",
    "    # Create Spectrum1D object\n",
    "    spectrum = Spectrum1D(spec * 1e16 * u.erg / u.angstrom / u.second / u.cm**2, \n",
    "                         wave * u.angstrom)\n",
    "    \n",
    "    # Fit continuum while suppressing warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        continuum_fit = fit_generic_continuum(\n",
    "            spectrum, \n",
    "            model=models.Chebyshev1D(4), \n",
    "            exclude_regions=[SpectralRegion(2745*u.angstrom, 2885*u.angstrom)]\n",
    "        )\n",
    "    \n",
    "    # Evaluate the fitted continuum model\n",
    "    y_continuum = continuum_fit(wave * u.angstrom)\n",
    "    y_continuum_original_scale = y_continuum.value * 1e-16\n",
    "    \n",
    "    # Handle cases where continuum might be zero\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    epsilon = 1e-20\n",
    "    safe_continuum = np.where(np.abs(y_continuum_original_scale) < epsilon, \n",
    "                              epsilon, y_continuum_original_scale)\n",
    "    \n",
    "    # Bootstrap for continuum uncertainty estimation\n",
    "    n_bootstrap = 100\n",
    "    continuum_bootstrap_samples = np.zeros((n_bootstrap, len(wave)))\n",
    "    \n",
    "    for j in range(n_bootstrap):\n",
    "        # Create bootstrap sample of the spectrum\n",
    "        if spec_std is not None:\n",
    "            bootstrap_spec = spec + np.random.normal(0, spec_std)\n",
    "        else:\n",
    "            # If no uncertainties provided, estimate from the scatter\n",
    "            scatter = np.std(spec - y_continuum_original_scale)\n",
    "            bootstrap_spec = spec + np.random.normal(0, scatter, size=len(spec))\n",
    "            \n",
    "        bootstrap_spectrum = Spectrum1D(bootstrap_spec * 1e16 * u.erg / u.angstrom / u.second / u.cm**2, \n",
    "                                      wave * u.angstrom)\n",
    "        \n",
    "        # Fit continuum to bootstrap sample\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            bootstrap_continuum_fit = fit_generic_continuum(\n",
    "                bootstrap_spectrum, \n",
    "                model=models.Chebyshev1D(4), \n",
    "                exclude_regions=[SpectralRegion(2745*u.angstrom, 2885*u.angstrom)]\n",
    "            )\n",
    "        \n",
    "        # Evaluate bootstrap continuum\n",
    "        bootstrap_y_continuum = bootstrap_continuum_fit(wave * u.angstrom)\n",
    "        continuum_bootstrap_samples[j] = bootstrap_y_continuum.value * 1e-16\n",
    "    \n",
    "    # Calculate standard deviation of continuum from bootstrap samples\n",
    "    y_continuum_std = np.std(continuum_bootstrap_samples, axis=0)\n",
    "    \n",
    "    # Calculate residuals: (spectrum - continuum) / continuum\n",
    "    residual = (spec - y_continuum_original_scale) / safe_continuum\n",
    "    \n",
    "    # Improve error propagation with continuum uncertainty\n",
    "    if spec_std is not None:\n",
    "        # Use full error propagation formula for (spec - cont)/cont\n",
    "        # σ_residual = sqrt((σ_spec/cont)² + (spec·σ_cont/cont²)²)\n",
    "        fit_uncertainty = np.sqrt((spec_std/safe_continuum)**2 + \n",
    "                                ((spec * y_continuum_std)/(safe_continuum**2))**2)\n",
    "    else:\n",
    "        # If no error provided, use a simple estimate based on residual scatter\n",
    "        fit_uncertainty = np.std(residual) * np.ones_like(residual)\n",
    "        \n",
    "    # Calculate fit quality metrics\n",
    "    # 1. R-squared (coefficient of determination)\n",
    "    ss_total = np.sum((spec - np.mean(spec))**2)\n",
    "    ss_residual = np.sum((spec - y_continuum_original_scale)**2)\n",
    "    r_squared = 1 - (ss_residual / ss_total)\n",
    "        \n",
    "    # 2. Chi-squared goodness of fit\n",
    "    if spec_std is not None and np.all(spec_std > 0):\n",
    "        weights = 1.0 / (spec_std**2)\n",
    "    else:\n",
    "        weights = np.ones_like(spec)\n",
    "    chi_squared = np.sum(weights * ((spec - y_continuum_original_scale)**2))\n",
    "    \n",
    "    # 3. Reduced chi-squared (chi-squared per degree of freedom)\n",
    "    dof = len(spec) - models.Chebyshev1D(4).degree - 1  # degrees of freedom\n",
    "    reduced_chi_squared = chi_squared / dof if dof > 0 else np.nan\n",
    "    \n",
    "    # 4. Kolmogorov-Smirnov test (normality of residuals)\n",
    "    # Handle potential NaN/Inf values in residuals\n",
    "    valid_residuals = residual[np.isfinite(residual)]\n",
    "    if len(valid_residuals) > 5:  # Need a minimum sample for KS test\n",
    "        normalized_residuals = valid_residuals / np.std(valid_residuals)\n",
    "        try:\n",
    "            ks_statistic, p_value = stats.kstest(normalized_residuals, 'norm')\n",
    "        except:\n",
    "            ks_statistic, p_value = np.nan, np.nan\n",
    "    else:\n",
    "        ks_statistic, p_value = np.nan, np.nan\n",
    "    \n",
    "    # Store fit metrics\n",
    "    metrics = {\n",
    "        'r_squared': r_squared,\n",
    "        'chi_squared': chi_squared,\n",
    "        'reduced_chi_squared': reduced_chi_squared,\n",
    "        'ks_statistic': ks_statistic,\n",
    "        'p_value': p_value,\n",
    "        'best_metric': 'r_squared' if r_squared > 0.9 else 'reduced_chi_squared'\n",
    "    }\n",
    "    \n",
    "    # Return only picklable objects (no Spectrum1D)\n",
    "    return {\n",
    "        'idx': idx,  # Include index for proper ordering later\n",
    "        'continuum': y_continuum_original_scale,\n",
    "        'continuum_std': y_continuum_std,\n",
    "        'residual': residual,\n",
    "        'fit_uncertainty': fit_uncertainty,\n",
    "        'fit_metrics': metrics\n",
    "    }\n",
    "\n",
    "def getting_the_continuum_fits_for_the_3000_or_2000(wave_a, spec_a, spec_std_a=None, scaling_factor=1e-17):\n",
    "    \"\"\"\n",
    "    Fits a continuum to spectra, calculates residuals, and evaluates fit quality using \n",
    "    parallel processing with a single progress bar.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wave_a : list of arrays\n",
    "        List of wavelength arrays for each spectrum\n",
    "    spec_a : list of arrays\n",
    "        List of flux arrays for each spectrum\n",
    "    spec_std_a : list of arrays, optional\n",
    "        List of flux standard deviation arrays for each spectrum\n",
    "    scaling_factor : float\n",
    "        Scaling factor to apply to the flux values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple containing:\n",
    "        - spectra: List of Spectrum1D objects\n",
    "        - continua: List of fitted continuum arrays\n",
    "        - residuals: List of residual arrays\n",
    "        - continua_std: List of continuum standard deviation arrays\n",
    "        - fit_metrics: List of dictionaries with fit quality metrics\n",
    "    \"\"\"\n",
    "    total_spectra = len(wave_a)\n",
    "    print(f\"Starting continuum fitting for {total_spectra} spectra...\")\n",
    "    \n",
    "    \n",
    "    # Determine number of CPUs to use - start with a safer default\n",
    "    n_jobs = min(os.cpu_count() or 1, 4)  # Limit to 4 cores by default for safety\n",
    "    print(f\"Using {n_jobs} CPU cores for parallel processing\")\n",
    "    \n",
    "    # Prepare inputs for processing\n",
    "    indices = list(range(total_spectra))\n",
    "    \n",
    "    # Create args for each spectrum\n",
    "    args_list = []\n",
    "    for i in indices:\n",
    "        spec_std = None if spec_std_a is None else spec_std_a[i]\n",
    "        args_list.append((i, wave_a[i], spec_a[i], spec_std, scaling_factor))\n",
    "    \n",
    "    # Process strategy: use a sequential approach with progress bar if multiprocessing fails\n",
    "    try:\n",
    "        # Try multiprocessing first\n",
    "        results = []\n",
    "        with mp.Pool(processes=n_jobs) as pool:\n",
    "            # Use imap to get results one at a time with progress bar\n",
    "            with tqdm(total=total_spectra, desc=\"Processing spectra\", \n",
    "                     bar_format=\"{desc}: {percentage:3.0f}%|{bar:30}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "                # Use chunksize=1 to update progress bar more frequently\n",
    "                for result in pool.imap(process_single_spectrum, args_list, chunksize=1):\n",
    "                    results.append(result)\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Multiprocessing failed with error: {str(e)}\")\n",
    "        print(\"Falling back to sequential processing...\")\n",
    "        \n",
    "        # Fall back to sequential processing\n",
    "        results = []\n",
    "        with tqdm(total=total_spectra, desc=\"Processing spectra (sequential)\", \n",
    "                 bar_format=\"{desc}: {percentage:3.0f}%|{bar:30}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "            for args in args_list:\n",
    "                result = process_single_spectrum(args)\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Sort results by index\n",
    "    results.sort(key=lambda x: x['idx'])\n",
    "    \n",
    "    # Generate Spectrum1D objects separately (since they weren't serialized)\n",
    "    spectra = []\n",
    "    for i in indices:\n",
    "        spectrum = Spectrum1D(spec_a[i] * 1e16 * u.erg / u.angstrom / u.second / u.cm**2, \n",
    "                            wave_a[i] * u.angstrom)\n",
    "        spectra.append(spectrum)\n",
    "    \n",
    "    # Extract results\n",
    "    fitted_continua = [r['continuum'] for r in results]\n",
    "    continua_std = [r['continuum_std'] for r in results]\n",
    "    residuals = [r['residual'] for r in results]\n",
    "    fit_std_dev = [r['fit_uncertainty'] for r in results]\n",
    "    fit_metrics = [r['fit_metrics'] for r in results]\n",
    "    \n",
    "    print(f\"Continuum fitting completed for {len(results)} spectra\")\n",
    "    \n",
    "    # Return in the original format (as a tuple)\n",
    "    return spectra, fitted_continua, residuals, continua_std, fit_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d68e7-ef62-4dc1-95a5-c7b4709a8ed0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80153cc-a285-455e-b2a0-3631286c988d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1cadc-3e8b-4909-bb9a-49f45f15e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_025_035.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_3000_025_035,\n",
    "     Y_Continuum_Fitted_3000_025_035,\n",
    "     Residuals_3000_Continuum_fit_025_035,\n",
    "     Y_Continuum_Fitted_SD_3000_025_035,\n",
    "     Y_Continuum_Fitted_Metrics_3000_025_035) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_3000_Wave_025_035,\n",
    "        L_3000_Flux_025_035,\n",
    "        L_3000_Flux_SD_025_035\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_3000_025_035)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_3000_025_035)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_3000_Continuum_fit_025_035)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_3000_025_035)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_3000_025_035)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_3000_025_035 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_3000_025_035 = table[\"Continuum\"]\n",
    "    Residuals_3000_Continuum_fit_025_035 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_3000_025_035 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_3000_025_035 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514c833-9e96-4c4b-8b8d-b4d188a408a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spec_Continuum_Fitted_2000_025_035, Y_Continuum_Fitted_2000_025_035, Residuals_2000_Continuum_fit_025_035,  Y_Continuum_Fitted_SD_2000_025_035, Y_Continuum_Fitted_Metrics_2000_025_035 =  getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "#                                                                                                                                                                                                    L_2000_Waves_025_035, L_2000_Flux_025_035, L_2000_Flux_SD_025_035)\n",
    "\"\"\"This can't be done because the rest waves don't go low enough for the 3000 angstrom continuum.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e9bfd-7a24-42eb-be9e-720ce2fc560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_035_045.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_3000_035_045,\n",
    "     Y_Continuum_Fitted_3000_035_045,\n",
    "     Residuals_3000_Continuum_fit_035_045,\n",
    "     Y_Continuum_Fitted_SD_3000_035_045,\n",
    "     Y_Continuum_Fitted_Metrics_3000_035_045) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_3000_Wave_035_045,\n",
    "        L_3000_Flux_035_045,\n",
    "        L_3000_Flux_SD_035_045\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_3000_035_045)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_3000_035_045)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_3000_Continuum_fit_035_045)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_3000_035_045)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_3000_035_045)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_3000_035_045 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_3000_035_045 = table[\"Continuum\"]\n",
    "    Residuals_3000_Continuum_fit_035_045 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_3000_035_045 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_3000_035_045 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc557fb5-d47c-4daa-9682-c78f2a354839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_035_045.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_2000_035_045,\n",
    "     Y_Continuum_Fitted_2000_035_045,\n",
    "     Residuals_2000_Continuum_fit_035_045,\n",
    "     Y_Continuum_Fitted_SD_2000_035_045,\n",
    "     Y_Continuum_Fitted_Metrics_2000_035_045) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_2000_Waves_035_045,\n",
    "        L_2000_Flux_035_045,\n",
    "        L_2000_Flux_SD_035_045\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_2000_035_045)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_2000_035_045)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_2000_Continuum_fit_035_045)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_2000_035_045)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_2000_035_045)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_2000_035_045 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_2000_035_045 = table[\"Continuum\"]\n",
    "    Residuals_2000_Continuum_fit_035_045 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_2000_035_045 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_2000_035_045 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc87be-a2d9-4870-b40d-86657cd0f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_045_055.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_3000_045_055,\n",
    "     Y_Continuum_Fitted_3000_045_055,\n",
    "     Residuals_3000_Continuum_fit_045_055,\n",
    "     Y_Continuum_Fitted_SD_3000_045_055,\n",
    "     Y_Continuum_Fitted_Metrics_3000_045_055) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_3000_Wave_045_055,\n",
    "        L_3000_Flux_045_055,\n",
    "        L_3000_Flux_SD_045_055\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_3000_045_055)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_3000_045_055)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_3000_Continuum_fit_045_055)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_3000_045_055)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_3000_045_055)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_3000_045_055 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_3000_045_055 = table[\"Continuum\"]\n",
    "    Residuals_3000_Continuum_fit_045_055 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_3000_045_055 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_3000_045_055 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb858a95-f71a-4500-b29c-2a74d77a70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_045_055.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_2000_045_055,\n",
    "     Y_Continuum_Fitted_2000_045_055,\n",
    "     Residuals_2000_Continuum_fit_045_055,\n",
    "     Y_Continuum_Fitted_SD_2000_045_055,\n",
    "     Y_Continuum_Fitted_Metrics_2000_045_055) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_2000_Waves_045_055,\n",
    "        L_2000_Flux_045_055,\n",
    "        L_2000_Flux_SD_045_055\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_2000_045_055)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_2000_045_055)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_2000_Continuum_fit_045_055)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_2000_045_055)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_2000_045_055)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_2000_045_055 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_2000_045_055 = table[\"Continuum\"]\n",
    "    Residuals_2000_Continuum_fit_045_055 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_2000_045_055 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_2000_045_055 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103af8a1-bf7b-4934-b2b2-63dc700e17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_055_065.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_3000_055_065,\n",
    "     Y_Continuum_Fitted_3000_055_065,\n",
    "     Residuals_3000_Continuum_fit_055_065,\n",
    "     Y_Continuum_Fitted_SD_3000_055_065,\n",
    "     Y_Continuum_Fitted_Metrics_3000_055_065) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_3000_Wave_055_065,\n",
    "        L_3000_Flux_055_065,\n",
    "        L_3000_Flux_SD_055_065\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_3000_055_065)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_3000_055_065)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_3000_Continuum_fit_055_065)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_3000_055_065)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_3000_055_065)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_3000_055_065 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_3000_055_065 = table[\"Continuum\"]\n",
    "    Residuals_3000_Continuum_fit_055_065 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_3000_055_065 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_3000_055_065 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95233c4-2618-4b8c-9795-6f9a209da9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_055_065.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_2000_055_065,\n",
    "     Y_Continuum_Fitted_2000_055_065,\n",
    "     Residuals_2000_Continuum_fit_055_065,\n",
    "     Y_Continuum_Fitted_SD_2000_055_065,\n",
    "     Y_Continuum_Fitted_Metrics_2000_055_065) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_2000_Waves_055_065,\n",
    "        L_2000_Flux_055_065,\n",
    "        L_2000_Flux_SD_055_065\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_2000_055_065)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_2000_055_065)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_2000_Continuum_fit_055_065)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_2000_055_065)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_2000_055_065)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_2000_055_065 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_2000_055_065 = table[\"Continuum\"]\n",
    "    Residuals_2000_Continuum_fit_055_065 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_2000_055_065 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_2000_055_065 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca6007-dcda-4f7a-9f40-9a374de5f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_065_075.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_3000_065_075,\n",
    "     Y_Continuum_Fitted_3000_065_075,\n",
    "     Residuals_3000_Continuum_fit_065_075,\n",
    "     Y_Continuum_Fitted_SD_3000_065_075,\n",
    "     Y_Continuum_Fitted_Metrics_3000_065_075) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_3000_Wave_065_075,\n",
    "        L_3000_Flux_065_075,\n",
    "        L_3000_Flux_SD_065_075\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_3000_065_075)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_3000_065_075)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_3000_Continuum_fit_065_075)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_3000_065_075)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_3000_065_075)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_3000_065_075 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_3000_065_075 = table[\"Continuum\"]\n",
    "    Residuals_3000_Continuum_fit_065_075 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_3000_065_075 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_3000_065_075 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafc711-8f57-4dbe-b733-53abfe87b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_065_075.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_2000_065_075,\n",
    "     Y_Continuum_Fitted_2000_065_075,\n",
    "     Residuals_2000_Continuum_fit_065_075,\n",
    "     Y_Continuum_Fitted_SD_2000_065_075,\n",
    "     Y_Continuum_Fitted_Metrics_2000_065_075) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_2000_Waves_065_075,\n",
    "        L_2000_Flux_065_075,\n",
    "        L_2000_Flux_SD_065_075\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_2000_065_075)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_2000_065_075)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_2000_Continuum_fit_065_075)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_2000_065_075)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_2000_065_075)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_2000_065_075 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_2000_065_075 = table[\"Continuum\"]\n",
    "    Residuals_2000_Continuum_fit_065_075 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_2000_065_075 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_2000_065_075 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f14b01-ec52-4f50-ac5a-a0f1ae07d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_075_085.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_3000_075_085,\n",
    "     Y_Continuum_Fitted_3000_075_085,\n",
    "     Residuals_3000_Continuum_fit_075_085,\n",
    "     Y_Continuum_Fitted_SD_3000_075_085,\n",
    "     Y_Continuum_Fitted_Metrics_3000_075_085) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_3000_Wave_075_085,\n",
    "        L_3000_Flux_075_085,\n",
    "        L_3000_Flux_SD_075_085\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_3000_075_085)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_3000_075_085)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_3000_Continuum_fit_075_085)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_3000_075_085)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_3000_075_085)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_3000_075_085 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_3000_075_085 = table[\"Continuum\"]\n",
    "    Residuals_3000_Continuum_fit_075_085 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_3000_075_085 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_3000_075_085 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9ae08-7e83-4a07-9d9f-13cf2ea08973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_075_085.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_2000_075_085,\n",
    "     Y_Continuum_Fitted_2000_075_085,\n",
    "     Residuals_2000_Continuum_fit_075_085,\n",
    "     Y_Continuum_Fitted_SD_2000_075_085,\n",
    "     Y_Continuum_Fitted_Metrics_2000_075_085) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_2000_Waves_075_085,\n",
    "        L_2000_Flux_075_085,\n",
    "        L_2000_Flux_SD_075_085\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_2000_075_085)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_2000_075_085)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_2000_Continuum_fit_075_085)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_2000_075_085)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_2000_075_085)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_2000_075_085 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_2000_075_085 = table[\"Continuum\"]\n",
    "    Residuals_2000_Continuum_fit_075_085 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_2000_075_085 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_2000_075_085 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360a7ed-55b1-4bb2-9455-df858181e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spec_Continuum_Fitted_3000_085_096, Y_Continuum_Fitted_3000_085_096, Residuals_3000_Continuum_fit_085_096,  Y_Continuum_Fitted_SD_3000_085_096, Y_Continuum_Fitted_Metrics_3000_085_096 =  getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "#                                                                                                                                                                                                    L_3000_Wave_085_096, L_3000_Flux_085_096)\n",
    "\"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387161c-dc8c-463f-abfc-dea6fc51b97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This checks to see if the file for this run already exists. If it doesn't the function is run and if it does then the code instead pulls the file.\n",
    "The getting_the_continuum_fits_for_the_3000_or_2000 :\n",
    "                                                Fits a continuum to spectra, calculates residuals, and evaluates fit quality.\n",
    "                                                Uses bootstrap resampling for uncertainty estimation.\n",
    "\"\"\"\n",
    "# Define the output path\n",
    "output_path = \"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Continuum_Fits_3000_085_096.fits\"\n",
    "# Control flag to force rerun if needed\n",
    "force_rerun = False  # Set this to True manually to re-run the fitting function\n",
    "\n",
    "if not os.path.exists(output_path) or force_rerun:\n",
    "    print(\"Running fitting function and saving results...\")\n",
    "    # Run the fitting\n",
    "    (Spec_Continuum_Fitted_2000_085_096,\n",
    "     Y_Continuum_Fitted_2000_085_096,\n",
    "     Residuals_2000_Continuum_fit_085_096,\n",
    "     Y_Continuum_Fitted_SD_2000_085_096,\n",
    "     Y_Continuum_Fitted_Metrics_2000_085_096) = getting_the_continuum_fits_for_the_3000_or_2000(\n",
    "        L_2000_Waves_085_096,\n",
    "        L_2000_Flux_085_096,\n",
    "        L_2000_Flux_SD_085_096\n",
    "    )\n",
    "    \n",
    "    # It looks like these are already numpy arrays, not Spectrum1D objects\n",
    "    # Check the types of the arrays and handle appropriately\n",
    "    \n",
    "    # Function to safely convert arrays to FITS-compatible format\n",
    "    def convert_to_fits_compatible(arr):\n",
    "        # If it's already a simple numpy array of numbers, return as is\n",
    "        if isinstance(arr, np.ndarray) and arr.dtype.kind in 'fiub':  # float, int, uint, bool\n",
    "            return arr\n",
    "        # If it's a numpy array of objects (dtype='O'), convert each element\n",
    "        elif isinstance(arr, np.ndarray) and arr.dtype.kind == 'O':\n",
    "            # Try to extract as simple array if possible\n",
    "            try:\n",
    "                return np.array([x for x in arr], dtype=float)\n",
    "            except:\n",
    "                # If conversion fails, convert to strings\n",
    "                return np.array([str(x) for x in arr])\n",
    "        # For other types, try direct conversion or fall back to strings\n",
    "        else:\n",
    "            try:\n",
    "                return np.array(arr, dtype=float)\n",
    "            except:\n",
    "                return np.array([str(x) for x in arr])\n",
    "    \n",
    "    # Convert each array to a FITS-compatible format\n",
    "    spectra_flux = convert_to_fits_compatible(Spec_Continuum_Fitted_2000_085_096)\n",
    "    continuum_flux = convert_to_fits_compatible(Y_Continuum_Fitted_2000_085_096)\n",
    "    residuals_flux = convert_to_fits_compatible(Residuals_2000_Continuum_fit_085_096)\n",
    "    continuum_sd_flux = convert_to_fits_compatible(Y_Continuum_Fitted_SD_2000_085_096)\n",
    "\n",
    "    \n",
    "    # For fit metrics, we need to know their structure\n",
    "    # If they're simple values, we can use them directly\n",
    "    # If they're complex objects, we may need to serialize them differently\n",
    "    \n",
    "    # Create a table with the extracted numerical data\n",
    "    table = QTable()\n",
    "    table['Spectra'] = spectra_flux\n",
    "    table['Continuum'] = continuum_flux\n",
    "    table['Residuals'] = residuals_flux\n",
    "    table['Continuum_SD'] = continuum_sd_flux\n",
    "    \n",
    "    \n",
    "    # Handle fit metrics based on their structure\n",
    "    fit_metrics = convert_to_fits_compatible(Y_Continuum_Fitted_Metrics_2000_085_096)\n",
    "    table['Fit_Metrics'] = fit_metrics\n",
    "    \n",
    "    # Write the table to FITS\n",
    "    table.write(output_path, overwrite=True)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Reading results from existing FITS file...\")\n",
    "    # Read from FITS and assign to variables\n",
    "    table = QTable.read(output_path)\n",
    "    \n",
    "    # Retrieve the data\n",
    "    Spec_Continuum_Fitted_2000_085_096 = table[\"Spectra\"]\n",
    "    Y_Continuum_Fitted_2000_085_096 = table[\"Continuum\"]\n",
    "    Residuals_2000_Continuum_fit_085_096 = table[\"Residuals\"]\n",
    "    Y_Continuum_Fitted_SD_2000_085_096 = table[\"Continuum_SD\"]\n",
    "    Y_Continuum_Fitted_Metrics_2000_085_096 = table[\"Fit_Metrics\"]\n",
    "\n",
    "    print(\"Finished Reading File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8161565-1ac5-4e1a-b39b-0639ae56cef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2bca4-a742-4b76-97c9-392f59428441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33228b-c3b2-49fd-8626-506d0ef76215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the wavelength bin sizes (step sizes) for spectral data arrays.\n",
    "    \n",
    "This function determines the wavelength step size between adjacent points in each wavelength array. It assumes that the wavelength spacing is uniform within each array,  so it only calculates the difference between the second and third elements of each array\n",
    "(indices 2 and 1) to represent the bin size. This bin size information is used for \n",
    "proper flux integration when calculating continuum luminosities at 3000 or 2000 Angstroms.\n",
    "\"\"\"\n",
    "Bin_Sizes_3000_025_035 = getting_the_bin_sizes(L_3000_Wave_025_035)\n",
    "Bin_Sizes_3000_035_045 = getting_the_bin_sizes(L_3000_Wave_035_045)\n",
    "Bin_Sizes_3000_045_055 = getting_the_bin_sizes(L_3000_Wave_045_055)\n",
    "Bin_Sizes_3000_055_065 = getting_the_bin_sizes(L_3000_Wave_055_065)\n",
    "Bin_Sizes_3000_065_075 = getting_the_bin_sizes(L_3000_Wave_065_075)\n",
    "Bin_Sizes_3000_075_085 = getting_the_bin_sizes(L_3000_Wave_075_085)\n",
    "#Bin_Sizes_3000_085_096 = getting_the_bin_sizes(L_3000_Wave_085_096)  \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n",
    "\n",
    "Bin_Sizes_2000_025_035 = getting_the_bin_sizes(L_2000_Waves_025_035)\n",
    "Bin_Sizes_2000_035_045 = getting_the_bin_sizes(L_2000_Waves_035_045)\n",
    "Bin_Sizes_2000_045_055 = getting_the_bin_sizes(L_2000_Waves_045_055)\n",
    "Bin_Sizes_2000_055_065 = getting_the_bin_sizes(L_2000_Waves_055_065)\n",
    "Bin_Sizes_2000_065_075 = getting_the_bin_sizes(L_2000_Waves_065_075)\n",
    "Bin_Sizes_2000_075_085 = getting_the_bin_sizes(L_2000_Waves_075_085)\n",
    "Bin_Sizes_2000_085_096 = getting_the_bin_sizes(L_2000_Waves_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc62cad-d64a-4844-943c-865d88d568fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2c772-a5dd-406a-b38b-40a256f3094e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef01dd4-10ef-46a9-b7e2-ecafd03cd5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getting_the_biweight_flux(y_continuum_fit, y_continuum_std, bin_size):\n",
    "#    \"\"\"\n",
    "#    Calculate the biweight flux from continuum fit values, accounting for bin sizes.\n",
    "#    \n",
    "#    This function converts the continuum fit values (flux densities) to total flux\n",
    "#    by multiplying by the bin size and applying astropy units.\n",
    "#    \n",
    "#    Parameters\n",
    "#    ----------\n",
    "#    y_continuum_fit : list of arrays\n",
    "#        Continuum fit values (flux densities) for each spectrum at 3000 Angstroms.\n",
    "#        Each array contains the flux density values for a single spectrum.\n",
    "#    \n",
    "#    y_continuum_std : list of arrays\n",
    "#        Standard deviations of the continuum fit values.\n",
    "#        Each array contains the standard deviations for a single spectrum.\n",
    "#    \n",
    "#    bin_size : list of float\n",
    "#        Bin sizes (wavelength steps) for each spectrum in Angstroms.\n",
    "#    \n",
    "#    Returns\n",
    "#    -------\n",
    "#    BiWeight_Flux_Array : list\n",
    "#        List of arrays containing the biweighted flux values with astropy units.\n",
    "#    \n",
    "#    BiWeight_Flux_Std_Array : list\n",
    "#        List of arrays containing the standard deviations of the biweighted flux values.\n",
    "#    \"\"\"\n",
    "#    BiWeight_Flux_Array = []\n",
    "#    BiWeight_Flux_Std_Array = []\n",
    "#    \n",
    "#    for i in range(len(bin_size)):\n",
    "#        # Convert flux density to flux by multiplying by bin size\n",
    "#        # Note: y_continuum_fit is assumed to be in units of erg/s/cm^2/Angstrom\n",
    "#        # Multiplying by bin_size (Angstroms) gives flux in erg/s/cm^2\n",
    "#        bin_size = np.array(bin_size)\n",
    "#        flux = y_continuum_fit[i] * bin_size[i]# * u.erg / (u.s * u.cm**2)\n",
    "#        \n",
    "#        # Propagate the uncertainty\n",
    "#        flux_std = y_continuum_std[i] * bin_size[i] * u.erg / (u.s * u.cm**2)\n",
    "#        \n",
    "#        BiWeight_Flux_Array.append(flux)\n",
    "#        BiWeight_Flux_Std_Array.append(flux_std)\n",
    "#        \n",
    "#    return BiWeight_Flux_Array, BiWeight_Flux_Std_Array\n",
    "\n",
    "def getting_the_biweight_loc(biweight_flux, biweight_flux_std):\n",
    "    \"\"\"\n",
    "    Calculate the biweight location (robust mean) of flux values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    biweight_flux : list\n",
    "        List of arrays containing flux values with astropy units.\n",
    "    \n",
    "    biweight_flux_std : list\n",
    "        List of arrays containing standard deviations of flux values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    BiWeight_Location_Array : list\n",
    "        List of biweight location values (robust means) for each spectrum.\n",
    "    \n",
    "    BiWeight_Location_Std_Array : list\n",
    "        List of standard deviation estimates for the biweight location values.\n",
    "    \"\"\"\n",
    "    BiWeight_Location_Array = []\n",
    "    BiWeight_Location_Std_Array = []\n",
    "    \n",
    "    for i in range(len(biweight_flux)):\n",
    "        # Calculate biweight location (robust mean)\n",
    "        loc = biweight_location(biweight_flux[i])\n",
    "        \n",
    "        # For the standard deviation, we use the median of the flux standard deviations\n",
    "        # This is a simplified approach; a more rigorous approach would use bootstrap resampling\n",
    "        loc_std = np.median(biweight_flux_std[i])\n",
    "        \n",
    "        BiWeight_Location_Array.append(loc)\n",
    "        BiWeight_Location_Std_Array.append(loc_std)\n",
    "                                       \n",
    "    return BiWeight_Location_Array, BiWeight_Location_Std_Array\n",
    "\n",
    "def L_3000_2000(biweight_loc, biweight_loc_std, dl, dl_std, z):\n",
    "    \"\"\"\n",
    "    Calculate the luminosity at 3000 Angstroms using biweight location, luminosity distance, and redshift.\n",
    "    \n",
    "    This function converts the observed flux to luminosity using the luminosity distance\n",
    "    and corrects for redshift.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    biweight_loc : list\n",
    "        List of biweight location values (robust means of flux) for each spectrum.\n",
    "    \n",
    "    biweight_loc_std : list\n",
    "        List of standard deviations for the biweight location values.\n",
    "    \n",
    "    dl : array-like\n",
    "        Luminosity distances for each spectrum in cm.\n",
    "    \n",
    "    dl_std : array-like\n",
    "        Standard deviations of the luminosity distances in cm.\n",
    "    \n",
    "    z : array-like\n",
    "        Redshift values for each spectrum.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    L_3000_Array : list\n",
    "        List of luminosity values at 3000 Angstroms in units of erg/s.\n",
    "    \n",
    "    L_3000_Std_Array : list\n",
    "        List of standard deviations of the luminosity values.\n",
    "    \"\"\"\n",
    "    L_3000_Array = []\n",
    "    L_3000_Std_Array = []\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        # Calculate luminosity: L = F * (1+z) * 4πD_L²\n",
    "        # The (1+z) factor accounts for redshift\n",
    "        # Note: biweight_loc should be in units of erg/s/cm²\n",
    "        # Multiplying by 4πD_L² converts to erg/s\n",
    "        l = biweight_loc[i] * (1 + z[i]) * (4 * np.pi * dl[i]**2)\n",
    "        \n",
    "        # Error propagation for luminosity\n",
    "        # For a function f(x,y,z) = x*y*z, the relative error is:\n",
    "        # σ_f/f = sqrt((σ_x/x)² + (σ_y/y)² + (σ_z/z)²)\n",
    "        # Here we ignore the uncertainty in z as it's typically very small\n",
    "        \n",
    "        # Relative errors\n",
    "        rel_err_flux = biweight_loc_std[i] / biweight_loc[i]\n",
    "        rel_err_dl = 2 * dl_std[i] / dl[i]  # Factor of 2 because distance is squared\n",
    "        \n",
    "        # Overall relative error\n",
    "        rel_err = np.sqrt(rel_err_flux**2 + rel_err_dl**2)\n",
    "        \n",
    "        # Absolute error\n",
    "        l_std = l * rel_err\n",
    "        \n",
    "        L_3000_Array.append(l)\n",
    "        L_3000_Std_Array.append(l_std)\n",
    "    \n",
    "    return L_3000_Array, L_3000_Std_Array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e8d07-4f84-4414-b2ff-e80f805345e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_the_biweight_flux(y_continuum_fit, y_continuum_std, bin_size):\n",
    "    \"\"\"\n",
    "    Calculate the biweight flux from continuum fit values, accounting for bin sizes.\n",
    "    \n",
    "    This function converts the continuum fit values (flux densities) to total flux\n",
    "    by multiplying by the bin size and applying astropy units.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_continuum_fit : list of arrays or strings\n",
    "        Continuum fit values (flux densities) for each spectrum at 3000 Angstroms.\n",
    "        Each element contains the flux density values for a single spectrum.\n",
    "    \n",
    "    y_continuum_std : list of arrays or strings\n",
    "        Standard deviations of the continuum fit values.\n",
    "        Each element contains the standard deviations for a single spectrum.\n",
    "    \n",
    "    bin_size : list of float\n",
    "        Bin sizes (wavelength steps) for each spectrum in Angstroms.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    BiWeight_Flux_Array : list\n",
    "        List of arrays containing the biweighted flux values.\n",
    "    \n",
    "    BiWeight_Flux_Std_Array : list\n",
    "        List of arrays containing the standard deviations of the biweighted flux values.\n",
    "    \"\"\"\n",
    "    \n",
    "    BiWeight_Flux_Array = []\n",
    "    BiWeight_Flux_Std_Array = []\n",
    "    \n",
    "    # Convert bin_size to numpy array once, outside the loop\n",
    "    bin_size_array = np.array(bin_size)\n",
    "    \n",
    "    for i in range(len(bin_size_array)):\n",
    "        # Handle the case where data might be stored as strings\n",
    "        if isinstance(y_continuum_fit[i], str):\n",
    "            # If it's a string representation of an array, convert it\n",
    "            # Remove brackets and split by whitespace, then convert to float\n",
    "            flux_density_str = y_continuum_fit[i].strip('[]')\n",
    "            flux_density = np.array([float(x) for x in flux_density_str.split()])\n",
    "            \n",
    "            flux_std_str = y_continuum_std[i].strip('[]')\n",
    "            flux_std_density = np.array([float(x) for x in flux_std_str.split()])\n",
    "        else:\n",
    "            # If it's already a numpy array or list\n",
    "            flux_density = np.array(y_continuum_fit[i])\n",
    "            flux_std_density = np.array(y_continuum_std[i])\n",
    "        \n",
    "        # Multiply by bin size to get total flux\n",
    "        # Note: flux_density is in units of erg/s/cm^2/Angstrom\n",
    "        # Multiplying by bin_size (Angstroms) gives flux in erg/s/cm^2\n",
    "        flux = flux_density * bin_size_array[i]\n",
    "        \n",
    "        # Propagate the uncertainty\n",
    "        flux_std = flux_std_density * bin_size_array[i]\n",
    "        \n",
    "        BiWeight_Flux_Array.append(flux)\n",
    "        BiWeight_Flux_Std_Array.append(flux_std)\n",
    "    \n",
    "    return BiWeight_Flux_Array, BiWeight_Flux_Std_Array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculate the biweight flux from continuum fit values, accounting for bin sizes.\n",
    "    \n",
    "This function converts the continuum fit values (flux densities) to total flux by multiplying by the bin size and applying astropy units.\n",
    "\"\"\"\n",
    "Biweight_Spec_3000_025_035, Biweight_Spec_SD_3000_025_035 = getting_the_biweight_flux(Y_Continuum_Fitted_3000_025_035, Y_Continuum_Fitted_SD_3000_025_035, Bin_Sizes_3000_025_035)\n",
    "Biweight_Spec_3000_035_045, Biweight_Spec_SD_3000_035_045 = getting_the_biweight_flux(Y_Continuum_Fitted_3000_035_045, Y_Continuum_Fitted_SD_3000_035_045, Bin_Sizes_3000_035_045)\n",
    "Biweight_Spec_3000_045_055, Biweight_Spec_SD_3000_045_055 = getting_the_biweight_flux(Y_Continuum_Fitted_3000_045_055, Y_Continuum_Fitted_SD_3000_045_055, Bin_Sizes_3000_045_055)\n",
    "Biweight_Spec_3000_055_065, Biweight_Spec_SD_3000_055_065 = getting_the_biweight_flux(Y_Continuum_Fitted_3000_055_065, Y_Continuum_Fitted_SD_3000_055_065, Bin_Sizes_3000_055_065)\n",
    "Biweight_Spec_3000_065_075, Biweight_Spec_SD_3000_065_075 = getting_the_biweight_flux(Y_Continuum_Fitted_3000_065_075, Y_Continuum_Fitted_SD_3000_065_075, Bin_Sizes_3000_065_075)\n",
    "Biweight_Spec_3000_075_085, Biweight_Spec_SD_3000_075_085 = getting_the_biweight_flux(Y_Continuum_Fitted_3000_075_085, Y_Continuum_Fitted_SD_3000_075_085, Bin_Sizes_3000_075_085)\n",
    "#Biweight_Spec_3000_085_096, Biweight_Spec_SD_3000_085_096 = getting_the_biweight_flux(Y_Continuum_Fitted_3000_085_096, Y_Continuum_Fitted_SD_3000_085_096, Bin_Sizes_3000_085_096)  \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n",
    "\n",
    "\n",
    "#Biweight_Spec_2000_025_035, Biweight_Spec_SD_2000_025_035 = getting_the_biweight_flux(Y_Continuum_Fitted_2000_025_035, Y_Continuum_Fitted_SD_2000_025_035, Bin_Sizes_2000_025_035) \"\"\"This can't be done because the rest waves don't go low enough for the 2000 angstrom continuum.\"\"\"\n",
    "Biweight_Spec_2000_035_045, Biweight_Spec_SD_2000_035_045 = getting_the_biweight_flux(Y_Continuum_Fitted_2000_035_045, Y_Continuum_Fitted_SD_2000_035_045, Bin_Sizes_2000_035_045)\n",
    "Biweight_Spec_2000_045_055, Biweight_Spec_SD_2000_045_055 = getting_the_biweight_flux(Y_Continuum_Fitted_2000_045_055, Y_Continuum_Fitted_SD_2000_045_055, Bin_Sizes_2000_045_055)\n",
    "Biweight_Spec_2000_055_065, Biweight_Spec_SD_2000_055_065 = getting_the_biweight_flux(Y_Continuum_Fitted_2000_055_065, Y_Continuum_Fitted_SD_2000_055_065, Bin_Sizes_2000_055_065)\n",
    "Biweight_Spec_2000_065_075, Biweight_Spec_SD_2000_065_075 = getting_the_biweight_flux(Y_Continuum_Fitted_2000_065_075, Y_Continuum_Fitted_SD_2000_065_075, Bin_Sizes_2000_065_075)\n",
    "Biweight_Spec_2000_075_085, Biweight_Spec_SD_2000_075_085 = getting_the_biweight_flux(Y_Continuum_Fitted_2000_075_085, Y_Continuum_Fitted_SD_2000_075_085, Bin_Sizes_2000_075_085)\n",
    "Biweight_Spec_2000_085_096, Biweight_Spec_SD_2000_085_096 = getting_the_biweight_flux(Y_Continuum_Fitted_2000_085_096, Y_Continuum_Fitted_SD_2000_085_096, Bin_Sizes_2000_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1c5b1-59fd-40f7-b2d1-69ccd0c7ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6ab97-ed25-47bc-ad13-b0af0bb33d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c4651-2c59-4709-a367-bc4b896fc3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the biweight location (robust mean) of flux values.\n",
    "\"\"\"\n",
    "Biweight_Location_3000_025_035, Biweight_Location_3000_SD_025_035 = getting_the_biweight_loc(Biweight_Spec_3000_025_035, Biweight_Spec_SD_3000_025_035)\n",
    "Biweight_Location_3000_035_045, Biweight_Location_3000_SD_035_045 = getting_the_biweight_loc(Biweight_Spec_3000_035_045, Biweight_Spec_SD_3000_035_045)\n",
    "Biweight_Location_3000_045_055, Biweight_Location_3000_SD_045_055 = getting_the_biweight_loc(Biweight_Spec_3000_045_055, Biweight_Spec_SD_3000_045_055)\n",
    "Biweight_Location_3000_055_065, Biweight_Location_3000_SD_055_065 = getting_the_biweight_loc(Biweight_Spec_3000_055_065, Biweight_Spec_SD_3000_055_065)\n",
    "Biweight_Location_3000_065_075, Biweight_Location_3000_SD_065_075 = getting_the_biweight_loc(Biweight_Spec_3000_065_075, Biweight_Spec_SD_3000_065_075)\n",
    "Biweight_Location_3000_075_085, Biweight_Location_3000_SD_075_085 = getting_the_biweight_loc(Biweight_Spec_3000_075_085, Biweight_Spec_SD_3000_075_085)\n",
    "#Biweight_Location_3000_085_096, Biweight_Location_3000_SD_085_096 = getting_the_biweight_loc(Biweight_Spec_3000_085_096, Biweight_Spec_SD_3000_085_096)  \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n",
    "\n",
    "\n",
    "#Biweight_Location_2000_025_035, Biweight_Location_2000_SD_025_035 = getting_the_biweight_loc(Biweight_Spec_2000_025_035, Biweight_Spec_SD_2000_025_035) \"\"\"This can't be done because the rest waves don't go low enough for the 2000 angstrom continuum.\"\"\"\n",
    "Biweight_Location_2000_035_045, Biweight_Location_2000_SD_035_045 = getting_the_biweight_loc(Biweight_Spec_2000_035_045, Biweight_Spec_SD_2000_035_045)\n",
    "Biweight_Location_2000_045_055, Biweight_Location_2000_SD_045_055 = getting_the_biweight_loc(Biweight_Spec_2000_045_055, Biweight_Spec_SD_2000_045_055)\n",
    "Biweight_Location_2000_055_065, Biweight_Location_2000_SD_055_065 = getting_the_biweight_loc(Biweight_Spec_2000_055_065, Biweight_Spec_SD_2000_055_065)\n",
    "Biweight_Location_2000_065_075, Biweight_Location_2000_SD_065_075 = getting_the_biweight_loc(Biweight_Spec_2000_065_075, Biweight_Spec_SD_2000_065_075)\n",
    "Biweight_Location_2000_075_085, Biweight_Location_2000_SD_075_085 = getting_the_biweight_loc(Biweight_Spec_2000_075_085, Biweight_Spec_SD_2000_075_085)\n",
    "Biweight_Location_2000_085_096, Biweight_Location_2000_SD_085_096 = getting_the_biweight_loc(Biweight_Spec_2000_085_096, Biweight_Spec_SD_2000_085_096)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3525db-9973-4e99-9637-c70877edd14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixing_the_redshift_arrays(redshift_array):\n",
    "    \"\"\"\n",
    "    This takes the redshift array which looks like this [array([0.25], dtype='>f8'), array([0.27], dtype='>f8') ...  into this [0.25 0.27 ...\n",
    "    \"\"\"\n",
    "    fixed_redshift_array = []\n",
    "    for i in redshift_array:\n",
    "        fixed_redshift_array.append(i[0])\n",
    "\n",
    "    return fixed_redshift_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb39af7-bf14-4bff-bfb3-9f541987c79b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This takes the redshift array which looks like this [array([0.25], dtype='>f8'), array([0.27], dtype='>f8') ...  into this [0.25 0.27 ...\n",
    "\"\"\"\n",
    "Fixed_Z_025_035 = fixing_the_redshift_arrays(Z_025_035)\n",
    "Fixed_Z_035_045 = fixing_the_redshift_arrays(Z_035_045)\n",
    "Fixed_Z_045_055 = fixing_the_redshift_arrays(Z_045_055)\n",
    "Fixed_Z_055_065 = fixing_the_redshift_arrays(Z_055_065)\n",
    "Fixed_Z_065_075 = fixing_the_redshift_arrays(Z_065_075)\n",
    "Fixed_Z_075_085 = fixing_the_redshift_arrays(Z_075_085)\n",
    "Fixed_Z_085_096 = fixing_the_redshift_arrays(Z_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b60511-989d-44be-815d-9edbc79c65be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ae682-291c-4d09-a956-d529affdbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the luminosity at 3000 Angstroms using biweight location, luminosity distance, and redshift.\n",
    "    \n",
    "This function converts the observed flux to luminosity using the luminosity distance\n",
    "and corrects for redshift.\n",
    "\"\"\"\n",
    "L_3000_025_035, L_3000_SD_025_035 = L_3000_2000(Biweight_Location_3000_025_035, Biweight_Location_3000_SD_025_035,  DL_Array_cm_025_035, DL_SD_cm_Array_025_035 , Fixed_Z_025_035)\n",
    "L_3000_035_045, L_3000_SD_035_045 = L_3000_2000(Biweight_Location_3000_035_045, Biweight_Location_3000_SD_035_045,  DL_Array_cm_035_045, DL_SD_cm_Array_035_045 , Fixed_Z_035_045)\n",
    "L_3000_045_055, L_3000_SD_045_055 = L_3000_2000(Biweight_Location_3000_045_055, Biweight_Location_3000_SD_045_055,  DL_Array_cm_045_055, DL_SD_cm_Array_045_055 , Fixed_Z_045_055)\n",
    "L_3000_055_065, L_3000_SD_055_065 = L_3000_2000(Biweight_Location_3000_055_065, Biweight_Location_3000_SD_055_065,  DL_Array_cm_055_065, DL_SD_cm_Array_055_065 , Fixed_Z_055_065)\n",
    "L_3000_065_075, L_3000_SD_065_075 = L_3000_2000(Biweight_Location_3000_065_075, Biweight_Location_3000_SD_065_075,  DL_Array_cm_065_075, DL_SD_cm_Array_065_075 , Fixed_Z_065_075)\n",
    "L_3000_075_085, L_3000_SD_075_085 = L_3000_2000(Biweight_Location_3000_075_085, Biweight_Location_3000_SD_075_085,  DL_Array_cm_075_085, DL_SD_cm_Array_075_085 , Fixed_Z_075_085)\n",
    "#L_3000_085_096, L_3000_SD_085_096 = L_3000_2000(Biweight_Location_3000_085_096, Biweight_Location_3000_SD_085_096,  DL_Array_cm_085_096, DL_SD_cm_Array_085_096 , Z_085_096) \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n",
    "\n",
    "\n",
    "#L_2000_025_035, L_2000_SD_025_035 = L_3000_2000(Biweight_Location_2000_025_035, Biweight_Location_2000_SD_025_035, DL_Array_cm_025_035, DL_SD_cm_Array_025_035, np.array(Z_025_035)[np.array(L_2000_Wave_Index_025_035)]) \"\"\"This can't be done because the rest waves don't go low enough for the 2000 angstrom continuum.\"\"\"\n",
    "L_2000_035_045, L_2000_SD_035_045 = L_3000_2000(Biweight_Location_2000_035_045, Biweight_Location_2000_SD_035_045, DL_Array_cm_035_045, DL_SD_cm_Array_035_045, np.array(Z_035_045)[np.array(L_2000_Wave_Index_035_045)])\n",
    "L_2000_045_055, L_2000_SD_045_055 = L_3000_2000(Biweight_Location_2000_045_055, Biweight_Location_2000_SD_045_055, DL_Array_cm_045_055, DL_SD_cm_Array_045_055, np.array(Z_045_055)[np.array(L_2000_Wave_Index_045_055)])\n",
    "L_2000_055_065, L_2000_SD_055_065 = L_3000_2000(Biweight_Location_2000_055_065, Biweight_Location_2000_SD_055_065, DL_Array_cm_055_065, DL_SD_cm_Array_055_065, np.array(Z_055_065)[np.array(L_2000_Wave_Index_055_065)])\n",
    "L_2000_065_075, L_2000_SD_065_075 = L_3000_2000(Biweight_Location_2000_065_075, Biweight_Location_2000_SD_065_075, DL_Array_cm_065_075, DL_SD_cm_Array_065_075, np.array(Z_065_075)[np.array(L_2000_Wave_Index_065_075)])\n",
    "L_2000_075_085, L_2000_SD_075_085 = L_3000_2000(Biweight_Location_2000_075_085, Biweight_Location_2000_SD_075_085, DL_Array_cm_075_085, DL_SD_cm_Array_075_085, np.array(Z_075_085)[np.array(L_2000_Wave_Index_075_085)])\n",
    "L_2000_085_096, L_2000_SD_085_096 = L_3000_2000(Biweight_Location_2000_085_096, Biweight_Location_2000_SD_085_096, DL_Array_cm_085_096, DL_SD_cm_Array_085_096, np.array(Z_085_096)[np.array(L_2000_Wave_Index_085_096)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc1e41-7330-440f-9ba8-0ccfafb91c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c73bb280-0b78-4ccd-a970-d6fa8bc474a4",
   "metadata": {},
   "source": [
    "### <font color='#e55730' size=3 >**Getting the average L_3000 from the groups and the BH off of that**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4841184-561b-4bf0-8a41-30622cdd11bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the average values for the 3000 and 2000 angstrom continuum luminosities.\n",
    "\"\"\"\n",
    "L_3000_Mean_025_035, L_3000_Mean_SD_025_035 = calculate_simple_mean_with_std(L_3000_025_035, L_3000_SD_025_035)\n",
    "L_3000_Mean_035_045, L_3000_Mean_SD_035_045 = calculate_simple_mean_with_std(L_3000_035_045, L_3000_SD_035_045)\n",
    "L_3000_Mean_045_055, L_3000_Mean_SD_045_055 = calculate_simple_mean_with_std(L_3000_045_055, L_3000_SD_045_055)\n",
    "L_3000_Mean_055_065, L_3000_Mean_SD_055_065 = calculate_simple_mean_with_std(L_3000_055_065, L_3000_SD_055_065)\n",
    "L_3000_Mean_065_075, L_3000_Mean_SD_065_075 = calculate_simple_mean_with_std(L_3000_065_075, L_3000_SD_065_075)\n",
    "L_3000_Mean_075_085, L_3000_Mean_SD_075_085 = calculate_simple_mean_with_std(L_3000_075_085, L_3000_SD_075_085)\n",
    "#L_3000_Mean_085_096, L_3000_Mean_SD_085_096 = calculate_simple_mean_with_std(L_3000_085_096, L_3000_SD_085_096) \"\"\"This can't be done because the rest waves don't go high enough for the 3000 angstrom continuum.\"\"\"\n",
    "\n",
    "\n",
    "#L_2000_Mean_025_035, L_2000_Mean_SD_025_035 = calculate_simple_mean_with_std(L_2000_025_035, L_2000_SD_025_035) \"\"\"This can't be done because the rest waves don't go low enough for the 2000 angstrom continuum.\"\"\"\n",
    "L_2000_Mean_035_045, L_2000_Mean_SD_035_045 = calculate_simple_mean_with_std(L_2000_035_045, L_2000_SD_035_045)\n",
    "L_2000_Mean_045_055, L_2000_Mean_SD_045_055 = calculate_simple_mean_with_std(L_2000_045_055, L_2000_SD_045_055)\n",
    "L_2000_Mean_055_065, L_2000_Mean_SD_055_065 = calculate_simple_mean_with_std(L_2000_055_065, L_2000_SD_055_065)\n",
    "L_2000_Mean_065_075, L_2000_Mean_SD_065_075 = calculate_simple_mean_with_std(L_2000_065_075, L_2000_SD_065_075)\n",
    "L_2000_Mean_075_085, L_2000_Mean_SD_075_085 = calculate_simple_mean_with_std(L_2000_075_085, L_2000_SD_075_085)\n",
    "L_2000_Mean_085_096, L_2000_Mean_SD_085_096 = calculate_simple_mean_with_std(L_2000_085_096, L_2000_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92872e19-34a7-42a6-a4ba-f92e662b2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the ratio of the 3000 over 2000 angstrom continuum luminosities. \n",
    "\"\"\"\n",
    "\n",
    "#R_3000_2000_025_035 = L_3000_Mean_025_035/L_2000_Mean_025_035 \"\"\"This can't be done because the rest waves don't go low enough for the 2000 angstrom continuum.\"\"\"\n",
    "R_3000_2000_035_045 = L_3000_Mean_035_045/L_2000_Mean_035_045\n",
    "R_3000_2000_045_055 = L_3000_Mean_045_055/L_2000_Mean_045_055\n",
    "R_3000_2000_055_065 = L_3000_Mean_055_065/L_2000_Mean_055_065\n",
    "R_3000_2000_065_075 = L_3000_Mean_065_075/L_2000_Mean_065_075\n",
    "R_3000_2000_075_085 = L_3000_Mean_075_085/L_2000_Mean_075_085\n",
    "\n",
    "\n",
    "#R_3000_2000_SD_025_035 = abs(R_3000_2000_025_035) * np.sqrt( (L_3000_Mean_SD_025_035/L_3000_Mean_025_035)**2 + (L_2000_Mean_SD_025_035/L_2000_Mean_025_035)**2) \"\"\"This can't be done because the rest waves don't go low enough for the 2000 angstrom continuum.\"\"\"\n",
    "R_3000_2000_SD_035_045 = abs(R_3000_2000_035_045) * np.sqrt( (L_3000_Mean_SD_035_045/L_3000_Mean_035_045)**2 + (L_2000_Mean_SD_035_045/L_2000_Mean_035_045)**2)\n",
    "R_3000_2000_SD_045_055 = abs(R_3000_2000_045_055) * np.sqrt( (L_3000_Mean_SD_045_055/L_3000_Mean_045_055)**2 + (L_2000_Mean_SD_045_055/L_2000_Mean_045_055)**2)\n",
    "R_3000_2000_SD_055_065 = abs(R_3000_2000_055_065) * np.sqrt( (L_3000_Mean_SD_055_065/L_3000_Mean_055_065)**2 + (L_2000_Mean_SD_055_065/L_2000_Mean_055_065)**2)\n",
    "R_3000_2000_SD_065_075 = abs(R_3000_2000_065_075) * np.sqrt( (L_3000_Mean_SD_065_075/L_3000_Mean_065_075)**2 + (L_2000_Mean_SD_065_075/L_2000_Mean_065_075)**2)\n",
    "R_3000_2000_SD_075_085 = abs(R_3000_2000_075_085) * np.sqrt( (L_3000_Mean_SD_075_085/L_3000_Mean_075_085)**2 + (L_2000_Mean_SD_075_085/L_2000_Mean_075_085)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979827de-3e74-43c5-bafd-822ce19307fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the average of the ratios.\n",
    "This gives us a value that lets us use the 2000 angstroms to the 3000 angstroms continuum luminosities.\n",
    "\"\"\"\n",
    "\n",
    "R_3000_2000_Array = [R_3000_2000_035_045, R_3000_2000_045_055, R_3000_2000_055_065, R_3000_2000_065_075, R_3000_2000_075_085]\n",
    "R_3000_2000_SD_Array = [R_3000_2000_SD_035_045, R_3000_2000_SD_045_055, R_3000_2000_SD_055_065, R_3000_2000_SD_065_075, R_3000_2000_SD_075_085]\n",
    "\n",
    "R_3000_2000_Mean, R_3000_2000_Mean_SD = calculate_simple_mean_with_std(R_3000_2000_Array, R_3000_2000_SD_Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf23052-4b18-487e-8e4a-dcd010b0d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using the ratio of the 3000 to 2000 relationship to get the continuum luminosities at 3000 angstroms for the AGN that don't have 3000 angstrom wavelengths.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "L_3000_Mean_085_096 = np.multiply(R_3000_2000_Mean, L_2000_Mean_085_096)\n",
    "L_3000_Mean_SD_085_096 = abs(L_3000_Mean_085_096) * np.sqrt( \n",
    "    (np.divide(R_3000_2000_Mean_SD, R_3000_2000_Mean))**2 + \n",
    "    (np.divide(L_2000_Mean_SD_085_096, L_2000_Mean_085_096))**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b167a-8b07-4d58-8d40-34ee0926a424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a4076-4c28-45dc-9cde-82c5d45ba79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L_3000_Mean_SD_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92b4c1-4a5e-4286-a05b-209a480d2eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81228c14-1fff-4c8e-b3b4-b3a117613823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472337ef-c7a0-44b7-b895-ac0fc4f1309a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ce4d1-3c8e-4a44-a486-11738367ed28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343bb00-ede6-4233-af98-099e2a712639",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the Narrow part of the MgII (This is not to actually be used. We want to use the broad component.)\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Narrow_MgII_025_035_Mean, BH_Mass_Narrow_MgII_025_035_Mean_SD = black_hole_mass(3000, L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035, L_3000_Mean_SD_025_035, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Narrow_MgII_035_045_Mean, BH_Mass_Narrow_MgII_035_045_Mean_SD = black_hole_mass(3000, L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045, L_3000_Mean_SD_035_045, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Narrow_MgII_045_055_Mean, BH_Mass_Narrow_MgII_045_055_Mean_SD = black_hole_mass(3000, L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055, L_3000_Mean_SD_045_055, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Narrow_MgII_055_065_Mean, BH_Mass_Narrow_MgII_055_065_Mean_SD = black_hole_mass(3000, L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065, L_3000_Mean_SD_055_065, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Narrow_MgII_065_075_Mean, BH_Mass_Narrow_MgII_065_075_Mean_SD = black_hole_mass(3000, L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075, L_3000_Mean_SD_065_075, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Narrow_MgII_075_085_Mean, BH_Mass_Narrow_MgII_075_085_Mean_SD = black_hole_mass(3000, L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085, L_3000_Mean_SD_075_085, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Narrow_MgII_085_096_Mean, BH_Mass_Narrow_MgII_085_096_Mean_SD = black_hole_mass(3000, L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096, L_3000_Mean_SD_085_096, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b39a0-b7ad-4b53-805a-798037fe2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the Broad part of the MgII.\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Broad_MgII_025_035_Mean, BH_Mass_Broad_MgII_025_035_Mean_SD = black_hole_mass(3000, L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035, L_3000_Mean_SD_025_035, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Broad_MgII_035_045_Mean, BH_Mass_Broad_MgII_035_045_Mean_SD = black_hole_mass(3000, L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045, L_3000_Mean_SD_035_045, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Broad_MgII_045_055_Mean, BH_Mass_Broad_MgII_045_055_Mean_SD = black_hole_mass(3000, L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055, L_3000_Mean_SD_045_055, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Broad_MgII_055_065_Mean, BH_Mass_Broad_MgII_055_065_Mean_SD = black_hole_mass(3000, L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065, L_3000_Mean_SD_055_065, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Broad_MgII_065_075_Mean, BH_Mass_Broad_MgII_065_075_Mean_SD = black_hole_mass(3000, L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075, L_3000_Mean_SD_065_075, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Broad_MgII_075_085_Mean, BH_Mass_Broad_MgII_075_085_Mean_SD = black_hole_mass(3000, L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085, L_3000_Mean_SD_075_085, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Broad_MgII_085_096_Mean, BH_Mass_Broad_MgII_085_096_Mean_SD = black_hole_mass(3000, L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096, L_3000_Mean_SD_085_096, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096)\n",
    "\n",
    "\n",
    "print(BH_Mass_Broad_MgII_035_045_Mean, BH_Mass_Broad_MgII_035_045_Mean_SD, BH_Mass_Broad_MgII_035_045_Mean_SD/BH_Mass_Broad_MgII_035_045_Mean)\n",
    "print(\"\")\n",
    "print(L_3000_Mean_035_045, L_3000_Mean_SD_035_045, L_3000_Mean_SD_035_045/L_3000_Mean_035_045)\n",
    "print(\"\")\n",
    "print(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Center_SD_035_045/MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f10c3-3f0d-408c-bbce-c5e47170e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '-',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 1.5,\n",
    "    'xtick.minor.width': 1.0,\n",
    "    'ytick.major.width': 1.5,\n",
    "    'ytick.minor.width': 1.0,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': False,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with MNRAS-standard proportions (single column width)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 6.5), facecolor='white')\n",
    "\n",
    "# Color scheme (keeping your original colors)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Plot data points (keeping your heart marker style)\n",
    "# Note: Replace these variable names with your actual data arrays\n",
    "datasets = [\n",
    "    ('025_035', 'BH_Mass_Broad_MgII_025_035_Mean', 'L_3000_Mean_025_035', \n",
    "     'BH_Mass_Broad_MgII_025_035_Mean_SD', 'L_3000_Mean_SD_025_035'),\n",
    "    ('035_045', 'BH_Mass_Broad_MgII_035_045_Mean', 'L_3000_Mean_035_045',\n",
    "     'BH_Mass_Broad_MgII_035_045_Mean_SD', 'L_3000_Mean_SD_035_045'),\n",
    "    ('045_055', 'BH_Mass_Broad_MgII_045_055_Mean', 'L_3000_Mean_045_055',\n",
    "     'BH_Mass_Broad_MgII_045_055_Mean_SD', 'L_3000_Mean_SD_045_055'),\n",
    "    ('055_065', 'BH_Mass_Broad_MgII_055_065_Mean', 'L_3000_Mean_055_065',\n",
    "     'BH_Mass_Broad_MgII_055_065_Mean_SD', 'L_3000_Mean_SD_055_065'),\n",
    "    ('065_075', 'BH_Mass_Broad_MgII_065_075_Mean', 'L_3000_Mean_065_075',\n",
    "     'BH_Mass_Broad_MgII_065_075_Mean_SD', 'L_3000_Mean_SD_065_075'),\n",
    "    ('075_085', 'BH_Mass_Broad_MgII_075_085_Mean', 'L_3000_Mean_075_085',\n",
    "     'BH_Mass_Broad_MgII_075_085_Mean_SD', 'L_3000_Mean_SD_075_085'),\n",
    "    ('085_096', 'BH_Mass_Broad_MgII_085_096_Mean', 'L_3000_Mean_085_096',\n",
    "     'BH_Mass_Broad_MgII_085_096_Mean_SD', 'L_3000_Mean_SD_085_096')\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_var, y_var, x_err_var, y_err_var) in enumerate(datasets):\n",
    "    # Note: You'll need to replace these with your actual data variables\n",
    "    # For demonstration, using placeholder variable names\n",
    "    x_data = globals().get(x_var, [])  # Replace with your actual data\n",
    "    y_data = globals().get(y_var, [])  # Replace with your actual data\n",
    "    x_err = globals().get(x_err_var, [])  # Replace with your actual errors\n",
    "    y_err = globals().get(y_err_var, [])  # Replace with your actual errors\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data, \n",
    "              color=colors[key], \n",
    "              s=150,  # Slightly smaller for cleaner look\n",
    "              marker=u\"$\\u2665$\", \n",
    "              alpha=1.0, \n",
    "              zorder=10+i, \n",
    "              label=labels[i],\n",
    "              edgecolors='black',\n",
    "              linewidths=0.5)\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data, \n",
    "               xerr=x_err, yerr=y_err, \n",
    "               linestyle='', \n",
    "               ecolor='black', \n",
    "               capsize=4, \n",
    "               capthick=1.0, \n",
    "               elinewidth=1.0,\n",
    "               alpha=0.7,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes\n",
    "ax.set_xlabel(r'Black hole mass [M$_{\\odot}$]', fontsize=14)\n",
    "ax.set_ylabel(r'Continuum L$_{3000\\,\\mathrm{\\AA}}$ [W]', fontsize=14)\n",
    "\n",
    "# Set log scales if appropriate for your data\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper right',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=False,\n",
    "    shadow=False,\n",
    "    borderpad=0.5,\n",
    "    handletextpad=0.5,\n",
    "    columnspacing=0.8,\n",
    "    handlelength=1.2,\n",
    "    numpoints=1,\n",
    "    markerscale=0.8\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(True, which='major', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, which='minor', alpha=0.15, linestyle='-', linewidth=0.3)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12, \n",
    "               length=8, width=1.5, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10, \n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following line to save:\n",
    "# fig.savefig(\"mnras_agn_broad_mgii.pdf\", dpi=300, bbox_inches='tight', \n",
    "#             facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"mnras_agn_broad_mgii.png\", dpi=300, bbox_inches='tight',\n",
    "#             facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2086f8-e175-483b-a30d-a146b8ac3ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10b0cc-7a69-459b-b591-a3f3702b6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '-',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 1.5,\n",
    "    'xtick.minor.width': 1.0,\n",
    "    'ytick.major.width': 1.5,\n",
    "    'ytick.minor.width': 1.0,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': False,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with MNRAS-standard proportions (single column width)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 6.5), facecolor='white')\n",
    "\n",
    "# Color scheme (keeping your original colors)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Plot data points (keeping your heart marker style)\n",
    "# Note: Replace these variable names with your actual data arrays\n",
    "datasets = [\n",
    "    ('025_035', 'BH_Mass_Narrow_MgII_025_035_Mean', 'L_3000_Mean_025_035', \n",
    "     'BH_Mass_Narrow_MgII_025_035_Mean_SD', 'L_3000_Mean_SD_025_035'),\n",
    "    ('035_045', 'BH_Mass_Narrow_MgII_035_045_Mean', 'L_3000_Mean_035_045',\n",
    "     'BH_Mass_Narrow_MgII_035_045_Mean_SD', 'L_3000_Mean_SD_035_045'),\n",
    "    ('045_055', 'BH_Mass_Narrow_MgII_045_055_Mean', 'L_3000_Mean_045_055',\n",
    "     'BH_Mass_Narrow_MgII_045_055_Mean_SD', 'L_3000_Mean_SD_045_055'),\n",
    "    ('055_065', 'BH_Mass_Narrow_MgII_055_065_Mean', 'L_3000_Mean_055_065',\n",
    "     'BH_Mass_Narrow_MgII_055_065_Mean_SD', 'L_3000_Mean_SD_055_065'),\n",
    "    ('065_075', 'BH_Mass_Narrow_MgII_065_075_Mean', 'L_3000_Mean_065_075',\n",
    "     'BH_Mass_Narrow_MgII_065_075_Mean_SD', 'L_3000_Mean_SD_065_075'),\n",
    "    ('075_085', 'BH_Mass_Narrow_MgII_075_085_Mean', 'L_3000_Mean_075_085',\n",
    "     'BH_Mass_Narrow_MgII_075_085_Mean_SD', 'L_3000_Mean_SD_075_085'),\n",
    "    ('085_096', 'BH_Mass_Narrow_MgII_085_096_Mean', 'L_3000_Mean_085_096',\n",
    "     'BH_Mass_Narrow_MgII_085_096_Mean_SD', 'L_3000_Mean_SD_085_096')\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_var, y_var, x_err_var, y_err_var) in enumerate(datasets):\n",
    "    # Note: You'll need to replace these with your actual data variables\n",
    "    # For demonstration, using placeholder variable names\n",
    "    x_data = globals().get(x_var, [])  # Replace with your actual data\n",
    "    y_data = globals().get(y_var, [])  # Replace with your actual data\n",
    "    x_err = globals().get(x_err_var, [])  # Replace with your actual errors\n",
    "    y_err = globals().get(y_err_var, [])  # Replace with your actual errors\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data, \n",
    "              color=colors[key], \n",
    "              s=150,  # Slightly smaller for cleaner look\n",
    "              marker=u\"$\\u2665$\", \n",
    "              alpha=1.0,  # Full opacity as requested\n",
    "              zorder=10+i, \n",
    "              label=labels[i],\n",
    "              edgecolors='black',\n",
    "              linewidths=0.5)\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data, \n",
    "               xerr=x_err, yerr=y_err, \n",
    "               linestyle='', \n",
    "               ecolor='black', \n",
    "               capsize=4, \n",
    "               capthick=1.0, \n",
    "               elinewidth=1.0,\n",
    "               alpha=0.7,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes\n",
    "ax.set_xlabel(r'Black hole mass [M$_{\\odot}$]', fontsize=14)\n",
    "ax.set_ylabel(r'Continuum L$_{3000\\,\\mathrm{\\AA}}$ [W]', fontsize=14)\n",
    "\n",
    "# Set log scales if appropriate for your data\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=False,\n",
    "    shadow=False,\n",
    "    borderpad=0.5,\n",
    "    handletextpad=0.5,\n",
    "    columnspacing=0.8,\n",
    "    handlelength=1.2,\n",
    "    numpoints=1,\n",
    "    markerscale=0.8\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(True, which='major', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, which='minor', alpha=0.15, linestyle='-', linewidth=0.3)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12, \n",
    "               length=8, width=1.5, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10, \n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following line to save:\n",
    "# fig.savefig(\"mnras_agn_narrow_mgii.pdf\", dpi=300, bbox_inches='tight', \n",
    "#             facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"mnras_agn_narrow_mgii.png\", dpi=300, bbox_inches='tight',\n",
    "#             facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad382f3-2a3a-4544-884d-af06f21a75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffa0ae-0eb4-48f7-a37b-a384775737ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '-',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 1.5,\n",
    "    'xtick.minor.width': 1.0,\n",
    "    'ytick.major.width': 1.5,\n",
    "    'ytick.minor.width': 1.0,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': False,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with MNRAS-standard proportions (single column width)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 6.5), facecolor='white')\n",
    "\n",
    "# Color scheme (keeping your original colors)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Plot data points for velocity sigma (FWHM) analysis\n",
    "# Note: Replace these variable names with your actual data arrays\n",
    "datasets = [\n",
    "    ('025_035', 'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035', 'L_3000_Mean_025_035', \n",
    "     'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035', 'L_3000_Mean_SD_025_035'),\n",
    "    ('035_045', 'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045', 'L_3000_Mean_035_045',\n",
    "     'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045', 'L_3000_Mean_SD_035_045'),\n",
    "    ('045_055', 'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055', 'L_3000_Mean_045_055',\n",
    "     'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055', 'L_3000_Mean_SD_045_055'),\n",
    "    ('055_065', 'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065', 'L_3000_Mean_055_065',\n",
    "     'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065', 'L_3000_Mean_SD_055_065'),\n",
    "    ('065_075', 'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075', 'L_3000_Mean_065_075',\n",
    "     'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075', 'L_3000_Mean_SD_065_075'),\n",
    "    ('075_085', 'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085', 'L_3000_Mean_075_085',\n",
    "     'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085', 'L_3000_Mean_SD_075_085'),\n",
    "    ('085_096', 'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096', 'L_3000_Mean_085_096',\n",
    "     'MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096', 'L_3000_Mean_SD_085_096')\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_var, y_var, x_err_var, y_err_var) in enumerate(datasets):\n",
    "    # Note: You'll need to replace these with your actual data variables\n",
    "    # For demonstration, using placeholder variable names\n",
    "    x_data = globals().get(x_var, [])  # Replace with your actual data\n",
    "    y_data = globals().get(y_var, [])  # Replace with your actual data\n",
    "    x_err = globals().get(x_err_var, [])  # Replace with your actual errors\n",
    "    y_err = globals().get(y_err_var, [])  # Replace with your actual errors\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data, \n",
    "              color=colors[key], \n",
    "              s=150,  # Slightly smaller for cleaner look\n",
    "              marker=u\"$\\u2665$\", \n",
    "              alpha=1.0,  # Full opacity as requested\n",
    "              zorder=10+i, \n",
    "              label=labels[i],\n",
    "              edgecolors='black',\n",
    "              linewidths=0.5)\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data, \n",
    "               xerr=x_err, yerr=y_err, \n",
    "               linestyle='', \n",
    "               ecolor='black', \n",
    "               capsize=4, \n",
    "               capthick=1.0, \n",
    "               elinewidth=1.0,\n",
    "               alpha=0.7,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes\n",
    "ax.set_xlabel(r'FWHM [km s$^{-1}$]', fontsize=14)\n",
    "ax.set_ylabel(r'Continuum L$_{3000\\,\\mathrm{\\AA}}$ [W]', fontsize=14)\n",
    "\n",
    "# Set log scales if appropriate for your data\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper right',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=False,\n",
    "    shadow=False,\n",
    "    borderpad=0.5,\n",
    "    handletextpad=0.5,\n",
    "    columnspacing=0.8,\n",
    "    handlelength=1.2,\n",
    "    numpoints=1,\n",
    "    markerscale=0.8\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(True, which='major', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, which='minor', alpha=0.15, linestyle='-', linewidth=0.3)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12, \n",
    "               length=8, width=1.5, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10, \n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following line to save:\n",
    "# fig.savefig(\"mnras_agn_velocity_sigma.pdf\", dpi=300, bbox_inches='tight', \n",
    "#             facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"mnras_agn_velocity_sigma.png\", dpi=300, bbox_inches='tight',\n",
    "#             facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5a681-28e2-4236-8fd1-cfcf219d3039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f680c-f275-4cff-a355-bac01737daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '-',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 1.5,\n",
    "    'xtick.minor.width': 1.0,\n",
    "    'ytick.major.width': 1.5,\n",
    "    'ytick.minor.width': 1.0,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': False,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with MNRAS-standard proportions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 6.5), facecolor='white')\n",
    "\n",
    "# Color scheme (keeping your original colors)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Plot data points for each redshift bin\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035, L_3000_Mean_025_035, \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035, L_3000_Mean_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045, L_3000_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045, L_3000_Mean_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055, L_3000_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055, L_3000_Mean_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065, L_3000_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065, L_3000_Mean_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075, L_3000_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075, L_3000_Mean_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085, L_3000_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085, L_3000_Mean_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096, L_3000_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096, L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data, \n",
    "              color=colors[key], \n",
    "              s=150,  # Slightly smaller for cleaner look\n",
    "              marker=u\"$\\u2665$\", \n",
    "              alpha=1.0,  # Full opacity\n",
    "              zorder=10+i, \n",
    "              label=labels[i],\n",
    "              edgecolors='black',\n",
    "              linewidths=0.5)\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data, \n",
    "               xerr=x_err, yerr=y_err, \n",
    "               linestyle='', \n",
    "               ecolor='black', \n",
    "               capsize=4, \n",
    "               capthick=1.0, \n",
    "               elinewidth=1.0,\n",
    "               alpha=0.7,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes\n",
    "ax.set_xlabel(r'FWHM [km s$^{-1}$]', fontsize=14)\n",
    "ax.set_ylabel(r'Continuum L$_{3000\\,\\mathrm{\\AA}}$ [W]', fontsize=14)\n",
    "\n",
    "# Set title with proper formatting\n",
    "ax.set_title('Unconstrained Double Gaussian - Narrow', fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=False,\n",
    "    shadow=False,\n",
    "    borderpad=0.5,\n",
    "    handletextpad=0.5,\n",
    "    columnspacing=0.8,\n",
    "    handlelength=1.2,\n",
    "    numpoints=1,\n",
    "    markerscale=0.8\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(True, which='major', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, which='minor', alpha=0.15, linestyle='-', linewidth=0.3)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12, \n",
    "               length=8, width=1.5, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10, \n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"mnras_agn_narrow_gaussian.pdf\", dpi=300, bbox_inches='tight', \n",
    "#             facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"mnras_agn_narrow_gaussian.png\", dpi=300, bbox_inches='tight',\n",
    "#             facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c8fa1-df63-4805-ba6c-4cbd305ee2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '-',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 1.5,\n",
    "    'xtick.minor.width': 1.0,\n",
    "    'ytick.major.width': 1.5,\n",
    "    'ytick.minor.width': 1.0,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': False,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with MNRAS-standard proportions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 6.5), facecolor='white')\n",
    "\n",
    "# Color scheme (keeping your original colors)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Redshift values for each bin (midpoints)\n",
    "redshift_values = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Plot data points for each redshift bin\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035, \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, x_err) in enumerate(datasets):\n",
    "    y_data = redshift_values[i]\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data, \n",
    "              color=colors[key], \n",
    "              s=150,  # Slightly smaller for cleaner look\n",
    "              marker=u\"$\\u2665$\", \n",
    "              alpha=1.0,  # Full opacity\n",
    "              zorder=10+i, \n",
    "              label=labels[i],\n",
    "              edgecolors='black',\n",
    "              linewidths=0.5)\n",
    "    \n",
    "    # Plot error bars (only x-direction since y is fixed redshift values)\n",
    "    ax.errorbar(x_data, y_data, \n",
    "               xerr=x_err, \n",
    "               linestyle='', \n",
    "               ecolor='black', \n",
    "               capsize=4, \n",
    "               capthick=1.0, \n",
    "               elinewidth=1.0,\n",
    "               alpha=0.7,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes\n",
    "ax.set_xlabel(r'FWHM [km s$^{-1}$]', fontsize=14)\n",
    "ax.set_ylabel(r'Redshift', fontsize=14)\n",
    "\n",
    "# Set title with proper formatting\n",
    "ax.set_title('Unconstrained Double Gaussian - Broad', fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=False,\n",
    "    shadow=False,\n",
    "    borderpad=0.5,\n",
    "    handletextpad=0.5,\n",
    "    columnspacing=0.8,\n",
    "    handlelength=1.2,\n",
    "    numpoints=1,\n",
    "    markerscale=0.8\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(True, which='major', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, which='minor', alpha=0.15, linestyle='-', linewidth=0.3)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12, \n",
    "               length=8, width=1.5, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10, \n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Set y-axis limits to better show the redshift range\n",
    "ax.set_ylim(0.25, 1.0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"mnras_agn_broad_gaussian.pdf\", dpi=300, bbox_inches='tight', \n",
    "#             facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"mnras_agn_broad_gaussian.png\", dpi=300, bbox_inches='tight',\n",
    "#             facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddaa4b-1238-4a55-b63d-5bc87acc443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '-',\n",
    "    'grid.linewidth': 0.5,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 1.5,\n",
    "    'xtick.minor.width': 1.0,\n",
    "    'ytick.major.width': 1.5,\n",
    "    'ytick.minor.width': 1.0,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': False,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with MNRAS-standard proportions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8.5, 6.5), facecolor='white')\n",
    "\n",
    "# Color scheme (keeping your original colors)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Redshift values for each bin (midpoints)\n",
    "redshift_values = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Plot data points for each redshift bin\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035, \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, x_err) in enumerate(datasets):\n",
    "    y_data = redshift_values[i]\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data, \n",
    "              color=colors[key], \n",
    "              s=150,  # Slightly smaller for cleaner look\n",
    "              marker=u\"$\\u2665$\", \n",
    "              alpha=1.0,  # Full opacity\n",
    "              zorder=10+i, \n",
    "              label=labels[i],\n",
    "              edgecolors='black',\n",
    "              linewidths=0.5)\n",
    "    \n",
    "    # Plot error bars (only x-direction since y is fixed redshift values)\n",
    "    ax.errorbar(x_data, y_data, \n",
    "               xerr=x_err, \n",
    "               linestyle='', \n",
    "               ecolor='black', \n",
    "               capsize=4, \n",
    "               capthick=1.0, \n",
    "               elinewidth=1.0,\n",
    "               alpha=0.7,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes\n",
    "ax.set_xlabel(r'FWHM [km s$^{-1}$]', fontsize=14)\n",
    "ax.set_ylabel(r'Redshift', fontsize=14)\n",
    "\n",
    "# Set title with proper formatting\n",
    "ax.set_title('Unconstrained Double Gaussian - Narrow', fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=11,\n",
    "    frameon=True,\n",
    "    fancybox=False,\n",
    "    shadow=False,\n",
    "    borderpad=0.5,\n",
    "    handletextpad=0.5,\n",
    "    columnspacing=0.8,\n",
    "    handlelength=1.2,\n",
    "    numpoints=1,\n",
    "    markerscale=0.8\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.0)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(True, which='major', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, which='minor', alpha=0.15, linestyle='-', linewidth=0.3)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12, \n",
    "               length=8, width=1.5, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10, \n",
    "               length=4, width=1.0, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Set y-axis limits to better show the redshift range\n",
    "ax.set_ylim(0.25, 1.0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"mnras_agn_narrow_redshift.pdf\", dpi=300, bbox_inches='tight', \n",
    "#             facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"mnras_agn_narrow_redshift.png\", dpi=300, bbox_inches='tight',\n",
    "#             facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bf7d6-ebc1-455d-a361-b61cf496279b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "635d5251-d949-4662-8239-475df5e0b117",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Minimum PSF - Fitting the MgII Velocity Profile</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a716b-4576-42c1-9c10-ac8bf2463ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908c0ae-c6c5-4ab2-a85d-1fbb853f3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035,\n",
    "    y_err = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.70,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.4,\n",
    "    g1_sigma=700,              # Set narrow component width\n",
    "    g2_sigma=5001,             # Set broad component width\n",
    "    g1_center=250,          # Set narrow component center\n",
    "    g2_center=-550,          # Set broad component center\n",
    "    g1_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.53, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.9),\n",
    "    g2_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.75),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 7000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity+2000, 6000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-200, 500),\n",
    "    g2_center_bounds=(-1000, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model, PSF-limited $\\sigma$ (0.25 $\\leq$ z $\\less$ 0.35)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccde26-82a0-4eb5-950b-34859197e646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7747803-632b-4ef3-85b4-a5e965acd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.70,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.25,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4000,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=0,          # Set broad component center\n",
    "    g1_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.7, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.9),\n",
    "    g2_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.40),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 4000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-200, 500),\n",
    "    g2_center_bounds=(-1, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model, PSF-limited $\\sigma$ (0.35 $\\leq$ z $\\less$ 0.45)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435f183-fa34-4862-aa4b-6e873800756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff3d62-06aa-4ea4-870d-3d182bd2ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.80,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.15,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=200,          # Set narrow component center\n",
    "    g2_center=-200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.65, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.45),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 30000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model, PSF-limited $\\sigma$ (0.45 $\\leq$ z $\\less$ 0.55)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d9891-1e8e-4c65-b22c-28d088c68583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e804696-49f0-4fb4-8f1b-e308820e6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.65,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.20,\n",
    "    g1_sigma=1000,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=50,          # Set narrow component center\n",
    "    g2_center=-100,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.43, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.35),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 4500),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model, PSF-limited $\\sigma$ (0.55 $\\leq$ z $\\less$ 0.65)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c321f-f208-4792-a99c-b982522c62c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935111f0-0455-486e-9440-357f9af393ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.23,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=200,          # Set narrow component center\n",
    "    g2_center=-200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.6, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.4),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 4800),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model, PSF-limited $\\sigma$ (0.65 $\\leq$ z $\\less$ 0.75)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221e9b6-f97e-412b-9a48-7dffcecd5831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb8445-64d6-469c-a108-1e313673c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.25,\n",
    "    g1_sigma=900,              # Set narrow component width\n",
    "    g2_sigma=4800,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=0,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.6, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.40),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 30000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model, PSF-limited $\\sigma$ (0.75 $\\leq$ z $\\less$ 0.85)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546fc18-35ce-408c-96fd-737b86ee3494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54315042-5dd6-4f78-8645-4d9d49098204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096 = fit_MgII_spectrum_velocity(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.63,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.37,\n",
    "    g1_sigma=1100,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.4, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.8),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.68),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 4800),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ doublet fit: two-component Gaussian model, PSF-limited $\\sigma$ (0.85 $\\leq$ z $\\leq$ 0.96)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "plt.xlim(-20000, 15000)  # Set your desired limits\n",
    "#plt.ylim(-0.5e-16, 1.25e-16)\n",
    "\n",
    "# Get current axes and set limits\n",
    "fig = plt.gcf()  # Get current figure\n",
    "axes = fig.get_axes()  # Get all axes\n",
    "\n",
    "axes[0].set_ylim(-0.5e-16, 1.5e-16)  # Set y-limits for first panel (adjust values as needed)\n",
    "axes[1].set_ylim(-0.3e-16, 0.3e-16)  # Set y-limits for second panel (adjust values as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f6faf-1de3-4047-ac69-340c5127a72d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26705036-9821-4007-8c8b-49a4b53fbaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the returns from the fit_MgII_Spectrum.\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Residuals_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['residuals']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_025_035['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Residuals_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_035_045['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Residuals_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_045_055['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Residuals_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_055_065['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Residuals_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_065_075['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Residuals_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_075_085['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Residuals_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_085_096['uncertainties']['g2_amplitude']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab73c3-0d2e-40c2-973c-e4386e667345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_085_096\n",
    ", MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c6a0b-bfa7-4eed-95ba-67d89b95cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the Narrow part of the MgII (This is not to actually be used. We want to use the broad component.)\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_025_035_Mean, BH_Mass_Narrow_MgII_FWHM_Min_025_035_Mean_SD = black_hole_mass(3000, L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_025_035, L_3000_Mean_SD_025_035, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_035_045_Mean, BH_Mass_Narrow_MgII_FWHM_Min_035_045_Mean_SD = black_hole_mass(3000, L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_035_045, L_3000_Mean_SD_035_045, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_045_055_Mean, BH_Mass_Narrow_MgII_FWHM_Min_045_055_Mean_SD = black_hole_mass(3000, L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_045_055, L_3000_Mean_SD_045_055, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_055_065_Mean, BH_Mass_Narrow_MgII_FWHM_Min_055_065_Mean_SD = black_hole_mass(3000, L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_055_065, L_3000_Mean_SD_055_065, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_065_075_Mean, BH_Mass_Narrow_MgII_FWHM_Min_065_075_Mean_SD = black_hole_mass(3000, L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_065_075, L_3000_Mean_SD_065_075, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_075_085_Mean, BH_Mass_Narrow_MgII_FWHM_Min_075_085_Mean_SD = black_hole_mass(3000, L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_075_085, L_3000_Mean_SD_075_085, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_085_096_Mean, BH_Mass_Narrow_MgII_FWHM_Min_085_096_Mean_SD = black_hole_mass(3000, L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_085_096, L_3000_Mean_SD_085_096, \n",
    "                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4d4d2-9dc8-44e0-8fb6-cebb9dbbc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the Broad part of the MgII.\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Broad_MgII_FWHM_Min_025_035_Mean, BH_Mass_Broad_MgII_FWHM_Min_025_035_Mean_SD = black_hole_mass(3000, L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_025_035, L_3000_Mean_SD_025_035, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_035_045_Mean, BH_Mass_Broad_MgII_FWHM_Min_035_045_Mean_SD = black_hole_mass(3000, L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_035_045, L_3000_Mean_SD_035_045, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_045_055_Mean, BH_Mass_Broad_MgII_FWHM_Min_045_055_Mean_SD = black_hole_mass(3000, L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_045_055, L_3000_Mean_SD_045_055, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_055_065_Mean, BH_Mass_Broad_MgII_FWHM_Min_055_065_Mean_SD = black_hole_mass(3000, L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_055_065, L_3000_Mean_SD_055_065, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_065_075_Mean, BH_Mass_Broad_MgII_FWHM_Min_065_075_Mean_SD = black_hole_mass(3000, L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_065_075, L_3000_Mean_SD_065_075, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_075_085_Mean, BH_Mass_Broad_MgII_FWHM_Min_075_085_Mean_SD = black_hole_mass(3000, L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_075_085, L_3000_Mean_SD_075_085, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean, BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean_SD = black_hole_mass(3000, L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_085_096, L_3000_Mean_SD_085_096, \n",
    "                                                                                      MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_085_096)\n",
    "\n",
    "\n",
    "print(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_085_096/MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_085_096)\n",
    "print(\"\")\n",
    "print(L_3000_Mean_085_096, L_3000_Mean_SD_085_096, L_3000_Mean_SD_085_096/L_3000_Mean_085_096)\n",
    "print(\"\")\n",
    "print(BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean, BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean_SD, BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean_SD/BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4dcf40-71ef-4463-871d-7f318d2be44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting\n",
    "datasets = [\n",
    "    ('025_035', BH_Mass_Broad_MgII_FWHM_Min_025_035_Mean, L_3000_Mean_025_035,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_025_035_Mean_SD, L_3000_Mean_SD_025_035),\n",
    "    ('035_045', BH_Mass_Broad_MgII_FWHM_Min_035_045_Mean, L_3000_Mean_035_045,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_035_045_Mean_SD, L_3000_Mean_SD_035_045),\n",
    "    ('045_055', BH_Mass_Broad_MgII_FWHM_Min_045_055_Mean, L_3000_Mean_045_055,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_045_055_Mean_SD, L_3000_Mean_SD_045_055),\n",
    "    ('055_065', BH_Mass_Broad_MgII_FWHM_Min_055_065_Mean, L_3000_Mean_055_065,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_055_065_Mean_SD, L_3000_Mean_SD_055_065),\n",
    "    ('065_075', BH_Mass_Broad_MgII_FWHM_Min_065_075_Mean, L_3000_Mean_065_075,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_065_075_Mean_SD, L_3000_Mean_SD_065_075),\n",
    "    ('075_085', BH_Mass_Broad_MgII_FWHM_Min_075_085_Mean, L_3000_Mean_075_085,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_075_085_Mean_SD, L_3000_Mean_SD_075_085),\n",
    "    ('085_096', BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean, L_3000_Mean_085_096,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_085_096_Mean_SD, L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Narrow Component PSF Min Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb8f8c-dc1f-4372-ad84-bd33e595acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BH_Mass_Narrow_MgII_FWHM_Min_085_096_Mean, BH_Mass_Narrow_MgII_FWHM_Min_085_096_Mean_SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c7914-98ae-4a02-a258-b8188e9a9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting\n",
    "datasets = [\n",
    "    ('025_035', BH_Mass_Narrow_MgII_FWHM_Min_025_035_Mean, L_3000_Mean_025_035,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_025_035_Mean_SD, L_3000_Mean_SD_025_035),\n",
    "    ('035_045', BH_Mass_Narrow_MgII_FWHM_Min_035_045_Mean, L_3000_Mean_035_045,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_035_045_Mean_SD, L_3000_Mean_SD_035_045),\n",
    "    ('045_055', BH_Mass_Narrow_MgII_FWHM_Min_045_055_Mean, L_3000_Mean_045_055,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_045_055_Mean_SD, L_3000_Mean_SD_045_055),\n",
    "    ('055_065', BH_Mass_Narrow_MgII_FWHM_Min_055_065_Mean, L_3000_Mean_055_065,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_055_065_Mean_SD, L_3000_Mean_SD_055_065),\n",
    "    ('065_075', BH_Mass_Narrow_MgII_FWHM_Min_065_075_Mean, L_3000_Mean_065_075,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_065_075_Mean_SD, L_3000_Mean_SD_065_075),\n",
    "    ('075_085', BH_Mass_Narrow_MgII_FWHM_Min_075_085_Mean, L_3000_Mean_075_085,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_075_085_Mean_SD, L_3000_Mean_SD_075_085),\n",
    "    ('085_096', BH_Mass_Narrow_MgII_FWHM_Min_085_096_Mean, L_3000_Mean_085_096,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_085_096_Mean_SD, L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Narrow Component PSF Min Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deae172-ae84-437e-a1b5-93c45cec7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_025_035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42cb8f-0ec4-403f-8613-d32ec0e21b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_025_035, L_3000_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_025_035, L_3000_Mean_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_035_045, L_3000_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_035_045, L_3000_Mean_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_045_055, L_3000_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_045_055, L_3000_Mean_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_055_065, L_3000_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_055_065, L_3000_Mean_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_065_075, L_3000_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_065_075, L_3000_Mean_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_075_085, L_3000_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_075_085, L_3000_Mean_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_085_096, L_3000_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_085_096, L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Narrow Component PSF Min Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9ff9f-8ce7-463b-889c-d27500b91776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f031a12-7a9f-4be7-a7f2-6921408ca841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (using narrow component data)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_025_035, L_3000_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_025_035, L_3000_Mean_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_035_045, L_3000_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_035_045, L_3000_Mean_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_045_055, L_3000_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_045_055, L_3000_Mean_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_055_065, L_3000_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_055_065, L_3000_Mean_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_065_075, L_3000_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_065_075, L_3000_Mean_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_075_085, L_3000_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_075_085, L_3000_Mean_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_085_096, L_3000_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_085_096, L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Narrow Component PSF Min Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d96e86-f74a-4eae-b5c0-27d8e312443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-positions for each redshift bin (fixed values)\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (using broad component data)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035, \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, ((key, x_data, x_err), y_pos) in enumerate(zip(datasets, y_positions)):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_pos,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (only x-direction since y is fixed)\n",
    "    ax.errorbar(x_data, y_pos,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Narrow Component PSF Min Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c433106-a13a-4ff5-8c7b-5fc320c0693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-positions for each redshift bin (fixed values)\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (using narrow component data)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035, \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, ((key, x_data, x_err), y_pos) in enumerate(zip(datasets, y_positions)):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_pos,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (only x-direction since y is fixed)\n",
    "    ax.errorbar(x_data, y_pos,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Narrow Component PSF Min Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce3f03-ed2d-4ad1-a643-7993322e87be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3349ff4-1dbc-4dfd-b94a-69ba23e905bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe852372-03a5-49cb-832d-325597514f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d0b335f-cc1e-46f4-91d0-d14890fe0ecc",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Unifom Narrow Sigma - Fitting the MgII Velocity Profile</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae1e42-ef61-4daf-abe9-c4f58c18c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_MgII_spectrum_velocity_uniform_narrow_sigma(x, y, y_err=None, plot=True, \n",
    "                    mask=None,  # NEW: mask parameter\n",
    "                    mask_ranges=None,  # NEW: alternative way to specify mask ranges\n",
    "                    g1_amp=None,\n",
    "                    g2_amp=None,\n",
    "                    g1_sigma=None,\n",
    "                    g2_sigma=None,\n",
    "                    g1_center=None,\n",
    "                    g2_center=None,\n",
    "                    g1_amp_bounds=None,\n",
    "                    g2_amp_bounds=None,\n",
    "                    g1_sigma_bounds=None,  # This will be ignored as g1_sigma is fixed\n",
    "                    g2_sigma_bounds=None,\n",
    "                    g1_center_bounds=None,\n",
    "                    g2_center_bounds=None,\n",
    "                    title=\"0.25 < z < 0.35 - MgII Doublet Fit\",\n",
    "                    n_random_starts=50,  # Number of random starting points to try\n",
    "                    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "                    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "                    verbose=True):\n",
    "    \"\"\"\n",
    "    Enhanced MgII doublet fitting with multiple optimization strategies and masking capability.\n",
    "    \n",
    "    This function tries multiple approaches:\n",
    "    1. Grid search over parameter space\n",
    "    2. Random starting points\n",
    "    3. Differential evolution (global optimizer)\n",
    "    4. Returns the best fit among all attempts\n",
    "    5. Supports masking to ignore specific data regions during fitting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array-like\n",
    "        Independent variable (velocity)\n",
    "    y : array-like\n",
    "        Dependent variable (flux)\n",
    "    y_err : array-like, optional\n",
    "        Uncertainties in y\n",
    "    plot : bool, optional\n",
    "        Whether to create plots (default: True)\n",
    "    mask : array-like of bool, optional\n",
    "        Boolean mask where True indicates points to INCLUDE in fit.\n",
    "        If None, all points are used.\n",
    "    mask_ranges : list of tuples, optional\n",
    "        List of (min, max) tuples defining ranges to EXCLUDE from fit.\n",
    "        E.g., [(-100, 100), (500, 600)] excludes -100 to 100 and 500 to 600.\n",
    "        This is an alternative to providing a mask array directly.\n",
    "    \n",
    "    Additional Parameters:\n",
    "    ---------------------\n",
    "    n_random_starts : int, optional\n",
    "        Number of random starting points to try (default: 50)\n",
    "    use_grid_search : bool, optional\n",
    "        Whether to perform grid search over parameter space (default: True)\n",
    "    use_differential_evolution : bool, optional\n",
    "        Whether to use differential evolution global optimizer (default: True)\n",
    "    verbose : bool, optional\n",
    "        Whether to print detailed optimization progress (default: True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle masking\n",
    "    if mask_ranges is not None:\n",
    "        # Create mask from ranges\n",
    "        mask = np.ones(len(x), dtype=bool)  # Start with all True (include all)\n",
    "        for min_val, max_val in mask_ranges:\n",
    "            mask = mask & ~((x >= min_val) & (x <= max_val))  # Exclude ranges\n",
    "        if verbose:\n",
    "            excluded_points = len(x) - np.sum(mask)\n",
    "            print(f\"Masking {excluded_points} points from {len(mask_ranges)} ranges: {mask_ranges}\")\n",
    "    \n",
    "    elif mask is not None:\n",
    "        # Use provided mask\n",
    "        mask = np.array(mask, dtype=bool)\n",
    "        if len(mask) != len(x):\n",
    "            raise ValueError(\"Mask length must match data length\")\n",
    "        if verbose:\n",
    "            excluded_points = len(x) - np.sum(mask)\n",
    "            print(f\"Using provided mask: excluding {excluded_points} points\")\n",
    "    else:\n",
    "        # No masking - include all points\n",
    "        mask = np.ones(len(x), dtype=bool)\n",
    "        if verbose:\n",
    "            print(\"No masking applied - using all data points\")\n",
    "    \n",
    "    # Apply mask to data\n",
    "    x_fit = x[mask]\n",
    "    y_fit = y[mask]\n",
    "    y_err_fit = y_err[mask] if y_err is not None else None\n",
    "    \n",
    "    if len(x_fit) == 0:\n",
    "        raise ValueError(\"No data points remaining after masking!\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Fitting {len(x_fit)} out of {len(x)} data points\")\n",
    "    \n",
    "    # Scale y values and uncertainties by 1e17 for fitting\n",
    "    y_scaled = y_fit * 1e17\n",
    "    y_err_scaled = y_err_fit * 1e17 if y_err_fit is not None else None\n",
    "    \n",
    "    # Scale amplitude guesses and bounds by 1e17\n",
    "    g1_amp_scaled = g1_amp * 1e17 if g1_amp is not None else None\n",
    "    g2_amp_scaled = g2_amp * 1e17 if g2_amp is not None else None\n",
    "    \n",
    "    g1_amp_bounds_scaled = None\n",
    "    if g1_amp_bounds is not None:\n",
    "        g1_amp_bounds_scaled = (g1_amp_bounds[0] * 1e17, \n",
    "                               g1_amp_bounds[1] * 1e17 if g1_amp_bounds[1] is not None else None)\n",
    "    \n",
    "    g2_amp_bounds_scaled = None\n",
    "    if g2_amp_bounds is not None:\n",
    "        g2_amp_bounds_scaled = (g2_amp_bounds[0] * 1e17, \n",
    "                               g2_amp_bounds[1] * 1e17 if g2_amp_bounds[1] is not None else None)\n",
    "    \n",
    "    # Create a wrapper for the double_gaussian_model_velocity function that fixes g1_sigma\n",
    "    def fixed_sigma_model(x, g1_amp, g1_center, g2_amp, g2_center, g2_sigma):\n",
    "        return double_gaussian_model_velocity(x, g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma)\n",
    "    \n",
    "    # Define objective function for optimization (uses masked data)\n",
    "    def objective_function(params):\n",
    "        try:\n",
    "            model_values = fixed_sigma_model(x_fit, *params)\n",
    "            if y_err_scaled is not None:\n",
    "                chi_squared = np.sum(((y_scaled - model_values) / y_err_scaled)**2)\n",
    "            else:\n",
    "                chi_squared = np.sum((y_scaled - model_values)**2)\n",
    "            return chi_squared\n",
    "        except:\n",
    "            return np.inf\n",
    "    \n",
    "    # Parameter bounds for optimization\n",
    "    bounds = [\n",
    "        (g1_amp_bounds_scaled[0], g1_amp_bounds_scaled[1]),\n",
    "        (g1_center_bounds[0], g1_center_bounds[1]),\n",
    "        (g2_amp_bounds_scaled[0], g2_amp_bounds_scaled[1]),\n",
    "        (g2_center_bounds[0], g2_center_bounds[1]),\n",
    "        (g2_sigma_bounds[0], g2_sigma_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    best_result = None\n",
    "    best_chi_squared = np.inf\n",
    "    all_attempts = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Starting multi-strategy optimization...\")\n",
    "        print(f\"Parameter bounds: {bounds}\")\n",
    "    \n",
    "    # Strategy 1: Grid Search\n",
    "    if use_grid_search:\n",
    "        if verbose:\n",
    "            print(\"\\n1. Performing grid search...\")\n",
    "        \n",
    "        # Create grid of starting points\n",
    "        n_grid_points = 5  # Points per dimension\n",
    "        grid_ranges = []\n",
    "        for lower, upper in bounds:\n",
    "            if upper is None:\n",
    "                upper = lower * 3  # Reasonable upper bound if None\n",
    "            grid_ranges.append(np.linspace(lower, upper, n_grid_points))\n",
    "        \n",
    "        grid_count = 0\n",
    "        for grid_point in product(*grid_ranges):\n",
    "            try:\n",
    "                popt, pcov = curve_fit(fixed_sigma_model, x_fit, y_scaled, p0=list(grid_point), \n",
    "                                     bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                     method='trf', max_nfev=5000)\n",
    "                \n",
    "                chi_squared = objective_function(popt)\n",
    "                all_attempts.append(('grid', grid_point, popt, chi_squared))\n",
    "                \n",
    "                if chi_squared < best_chi_squared:\n",
    "                    best_chi_squared = chi_squared\n",
    "                    best_result = (popt, pcov)\n",
    "                    if verbose:\n",
    "                        print(f\"  New best from grid search: χ² = {chi_squared:.6f}\")\n",
    "                \n",
    "                grid_count += 1\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Grid search completed: {grid_count} successful fits\")\n",
    "    \n",
    "    # Strategy 2: Random Starting Points\n",
    "    if verbose:\n",
    "        print(f\"\\n2. Trying {n_random_starts} random starting points...\")\n",
    "    \n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    random_count = 0\n",
    "    \n",
    "    for i in range(n_random_starts):\n",
    "        # Generate random starting point within bounds\n",
    "        random_start = []\n",
    "        for lower, upper in bounds:\n",
    "            if upper is None:\n",
    "                upper = lower * 3\n",
    "            random_start.append(np.random.uniform(lower, upper))\n",
    "        \n",
    "        try:\n",
    "            popt, pcov = curve_fit(fixed_sigma_model, x_fit, y_scaled, p0=random_start, \n",
    "                                 bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                 method='trf', max_nfev=5000)\n",
    "            \n",
    "            chi_squared = objective_function(popt)\n",
    "            all_attempts.append(('random', random_start, popt, chi_squared))\n",
    "            \n",
    "            if chi_squared < best_chi_squared:\n",
    "                best_chi_squared = chi_squared\n",
    "                best_result = (popt, pcov)\n",
    "                if verbose:\n",
    "                    print(f\"  New best from random start {i+1}: χ² = {chi_squared:.6f}\")\n",
    "            \n",
    "            random_count += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Random starts completed: {random_count} successful fits\")\n",
    "    \n",
    "    # Strategy 3: Differential Evolution (Global Optimizer)\n",
    "    if use_differential_evolution:\n",
    "        if verbose:\n",
    "            print(\"\\n3. Running differential evolution global optimizer...\")\n",
    "        \n",
    "        try:\n",
    "            # Use differential evolution to find global minimum\n",
    "            de_bounds = [(lower, upper if upper is not None else lower * 3) for lower, upper in bounds]\n",
    "            \n",
    "            result = differential_evolution(objective_function, de_bounds, \n",
    "                                          maxiter=1000, popsize=15, seed=42)\n",
    "            \n",
    "            if result.success:\n",
    "                # Refine with curve_fit\n",
    "                try:\n",
    "                    popt, pcov = curve_fit(fixed_sigma_model, x_fit, y_scaled, p0=result.x, \n",
    "                                         bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                                         method='trf', max_nfev=5000)\n",
    "                    \n",
    "                    chi_squared = objective_function(popt)\n",
    "                    all_attempts.append(('differential_evolution', result.x, popt, chi_squared))\n",
    "                    \n",
    "                    if chi_squared < best_chi_squared:\n",
    "                        best_chi_squared = chi_squared\n",
    "                        best_result = (popt, pcov)\n",
    "                        if verbose:\n",
    "                            print(f\"  New best from differential evolution: χ² = {chi_squared:.6f}\")\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Differential evolution failed: {e}\")\n",
    "    \n",
    "    # Strategy 4: Try the original starting point too\n",
    "    if verbose:\n",
    "        print(\"\\n4. Trying original starting point...\")\n",
    "    \n",
    "    original_p0 = [g1_amp_scaled, g1_center, g2_amp_scaled, g2_center, g2_sigma]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(fixed_sigma_model, x_fit, y_scaled, p0=original_p0, \n",
    "                             bounds=([b[0] for b in bounds], [b[1] for b in bounds]),\n",
    "                             method='trf', max_nfev=10000)\n",
    "        \n",
    "        chi_squared = objective_function(popt)\n",
    "        all_attempts.append(('original', original_p0, popt, chi_squared))\n",
    "        \n",
    "        if chi_squared < best_chi_squared:\n",
    "            best_chi_squared = chi_squared\n",
    "            best_result = (popt, pcov)\n",
    "            if verbose:\n",
    "                print(f\"  Original starting point: χ² = {chi_squared:.6f}\")\n",
    "    except:\n",
    "        if verbose:\n",
    "            print(\"  Original starting point failed\")\n",
    "    \n",
    "    if best_result is None:\n",
    "        print(\"All optimization attempts failed!\")\n",
    "        return None\n",
    "    \n",
    "    popt, pcov = best_result\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nOptimization complete!\")\n",
    "        print(f\"Best χ² = {best_chi_squared:.6f}\")\n",
    "        print(f\"Total successful attempts: {len(all_attempts)}\")\n",
    "        \n",
    "        # Show top 5 results\n",
    "        all_attempts.sort(key=lambda x: x[3])  # Sort by chi-squared\n",
    "        print(f\"\\nTop 5 results:\")\n",
    "        for i, (method, start, final, chi2) in enumerate(all_attempts[:5]):\n",
    "            print(f\"  {i+1}. {method}: χ² = {chi2:.6f}\")\n",
    "    \n",
    "    # Continue with original processing code...\n",
    "    try:\n",
    "        # Scale amplitude parameters back to original scale\n",
    "        popt_unscaled = popt.copy()\n",
    "        popt_unscaled[0] /= 1e17  # g1_amp\n",
    "        popt_unscaled[2] /= 1e17  # g2_amp\n",
    "        \n",
    "        # Scale the covariance matrix back to original parameter space\n",
    "        pcov_unscaled = pcov.copy()\n",
    "        \n",
    "        # Scale factors for the fitted parameters only\n",
    "        # [g1_amp, g1_center, g2_amp, g2_center, g2_sigma]\n",
    "        scale_factors = np.array([1e17, 1, 1e17, 1, 1])\n",
    "        \n",
    "        # Correct transformation: Cov_unscaled[i,j] = Cov_scaled[i,j] / (scale_i * scale_j)\n",
    "        for i in range(len(scale_factors)):\n",
    "            for j in range(len(scale_factors)):\n",
    "                pcov_unscaled[i,j] = pcov[i,j] / (scale_factors[i] * scale_factors[j])\n",
    "        \n",
    "        # Extract uncertainties from the properly scaled covariance matrix\n",
    "        perr_unscaled = np.sqrt(np.diag(pcov_unscaled))\n",
    "        \n",
    "        # Now insert the fixed g1_sigma into the parameter arrays\n",
    "        # Insert at index 2 to get: [g1_amp, g1_center, g1_sigma, g2_amp, g2_center, g2_sigma]\n",
    "        full_popt = np.insert(popt_unscaled, 2, g1_sigma)\n",
    "        full_perr = np.insert(perr_unscaled, 2, 0.0)  # Zero error for fixed parameter\n",
    "\n",
    "        # Calculate best fit using the full parameter set (unscaled) and ORIGINAL x array\n",
    "        best_fit = double_gaussian_model_velocity(x, *full_popt)\n",
    "        \n",
    "        # Calculate residuals and percent error using original y values and ALL data points\n",
    "        residuals = y - best_fit\n",
    "        percent_error = 100 * residuals / np.where(y != 0, y, np.inf)\n",
    "        \n",
    "        # Calculate R-squared using original y values\n",
    "        ss_total = np.sum((y - np.mean(y))**2)\n",
    "        ss_residual = np.sum(residuals**2)\n",
    "        r_squared = 1 - (ss_residual / ss_total)\n",
    "        \n",
    "        # Calculate chi-squared using original y values and uncertainties\n",
    "        if y_err is not None:\n",
    "            chi_squared = np.sum((residuals / y_err)**2)\n",
    "            reduced_chi_squared = chi_squared / (len(x) - len(popt))\n",
    "        else:\n",
    "            chi_squared = np.sum(residuals**2)\n",
    "            reduced_chi_squared = chi_squared / (len(x) - len(popt))\n",
    "        \n",
    "        # Also calculate chi-squared for ONLY the fitted points\n",
    "        if y_err is not None:\n",
    "            chi_squared_fitted = np.sum((residuals[mask] / y_err[mask])**2)\n",
    "            reduced_chi_squared_fitted = chi_squared_fitted / (len(x_fit) - len(popt))\n",
    "        else:\n",
    "            chi_squared_fitted = np.sum(residuals[mask]**2)\n",
    "            reduced_chi_squared_fitted = chi_squared_fitted / (len(x_fit) - len(popt))\n",
    "        \n",
    "        # Calculate individual components using unscaled parameters\n",
    "        components = calc_components_velocity(x, full_popt)\n",
    "        \n",
    "        # Create output report\n",
    "        param_names = ['g1_amplitude', 'g1_center', 'g1_sigma', \n",
    "                      'g2_amplitude', 'g2_center', 'g2_sigma']\n",
    "        \n",
    "        fit_report = \"Multi-Strategy Fit Results with Masking:\\n\"\n",
    "        fit_report += f\"Data points used for fitting: {len(x_fit)}/{len(x)}\\n\"\n",
    "        fit_report += f\"R-squared (all data): {r_squared:.6f}\\n\"\n",
    "        fit_report += f\"Chi-squared (all data): {chi_squared:.6f}\\n\"\n",
    "        fit_report += f\"Reduced chi-squared (all data): {reduced_chi_squared:.6f}\\n\"\n",
    "        fit_report += f\"Chi-squared (fitted data only): {chi_squared_fitted:.6f}\\n\"\n",
    "        fit_report += f\"Reduced chi-squared (fitted data only): {reduced_chi_squared_fitted:.6f}\\n\"\n",
    "        fit_report += f\"Total optimization attempts: {len(all_attempts)}\\n\\n\"\n",
    "        fit_report += \"Parameters:\\n\"\n",
    "        \n",
    "        for name, val, err in zip(param_names, full_popt, full_perr):\n",
    "            if name == 'g1_sigma':\n",
    "                fit_report += f\"{name} = {val:.6g} (fixed)\\n\"\n",
    "            else:\n",
    "                fit_report += f\"{name} = {val:.6g} ± {err:.6g}\\n\"\n",
    "        \n",
    "        print(fit_report)\n",
    "        \n",
    "        if plot:\n",
    "            # Create figure\n",
    "            plt.rcParams['axes.grid'] = True\n",
    "            plt.rcParams['grid.alpha'] = 0.7\n",
    "            plt.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "            fig1 = plt.figure(figsize=(15, 12))\n",
    "            \n",
    "            # Create individual subplots with specific spacing\n",
    "            ax0 = fig1.add_axes([0.1, 0.45, 0.8, 0.45])  # [left, bottom, width, height]\n",
    "            ax1 = fig1.add_axes([0.1, 0.25, 0.8, 0.15], sharex=ax0)\n",
    "            ax2 = fig1.add_axes([0.1, 0.1, 0.8, 0.15], sharex=ax0)\n",
    "            \n",
    "            # Hide x-labels for first two plots\n",
    "            plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "            plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "            \n",
    "            axes = [ax0, ax1, ax2]\n",
    "            \n",
    "            # Plot 1: Overall fit with components (using original y values)\n",
    "            # Plot all data points\n",
    "            axes[0].step(x, y, where='mid', linewidth=2.25, color='#60B5FF', label='All Data', zorder=1)\n",
    "            axes[0].fill_between(x, y - y_err, y + y_err, color=\"#60B5FF\", alpha=0.3, zorder=0, step='mid', label=r\"2$\\sigma$ Error\")\n",
    "\n",
    "                        # Highlight masked (excluded) regions as separate step plots\n",
    "            if not np.all(mask):\n",
    "                # Find continuous masked regions\n",
    "                masked_indices = np.where(~mask)[0]\n",
    "                if len(masked_indices) > 0:\n",
    "                    # Group consecutive indices\n",
    "                    groups = []\n",
    "                    current_group = [masked_indices[0]]\n",
    "                    \n",
    "                    for i in range(1, len(masked_indices)):\n",
    "                        if masked_indices[i] == masked_indices[i-1] + 1:\n",
    "                            current_group.append(masked_indices[i])\n",
    "                        else:\n",
    "                            groups.append(current_group)\n",
    "                            current_group = [masked_indices[i]]\n",
    "                    groups.append(current_group)\n",
    "                    \n",
    "                    # Plot each group separately\n",
    "                    for i, group in enumerate(groups):\n",
    "                        label = 'Masked Data' if i == 0 else None\n",
    "                        axes[0].step(x[group], y[group], where='mid', linewidth=2.25, color='red', alpha=0.7, \n",
    "                                   label=label, zorder=2)\n",
    "                        axes[0].fill_between(x[group], y[group] - y_err[group], y[group] + y_err[group], \n",
    "                                           color=\"red\", alpha=0.2, zorder=0, step='mid')\n",
    "            axes[0].plot(x, best_fit, '-', linewidth=2.25, color='black', label='Best fit', zorder=4)\n",
    "            axes[0].plot(x, components['gaussian1'], '-', linewidth=4.5, color='#a714ff', label='Narrow component', zorder=2)\n",
    "            axes[0].plot(x, components['gaussian2'], '-', linewidth=4.5, color='#ff14f5', label='Broad component', zorder=3)\n",
    "            \n",
    "            # Mark the centers of the Gaussian components\n",
    "            axes[0].plot(x, np.full(len(x), 0), color='#ffbb14', linestyle='-', linewidth=4.5, zorder=1, label=\"Exponential Component\")\n",
    "\n",
    "            axes[0].axvline(x=full_popt[1], color='#a714ff', linestyle=':', alpha=0.7)\n",
    "            axes[0].axvline(x=full_popt[4], color='#ff14f5', linestyle=':', alpha=0.7)\n",
    "            \n",
    "            axes[0].legend(facecolor=\"white\", labelcolor=\"black\", fontsize=12, frameon=True, fancybox=True, shadow=True, \n",
    "                           edgecolor=\"black\", borderpad=1, handlelength=4.0)  \n",
    "                           \n",
    "            axes[0].set_ylabel(r'Flux [$erg s^{-1} cm^{-2} \\AA^{-1}$]', size='14', color=\"black\")\n",
    "            axes[0].set_title(title, fontsize=14)\n",
    "            \n",
    "            # Plot 2: Residuals (using original scale)\n",
    "            axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot residuals for fitted points\n",
    "            axes[1].scatter(x[mask], residuals[mask], marker='o', s=30, c='#00FF9C', edgecolors=\"black\", alpha=0.7, label='Fitted')\n",
    "            \n",
    "            # Plot residuals for masked points (if any)\n",
    "            if not np.all(mask):\n",
    "                axes[1].scatter(x[~mask], residuals[~mask], marker='x', s=40, c='red', alpha=0.7, label='Masked')\n",
    "            \n",
    "            axes[1].fill_between(x, 0 - y_err, 0 + y_err, color=\"#60B5FF\", alpha=0.3, zorder=0)\n",
    "            \n",
    "            if not np.all(mask):\n",
    "                axes[1].legend(fontsize=10)\n",
    "            \n",
    "            axes[1].set_ylabel('Residuals', size='14', color='black')\n",
    "            \n",
    "            # Plot 3: Percent error\n",
    "            axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot percent error for fitted points\n",
    "            axes[2].scatter(x[mask], percent_error[mask], marker='o', s=30, c='#00FF9C', edgecolors=\"black\", alpha=0.7, label='Fitted')\n",
    "            \n",
    "            # Plot percent error for masked points (if any)\n",
    "            if not np.all(mask):\n",
    "                axes[2].scatter(x[~mask], percent_error[~mask], marker='x', s=40, c='red', alpha=0.7, label='Masked')\n",
    "\n",
    "            # Filter out infinite or very large percent errors for better visualization\n",
    "            valid_percent = np.where(np.abs(percent_error) < 1000, percent_error, np.nan)\n",
    "            max_err = np.nanmax(np.abs(valid_percent))\n",
    "            if np.isfinite(max_err) and max_err > 0:\n",
    "                y_limit = min(max_err * 1.2, 130)\n",
    "                axes[2].set_ylim(-y_limit, y_limit)\n",
    "            \n",
    "            if not np.all(mask):\n",
    "                axes[2].legend(fontsize=10)\n",
    "            \n",
    "            axes[2].set_xlabel(r'Velocity [km $s^{-1}$]', size='14', color='black')\n",
    "            axes[2].set_ylabel('Percent Error [%]', size='14')\n",
    "            \n",
    "            # Make the axes thicker\n",
    "            for ax in axes:\n",
    "                ax.spines['top'].set_linewidth(2.5)\n",
    "                ax.spines['right'].set_linewidth(2.5)\n",
    "                ax.spines['left'].set_linewidth(2.5)\n",
    "                ax.spines['bottom'].set_linewidth(2.5)\n",
    "            \n",
    "                ax.tick_params(axis='both', which='major', width=2)\n",
    "                ax.tick_params(axis='both', which='minor', width=1)\n",
    "                ax.grid(visible=True, which='both', axis='both', linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "            # Use Times New Roman for a more formal look in publications\n",
    "            plt.rcParams['font.family'] = 'serif'\n",
    "            plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "            \n",
    "            # Set tick label size\n",
    "            for ax in axes:\n",
    "                ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "                ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "                ax.grid(visible=True, which='major', axis='both', linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        # Return results with additional information about optimization attempts and masking\n",
    "        results = {\n",
    "            'parameters': dict(zip(param_names, full_popt)),\n",
    "            'uncertainties': dict(zip(param_names, full_perr)),\n",
    "            'fit': best_fit,\n",
    "            'residuals': residuals,\n",
    "            'percent_error': percent_error,\n",
    "            'r_squared': r_squared,\n",
    "            'chi_squared': chi_squared,\n",
    "            'reduced_chi_squared': reduced_chi_squared,\n",
    "            'chi_squared_fitted_only': chi_squared_fitted,\n",
    "            'reduced_chi_squared_fitted_only': reduced_chi_squared_fitted,\n",
    "            'components': components,\n",
    "            'optimization_attempts': len(all_attempts),\n",
    "            'best_chi_squared': best_chi_squared,\n",
    "            'all_attempts': all_attempts,\n",
    "            'mask': mask,\n",
    "            'n_fitted_points': len(x_fit),\n",
    "            'n_total_points': len(x)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during results processing: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "######################################################################################################################################################################################\n",
    "def find_emission_line_bounds(velocity, flux, \n",
    "                             sigma_threshold=3.0, \n",
    "                             min_velocity_width=200, \n",
    "                             max_velocity_width=500,\n",
    "                             fractional_intensity=0.05,\n",
    "                             continuum_regions=None,\n",
    "                             smooth_kernel_size=3,\n",
    "                             return_diagnostics=False):\n",
    "    \"\"\"\n",
    "    Determine the boundaries of an emission line for spectral masking using velocity arrays.\n",
    "    \n",
    "    This function implements a multi-criteria approach combining:\n",
    "    - Signal-to-noise ratio thresholding\n",
    "    - Velocity-based limits\n",
    "    - Fractional peak intensity\n",
    "    - Derivative-based detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    velocity : array-like\n",
    "        Velocity array in km/s (relative to line center, typically centered at 0)\n",
    "    flux : array-like\n",
    "        Flux array corresponding to velocity\n",
    "    sigma_threshold : float, default=3.0\n",
    "        Number of sigma above continuum noise for detection\n",
    "    min_velocity_width : float, default=200\n",
    "        Minimum velocity width (km/s) to include around line center (±km/s)\n",
    "    max_velocity_width : float, default=500\n",
    "        Maximum velocity width (km/s) to consider for line boundaries (±km/s)\n",
    "    fractional_intensity : float, default=0.05\n",
    "        Fraction of peak intensity (0.05 = 5%) for boundary detection\n",
    "    continuum_regions : list of tuples, optional\n",
    "        [(vel_start1, vel_end1), (vel_start2, vel_end2)] for continuum estimation\n",
    "        If None, uses regions far from the line center (> max_velocity_width * 1.5)\n",
    "    smooth_kernel_size : int, default=3\n",
    "        Size of smoothing kernel for derivative calculation\n",
    "    return_diagnostics : bool, default=False\n",
    "        If True, returns additional diagnostic information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bounds : tuple\n",
    "        (lower_velocity, upper_velocity) defining the emission line region in km/s\n",
    "    diagnostics : dict (optional)\n",
    "        Dictionary containing diagnostic information if return_diagnostics=True\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    velocity = np.array(velocity)\n",
    "    flux = np.array(flux)\n",
    "    \n",
    "    # Define search region based on maximum velocity width\n",
    "    search_mask = np.abs(velocity) <= max_velocity_width\n",
    "    search_indices = np.where(search_mask)[0]\n",
    "    \n",
    "    if len(search_indices) < 10:\n",
    "        raise ValueError(\"Search region too small. Check velocity range and max_velocity_width.\")\n",
    "    \n",
    "    # Estimate continuum and noise\n",
    "    if continuum_regions is None:\n",
    "        # Automatically define continuum regions far from the line center\n",
    "        continuum_mask = np.abs(velocity) > max_velocity_width * 1.5\n",
    "        if np.sum(continuum_mask) < 20:\n",
    "            # Fallback: use outer regions of the velocity array\n",
    "            n_points = len(flux)\n",
    "            edge_fraction = 0.1\n",
    "            continuum_mask = np.zeros(n_points, dtype=bool)\n",
    "            continuum_mask[:int(n_points * edge_fraction)] = True\n",
    "            continuum_mask[-int(n_points * edge_fraction):] = True\n",
    "    else:\n",
    "        continuum_mask = np.zeros(len(velocity), dtype=bool)\n",
    "        for vel_start, vel_end in continuum_regions:\n",
    "            region_mask = (velocity >= vel_start) & (velocity <= vel_end)\n",
    "            continuum_mask |= region_mask\n",
    "    \n",
    "    # Calculate continuum level and noise\n",
    "    continuum_flux = flux[continuum_mask]\n",
    "    if len(continuum_flux) < 5:\n",
    "        warnings.warn(\"Very few continuum points available. Results may be unreliable.\")\n",
    "        continuum_level = np.median(flux)\n",
    "        noise_level = np.std(flux) * 0.1  # Conservative estimate\n",
    "    else:\n",
    "        continuum_level = np.median(continuum_flux)\n",
    "        # Use median absolute deviation for robust noise estimation\n",
    "        noise_level = median_abs_deviation(continuum_flux, scale='normal')\n",
    "    \n",
    "    # Method 1: Signal-to-noise threshold\n",
    "    snr_threshold = continuum_level + sigma_threshold * noise_level\n",
    "    snr_mask = flux > snr_threshold\n",
    "    \n",
    "    # Method 2: Find peak and apply fractional intensity threshold\n",
    "    search_flux = flux[search_mask]\n",
    "    peak_idx_local = np.argmax(search_flux)\n",
    "    peak_idx_global = search_indices[peak_idx_local]\n",
    "    peak_flux = flux[peak_idx_global]\n",
    "    \n",
    "    fractional_threshold = continuum_level + fractional_intensity * (peak_flux - continuum_level)\n",
    "    fractional_mask = flux > fractional_threshold\n",
    "    \n",
    "    # Method 3: Derivative-based detection (smoothed)\n",
    "    if smooth_kernel_size > 1:\n",
    "        smoothed_flux = ndimage.uniform_filter1d(flux, smooth_kernel_size)\n",
    "    else:\n",
    "        smoothed_flux = flux.copy()\n",
    "    \n",
    "    # Calculate derivative\n",
    "    derivative = np.gradient(smoothed_flux, velocity)\n",
    "    derivative_threshold = 3 * np.std(derivative[continuum_mask])\n",
    "    \n",
    "    # Find regions where derivative is significant\n",
    "    significant_derivative = np.abs(derivative) > derivative_threshold\n",
    "    \n",
    "    # Combine all methods\n",
    "    # Start with SNR detection as primary criterion\n",
    "    combined_mask = snr_mask.copy()\n",
    "    \n",
    "    # Expand to include fractional intensity regions\n",
    "    combined_mask |= fractional_mask\n",
    "    \n",
    "    # Further expand to include significant derivative regions near the line\n",
    "    nearby_mask = np.abs(velocity) <= max_velocity_width\n",
    "    combined_mask |= (significant_derivative & nearby_mask)\n",
    "    \n",
    "    # Find connected components and select the one containing the peak\n",
    "    labeled_regions, n_regions = ndimage.label(combined_mask)\n",
    "    \n",
    "    if n_regions == 0:\n",
    "        # Fallback: use minimum velocity width around peak\n",
    "        peak_velocity = velocity[peak_idx_global]\n",
    "        min_vel_mask = np.abs(velocity - peak_velocity) <= min_velocity_width\n",
    "        bounds_indices = np.where(min_vel_mask)[0]\n",
    "        lower_bound = velocity[bounds_indices[0]]\n",
    "        upper_bound = velocity[bounds_indices[-1]]\n",
    "    else:\n",
    "        # Select region containing the peak\n",
    "        peak_region_label = labeled_regions[peak_idx_global]\n",
    "        if peak_region_label == 0:\n",
    "            # Peak not in any detected region, use closest region\n",
    "            region_centers = []\n",
    "            for i in range(1, n_regions + 1):\n",
    "                region_indices = np.where(labeled_regions == i)[0]\n",
    "                region_center = np.mean(region_indices)\n",
    "                region_centers.append((i, region_center))\n",
    "            \n",
    "            # Find closest region to peak\n",
    "            distances = [abs(center - peak_idx_global) for _, center in region_centers]\n",
    "            closest_region_idx = np.argmin(distances)\n",
    "            peak_region_label = region_centers[closest_region_idx][0]\n",
    "        \n",
    "        # Get boundaries of the selected region\n",
    "        region_mask = labeled_regions == peak_region_label\n",
    "        region_indices = np.where(region_mask)[0]\n",
    "        \n",
    "        # Ensure minimum velocity width\n",
    "        peak_velocity = velocity[peak_idx_global]\n",
    "        min_lower_vel = peak_velocity - min_velocity_width\n",
    "        min_upper_vel = peak_velocity + min_velocity_width\n",
    "        \n",
    "        # Get actual bounds\n",
    "        lower_bound = velocity[region_indices[0]]\n",
    "        upper_bound = velocity[region_indices[-1]]\n",
    "        \n",
    "        # Apply minimum width constraint\n",
    "        lower_bound = min(lower_bound, min_lower_vel)\n",
    "        upper_bound = max(upper_bound, min_upper_vel)\n",
    "        \n",
    "        # Apply maximum width constraint\n",
    "        max_lower_vel = peak_velocity - max_velocity_width\n",
    "        max_upper_vel = peak_velocity + max_velocity_width\n",
    "        \n",
    "        lower_bound = max(lower_bound, max_lower_vel)\n",
    "        upper_bound = min(upper_bound, max_upper_vel)\n",
    "    \n",
    "    bounds = (lower_bound, upper_bound)\n",
    "    \n",
    "    if return_diagnostics:\n",
    "        # Calculate final velocity range\n",
    "        final_lower_vel = lower_bound\n",
    "        final_upper_vel = upper_bound\n",
    "        \n",
    "        diagnostics = {\n",
    "            'continuum_level': continuum_level,\n",
    "            'noise_level': noise_level,\n",
    "            'snr_threshold': snr_threshold,\n",
    "            'peak_flux': peak_flux,\n",
    "            'fractional_threshold': fractional_threshold,\n",
    "            'peak_velocity': velocity[peak_idx_global],\n",
    "            'velocity_range_km_s': (final_lower_vel, final_upper_vel),\n",
    "            'line_width_km_s': final_upper_vel - final_lower_vel,\n",
    "            'masks': {\n",
    "                'snr_mask': snr_mask,\n",
    "                'fractional_mask': fractional_mask,\n",
    "                'derivative_mask': significant_derivative,\n",
    "                'combined_mask': combined_mask,\n",
    "                'final_mask': (velocity >= lower_bound) & (velocity <= upper_bound)\n",
    "            }\n",
    "        }\n",
    "        return bounds, diagnostics\n",
    "    \n",
    "    return bounds\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035 = find_emission_line_bounds(\n",
    "                             MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035, MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035, \n",
    "                             sigma_threshold=3.0, \n",
    "                             min_velocity_width=200, \n",
    "                             max_velocity_width=20000,\n",
    "                             fractional_intensity=0.05,\n",
    "                             continuum_regions=None,\n",
    "                             smooth_kernel_size=3,\n",
    "                             return_diagnostics=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2454a-5a7c-4420-a676-6cdbea143f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the average sigma value for the narrow gaussian component.\n",
    "\"\"\"\n",
    "Uniform_Narrow_Sigma = np.average([MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_035_045, \n",
    "                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_055_065, \n",
    "                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_075_085, \n",
    "                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_085_096])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9542a-50a8-4945-85ee-b41a233ca211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035 = fit_MgII_spectrum_velocity_uniform_narrow_sigma(\n",
    "            MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035,\n",
    "            MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035,\n",
    "            y_err = MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_025_035*2,\n",
    "            g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.70,\n",
    "            g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.4,\n",
    "            g1_sigma=Uniform_Narrow_Sigma,              # Set narrow component width\n",
    "            g2_sigma=5000,             # Set broad component width\n",
    "            g1_center=100,          # Set narrow component center\n",
    "            g2_center=-550,          # Set broad component center\n",
    "            g1_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.5, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.9),\n",
    "            g2_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_025_035) * 0.9),      \n",
    "            g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "            g2_sigma_bounds=(FWHM_Velocity, 6000),    # Set bounds for broad component width\n",
    "            g1_center_bounds=(-800, 500),\n",
    "            g2_center_bounds=(-1500, 500),\n",
    "            title = r\"MgII 2800$\\AA$ fit: fixed narrow + broad Gaussian (0.25 $\\leq$ z $\\less$ 0.35)\",\n",
    "            n_random_starts=150,  # Number of random starting points to try\n",
    "            use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "            use_differential_evolution=True,  # Whether to use differential evolution\n",
    "            verbose=True,\n",
    "            mask_ranges=([\n",
    "                (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[0]),\n",
    "                (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_025_035[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_025_035))]),\n",
    "            plot=True\n",
    ")\n",
    "print(Uniform_Narrow_Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bc6d0-60c9-434a-99d8-8e3d02991f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f72cd-c329-4522-9565-7741439c1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045 = fit_MgII_spectrum_velocity_uniform_narrow_sigma(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_035_045*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.70,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.15,\n",
    "    g1_sigma=Uniform_Narrow_Sigma,              # Set narrow component width\n",
    "    g2_sigma=3000,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=-200,          # Set broad component center\n",
    "    g1_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.7, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.85),\n",
    "    g2_amp_bounds= (np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_035_045) * 0.4),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 100000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-200, 500),\n",
    "    g2_center_bounds=(-400, -200),\n",
    "    title = r\"MgII 2800$\\AA$ fit: fixed narrow + broad Gaussian (0.35 $\\leq$ z $\\less$ 0.45)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_035_045[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_035_045[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_035_045))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e909202-428c-4db1-b844-a47a23344871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab3a9a-8747-480c-b78c-41460a23e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055 = fit_MgII_spectrum_velocity_uniform_narrow_sigma(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_045_055*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.80,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.15,\n",
    "    g1_sigma=Uniform_Narrow_Sigma,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=200,          # Set narrow component center\n",
    "    g2_center=-200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.65, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.83),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_045_055) * 0.45),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 4500),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ fit: fixed narrow + broad Gaussian (0.45 $\\leq$ z $\\less$ 0.55)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_045_055[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_045_055[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_045_055))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e31249-f27f-4c66-b06e-06ebbc4598e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699776f9-8dae-455e-a7e3-4c04f7bf9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065 = fit_MgII_spectrum_velocity_uniform_narrow_sigma(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_055_065*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.65,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.20,\n",
    "    g1_sigma=Uniform_Narrow_Sigma,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=50,          # Set narrow component center\n",
    "    g2_center=-100,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.43, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_055_065) * 0.35),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 4400),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ fit: fixed narrow + broad Gaussian (0.55 $\\leq$ z $\\less$ 0.65)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_055_065[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_055_065[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_055_065))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69370f-17b1-4d2b-a3b2-757002515389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678a403-60cb-4429-baab-6f19e385aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075 = fit_MgII_spectrum_velocity_uniform_narrow_sigma(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_065_075*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.23,\n",
    "    g1_sigma=Uniform_Narrow_Sigma,              # Set narrow component width\n",
    "    g2_sigma=4500,             # Set broad component width\n",
    "    g1_center=200,          # Set narrow component center\n",
    "    g2_center=-200,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.6, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.85),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_065_075) * 0.40),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 4800),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ fit: fixed narrow + broad Gaussian (0.65 $\\leq$ z $\\less$ 0.75)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_065_075[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_065_075[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_065_075))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb833e-43fc-4f13-a659-1f9d2e5bbce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9de2ff-8f65-4b9d-a93b-d28036e7cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085 = fit_MgII_spectrum_velocity_uniform_narrow_sigma(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_075_085*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.75,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.25,\n",
    "    g1_sigma=Uniform_Narrow_Sigma,              # Set narrow component width\n",
    "    g2_sigma=4800,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=0,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.6, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_075_085) * 0.40),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 30000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ fit: fixed narrow + broad Gaussian (0.75 $\\leq$ z $\\less$ 0.85)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_075_085[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_075_085[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_075_085))]),\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391f4e5-f57a-4a85-97ae-b895bf1fc40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c167ff4-3336-459b-8c3d-2d53fbcad576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FWHM_Velocity = 374.740625 km / s\n",
    "\"\"\"\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096 = fit_MgII_spectrum_velocity_uniform_narrow_sigma(\n",
    "    MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096,\n",
    "    MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096,\n",
    "    y_err=MgII_Continuum_Removed_ReStacked_Continuum_Scaled_SD_085_096*2,\n",
    "    g1_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.63,\n",
    "    g2_amp = np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.37,\n",
    "    g1_sigma=Uniform_Narrow_Sigma,              # Set narrow component width\n",
    "    g2_sigma=4800,             # Set broad component width\n",
    "    g1_center=0,          # Set narrow component center\n",
    "    g2_center=0,          # Set broad component center\n",
    "    g1_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.4, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.9),\n",
    "    g2_amp_bounds=(np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.1, np.max(MgII_Continuum_Removed_ReStacked_Continuum_Scaled_085_096) * 0.6),      \n",
    "    g1_sigma_bounds=(FWHM_Velocity, 30000),  # Set bounds for narrow component width\n",
    "    g2_sigma_bounds=(FWHM_Velocity, 30000),    # Set bounds for broad component width\n",
    "    g1_center_bounds=(-500, 500),\n",
    "    g2_center_bounds=(-500, 500),\n",
    "    title = r\"MgII 2800$\\AA$ fit: fixed narrow + broad Gaussian (0.85 $\\leq$ z $\\leq$ 0.96)\",\n",
    "    n_random_starts=150,  # Number of random starting points to try\n",
    "    use_grid_search=True,  # Whether to use grid search in addition to random starts\n",
    "    use_differential_evolution=True,  # Whether to use differential evolution\n",
    "    verbose=True,\n",
    "    mask_ranges=([\n",
    "        (min(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096), MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_085_096[0]),\n",
    "        (MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Fitting_Bounds_085_096[1], max(MgII_ReStacked_Continuum_Scaled_Velocity_Shifted_085_096))]),\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "plt.xlim(-20000, 15000)  # Set your desired limits\n",
    "#plt.ylim(-0.5e-16, 1.25e-16)\n",
    "\n",
    "# Get current axes and set limits\n",
    "fig = plt.gcf()  # Get current figure\n",
    "axes = fig.get_axes()  # Get all axes\n",
    "\n",
    "axes[0].set_ylim(-0.5e-16, 1.5e-16)  # Set y-limits for first panel (adjust values as needed)\n",
    "axes[1].set_ylim(-0.3e-16, 0.3e-16)  # Set y-limits for second panel (adjust values as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2187d-0ed8-41ce-a517-c007a9773a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6d9c8-acb5-4b53-9b25-c1d84524b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the returns from the fit_MgII_Spectrum.\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Residuals_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['residuals']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_SD_025_035 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_025_035['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Residuals_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_SD_035_045 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_035_045['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Residuals_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_SD_045_055 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_045_055['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Residuals_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_SD_055_065 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_055_065['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Residuals_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_SD_065_075 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_065_075['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Residuals_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_SD_075_085 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_075_085['uncertainties']['g2_amplitude']\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['parameters']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['parameters']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['parameters']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['parameters']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['parameters']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['parameters']['g2_amplitude']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['fit']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Residuals_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['residuals']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Narrow_Gaussian_Velocity_FWHM_Min_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['components']['gaussian1']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_BestFit_Broad_Gaussian_Velocity_FWHM_Min_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['components']['gaussian2']\n",
    "\n",
    "\"\"\"\n",
    "Standard Deviations\n",
    "\"\"\"\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['uncertainties']['g1_center']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Center_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['uncertainties']['g2_center']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['uncertainties']['g1_sigma']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['uncertainties']['g2_sigma']\n",
    "\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['uncertainties']['g1_amplitude']\n",
    "MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Amplitude_SD_085_096 = MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_085_096['uncertainties']['g2_amplitude']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b630663-f13c-4982-98a0-e32df95047a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a432b-e4f1-4cb1-8416-b6d468c51230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the Narrow part of the MgII (This is not to actually be used. We want to use the broad component.)\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_025_035_Mean, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_025_035_Mean_SD = black_hole_mass(3000, L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_025_035, \n",
    "                                                                                                                                  L_3000_Mean_SD_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_035_045_Mean, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_035_045_Mean_SD = black_hole_mass(3000, L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_035_045, \n",
    "                                                                                                                                  L_3000_Mean_SD_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_045_055_Mean, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_045_055_Mean_SD = black_hole_mass(3000, L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_045_055, \n",
    "                                                                                                                                  L_3000_Mean_SD_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_055_065_Mean, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_055_065_Mean_SD = black_hole_mass(3000, L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_055_065, \n",
    "                                                                                                                                  L_3000_Mean_SD_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_065_075_Mean, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_065_075_Mean_SD = black_hole_mass(3000, L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_065_075,\n",
    "                                                                                                                                  L_3000_Mean_SD_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_075_085_Mean, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_075_085_Mean_SD = black_hole_mass(3000, L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_075_085, \n",
    "                                                                                                                                  L_3000_Mean_SD_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_085_096_Mean, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_085_096_Mean_SD = black_hole_mass(3000, L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_085_096, \n",
    "                                                                                                                                  L_3000_Mean_SD_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_085_096)\n",
    "\n",
    "print(L_3000_Mean_075_085, L_3000_Mean_SD_075_085, L_3000_Mean_SD_075_085/L_3000_Mean_075_085)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3be47-4af4-472a-b09e-a8073b99cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the Broad part of the MgII.\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_025_035_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_025_035_Mean_SD = black_hole_mass(3000, L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_025_035, \n",
    "                                                                                                                                L_3000_Mean_SD_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean_SD = black_hole_mass(3000, L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_035_045, \n",
    "                                                                                                                                L_3000_Mean_SD_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_045_055_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_045_055_Mean_SD = black_hole_mass(3000, L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_045_055, \n",
    "                                                                                                                                L_3000_Mean_SD_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_055_065_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_055_065_Mean_SD = black_hole_mass(3000, L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_055_065, \n",
    "                                                                                                                                L_3000_Mean_SD_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_065_075_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_065_075_Mean_SD = black_hole_mass(3000, L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_065_075, \n",
    "                                                                                                                                L_3000_Mean_SD_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_075_085_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_075_085_Mean_SD = black_hole_mass(3000, L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_075_085, \n",
    "                                                                                                                                L_3000_Mean_SD_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_085_096_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_085_096_Mean_SD = black_hole_mass(3000, L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_085_096, \n",
    "                                                                                                                                L_3000_Mean_SD_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_085_096)\n",
    "\n",
    "\n",
    "print(BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean_SD, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean_SD/BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean)\n",
    "print(\"\")\n",
    "print(L_3000_Mean_035_045, L_3000_Mean_SD_035_045, L_3000_Mean_SD_035_045/L_3000_Mean_035_045)\n",
    "print(\"\")\n",
    "print(MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_035_045/MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_035_045)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68334615-b101-419b-9200-716f2eb401e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting\n",
    "datasets = [\n",
    "    ('025_035', BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_025_035_Mean, \n",
    "     L_3000_Mean_025_035, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_025_035_Mean_SD, \n",
    "     L_3000_Mean_SD_025_035),\n",
    "    ('035_045', BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean,\n",
    "     L_3000_Mean_035_045, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_035_045_Mean_SD,\n",
    "     L_3000_Mean_SD_035_045),\n",
    "    ('045_055', BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_045_055_Mean,\n",
    "     L_3000_Mean_045_055, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_045_055_Mean_SD,\n",
    "     L_3000_Mean_SD_045_055),\n",
    "    ('055_065', BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_055_065_Mean,\n",
    "     L_3000_Mean_055_065, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_055_065_Mean_SD,\n",
    "     L_3000_Mean_SD_055_065),\n",
    "    ('065_075', BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_065_075_Mean,\n",
    "     L_3000_Mean_065_075, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_065_075_Mean_SD,\n",
    "     L_3000_Mean_SD_065_075),\n",
    "    ('075_085', BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_075_085_Mean,\n",
    "     L_3000_Mean_075_085, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_075_085_Mean_SD,\n",
    "     L_3000_Mean_SD_075_085),\n",
    "    ('085_096', BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_085_096_Mean,\n",
    "     L_3000_Mean_085_096, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_085_096_Mean_SD,\n",
    "     L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Fixed Narrow Component Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0cb5e-2472-4cf1-bc4a-b5492dd3e620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e362ed8-ba0d-45b1-aecb-1b0cd5be9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (using narrow component data)\n",
    "datasets = [\n",
    "    ('025_035', BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_025_035_Mean, \n",
    "     L_3000_Mean_025_035, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_025_035_Mean_SD, \n",
    "     L_3000_Mean_SD_025_035),\n",
    "    ('035_045', BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_035_045_Mean,\n",
    "     L_3000_Mean_035_045, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_035_045_Mean_SD,\n",
    "     L_3000_Mean_SD_035_045),\n",
    "    ('045_055', BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_045_055_Mean,\n",
    "     L_3000_Mean_045_055, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_045_055_Mean_SD,\n",
    "     L_3000_Mean_SD_045_055),\n",
    "    ('055_065', BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_055_065_Mean,\n",
    "     L_3000_Mean_055_065, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_055_065_Mean_SD,\n",
    "     L_3000_Mean_SD_055_065),\n",
    "    ('065_075', BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_065_075_Mean,\n",
    "     L_3000_Mean_065_075, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_065_075_Mean_SD,\n",
    "     L_3000_Mean_SD_065_075),\n",
    "    ('075_085', BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_075_085_Mean,\n",
    "     L_3000_Mean_075_085, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_075_085_Mean_SD,\n",
    "     L_3000_Mean_SD_075_085),\n",
    "    ('085_096', BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_085_096_Mean,\n",
    "     L_3000_Mean_085_096, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_085_096_Mean_SD,\n",
    "     L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Fixed Narrow Component Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99c03b-0f27-4b15-a1f9-2ff2a41fc8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e610ca5-9ed9-434c-9484-27e5680b432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (using broad component data)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_025_035, \n",
    "     L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_025_035, \n",
    "     L_3000_Mean_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_035_045,\n",
    "     L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_035_045,\n",
    "     L_3000_Mean_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_045_055,\n",
    "     L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_045_055,\n",
    "     L_3000_Mean_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_055_065,\n",
    "     L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_055_065,\n",
    "     L_3000_Mean_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_065_075,\n",
    "     L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_065_075,\n",
    "     L_3000_Mean_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_075_085,\n",
    "     L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_075_085,\n",
    "     L_3000_Mean_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_085_096,\n",
    "     L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_085_096,\n",
    "     L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Fixed Narrow Component Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Broad_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Broad_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22708788-7bb5-42fb-8d1c-54ff0cc05461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796fd37-933b-42c3-9a63-385925516e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (using narrow component data)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_025_035, \n",
    "     L_3000_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_025_035, \n",
    "     L_3000_Mean_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_035_045,\n",
    "     L_3000_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_035_045,\n",
    "     L_3000_Mean_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_045_055,\n",
    "     L_3000_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_045_055,\n",
    "     L_3000_Mean_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_055_065,\n",
    "     L_3000_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_055_065,\n",
    "     L_3000_Mean_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_065_075,\n",
    "     L_3000_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_065_075,\n",
    "     L_3000_Mean_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_075_085,\n",
    "     L_3000_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_075_085,\n",
    "     L_3000_Mean_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_085_096,\n",
    "     L_3000_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_085_096,\n",
    "     L_3000_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Fixed Narrow Component Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321b76f-cb28-4228-803a-35de33bacd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-values for each redshift bin (fixed positions)\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (redshift vs FWHM with fixed y-positions)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035, \n",
    "     0.3, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035, \n",
    "     None),  # No y-error for fixed positions\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045,\n",
    "     0.4, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045,\n",
    "     None),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055,\n",
    "     0.5, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055,\n",
    "     None),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065,\n",
    "     0.6, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065,\n",
    "     None),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075,\n",
    "     0.7, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075,\n",
    "     None),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085,\n",
    "     0.8, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085,\n",
    "     None),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096,\n",
    "     0.9, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096,\n",
    "     None)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (only x-direction since y-positions are fixed)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,  # Will be None\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Fixed Narrow Component Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Redshift_FWHM_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Redshift_FWHM_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0befe-f0d2-41b9-a8fc-b5cfce671032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-values for each redshift bin (fixed positions)\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (redshift vs FWHM with fixed y-positions)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035, \n",
    "     0.3, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035, \n",
    "     None),  # No y-error for fixed positions\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045,\n",
    "     0.4, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045,\n",
    "     None),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055,\n",
    "     0.5, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055,\n",
    "     None),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065,\n",
    "     0.6, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065,\n",
    "     None),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075,\n",
    "     0.7, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075,\n",
    "     None),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085,\n",
    "     0.8, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085,\n",
    "     None),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096,\n",
    "     0.9, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096,\n",
    "     None)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (only x-direction since y-positions are fixed)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,  # Will be None\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Fixed Narrow Component Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e301f-bfb1-47fa-ae3c-2b57781717e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed2d23-150b-407a-ac1f-5712242fab9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47c7fb6c-7eaf-40b3-8d5c-eeb5f21d16c4",
   "metadata": {},
   "source": [
    "## <font color='#00879E' size=5 >Taking out the increasing luminosity problem - </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad4e9d-3e89-41c3-9907-e7ca44860c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823447d7-bf29-44ec-9347-c5ec28cbb7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd29fd-9eb8-406a-955d-876e2f329b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fca9a2-c9ad-450e-882b-d681cdb15955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241cfa7-2409-4b55-94c3-c247f7181f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241455c-ffc3-40be-a4ac-e6b5f06a1360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf03eb-3922-4db3-bf56-32b320ef42e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebaeb9-ad38-407b-9f94-24e5ab072aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f8cfa-6be6-4a13-b0ae-c336f43151d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_the_average_luminosity_for_each_AGN(l_3000, l_sd_3000):\n",
    "    \"\"\"\n",
    "    Calculate simple mean and its standard deviation using error propagation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    values : array-like\n",
    "        Array of measurement values.\n",
    "    std_values : array-like\n",
    "        Array of standard deviations for each measurement value.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mean_value : float\n",
    "        Simple mean of the input values.\n",
    "    mean_std : float\n",
    "        Standard deviation of the mean.\n",
    "    \"\"\"\n",
    "    # The Arrays\n",
    "    mean_value_array = []\n",
    "    mean_std_array = []\n",
    "    \n",
    "    # Convert inputs to numpy arrays if they aren't already\n",
    "    l_3000 = np.array(l_3000)\n",
    "\n",
    "    for i in range(len(l_3000)):\n",
    "        values = np.array(l_3000[i])\n",
    "        std_values = np.array(l_sd_3000[i])\n",
    "        \n",
    "        # Calculate simple mean\n",
    "        mean_value_array.append(np.mean(values))\n",
    "        \n",
    "        # Calculate standard deviation of the mean using error propagation\n",
    "        # For a sum of variables, the variances add\n",
    "        # For a mean (sum divided by n), we divide the total variance by n²\n",
    "        n = len(values)\n",
    "        mean_std_array.append(np.std(values, ddof=1))\n",
    "        \n",
    "        # Alternative: standard error of the mean if your std_values are not measurement errors\n",
    "        # but rather standard deviations of the sample\n",
    "        # mean_std_alt = np.std(values, ddof=1) / np.sqrt(n)\n",
    "    \n",
    "    return mean_value_array, mean_std_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741dc2f-dd6a-4fcd-aa46-bc96bd9d6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the array of luminosities at 3000 angstroms for the redshift range of 0.85 to 0.96.\n",
    "This isn't the same as the other redshfits because this redshift range doesn't go up to 3000 angstroms. \n",
    "So it has to be calculated through the ratio of the 3000 to 2000 wavelengths of the other redshift ranges.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Using the ratio of the 3000 to 2000 relationship to get the continuum luminosities at 3000 angstroms for the AGN that don't have 3000 angstrom wavelengths.\n",
    "\"\"\"\n",
    "#L_3000_Mean_085_096 = np.multiply(R_3000_2000_Mean, L_2000_Mean_085_096)\n",
    "#L_3000_Mean_SD_085_096 = abs(L_3000_Mean_085_096) * np.sqrt( np.divide(R_3000_2000_SD_Array, R_3000_2000_Array)**2 + np.divide(L_2000_Mean_SD_085_096, L_2000_Mean_085_096)**2)\n",
    "\n",
    "#print(len(R_3000_2000_SD_Array), len(R_3000_2000_Array), L_2000_Mean_SD_085_096, L_2000_Mean_085_096)\n",
    "#print(len(np.divide(R_3000_2000_SD_Array, R_3000_2000_Array)))\n",
    "#print(np.divide(L_2000_Mean_SD_085_096, L_2000_Mean_085_096))\n",
    "#print(len(np.divide(L_2000_SD_085_096, L_2000_085_096)))\n",
    "#print(np.divide(L_2000_SD_085_096, L_2000_085_096))\n",
    "#print(np.ndim((np.divide(L_2000_SD_085_096, L_2000_085_096))))\n",
    "#print(np.ndim(L_2000_SD_085_096))\n",
    "#print(L_2000_SD_085_096[0])\n",
    "#print(np.ndim(L_3000_SD_075_085[0]))\n",
    "\n",
    "\n",
    "def calculate_product_std_deviations(single_value, std_dev_single, array_values, array_std_devs):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviations for products of a single value with an array of values,\n",
    "    given the standard deviation of the single value and an array of standard deviations.\n",
    "    \n",
    "    For multiplication of independent random variables, error propagation follows:\n",
    "    If Z = X * Y, then:\n",
    "    (σZ/Z)² = (σX/X)² + (σY/Y)²\n",
    "    \n",
    "    So σZ = Z * sqrt((σX/X)² + (σY/Y)²)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    single_value : float\n",
    "        The single value being multiplied with each array element\n",
    "    std_dev_single : float\n",
    "        The standard deviation of the single value\n",
    "    array_values : list or numpy array\n",
    "        The array of values to multiply with the single value\n",
    "    array_std_devs : list or numpy array\n",
    "        The array of standard deviations for each value in array_values\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (result_values, result_std_devs) - The products and their standard deviations\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    array_values = np.array(array_values)\n",
    "    array_std_devs = np.array(array_std_devs)\n",
    "    \n",
    "    # Calculate the products\n",
    "    products = single_value * array_values\n",
    "    \n",
    "    # Calculate the relative errors squared\n",
    "    if single_value != 0:\n",
    "        rel_err_single_squared = (std_dev_single / single_value) ** 2\n",
    "    else:\n",
    "        rel_err_single_squared = 0\n",
    "    \n",
    "    # Handle potential zeros in array_values\n",
    "    rel_err_array_squared = np.zeros_like(array_values, dtype=float)\n",
    "    non_zero_mask = (array_values != 0)\n",
    "    rel_err_array_squared[non_zero_mask] = (array_std_devs[non_zero_mask] / array_values[non_zero_mask]) ** 2\n",
    "    \n",
    "    # Calculate product standard deviations using error propagation\n",
    "    product_std_devs = np.abs(products) * np.sqrt(rel_err_single_squared + rel_err_array_squared)\n",
    "    \n",
    "    return products, product_std_devs\n",
    "\n",
    "L_3000_085_096, L_3000_SD_085_096 = calculate_product_std_deviations(R_3000_2000_Mean, R_3000_2000_Mean_SD, L_2000_085_096, L_2000_SD_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d4e0a-149a-441f-87e8-b577fe442189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting the arrays of average luminosity for each of the AGN in each of the redshift bins.\n",
    "\"\"\"\n",
    "Luminosity_Average_From_Each_AGN_025_035, Luminosity_Average_SD_From_Each_AGN_025_035 = getting_the_average_luminosity_for_each_AGN(L_3000_025_035, L_3000_SD_025_035)\n",
    "Luminosity_Average_From_Each_AGN_035_045, Luminosity_Average_SD_From_Each_AGN_035_045 = getting_the_average_luminosity_for_each_AGN(L_3000_035_045, L_3000_SD_035_045)\n",
    "Luminosity_Average_From_Each_AGN_045_055, Luminosity_Average_SD_From_Each_AGN_045_055 = getting_the_average_luminosity_for_each_AGN(L_3000_045_055, L_3000_SD_045_055)\n",
    "Luminosity_Average_From_Each_AGN_055_065, Luminosity_Average_SD_From_Each_AGN_055_065 = getting_the_average_luminosity_for_each_AGN(L_3000_055_065, L_3000_SD_055_065)\n",
    "Luminosity_Average_From_Each_AGN_065_075, Luminosity_Average_SD_From_Each_AGN_065_075 = getting_the_average_luminosity_for_each_AGN(L_3000_065_075, L_3000_SD_065_075)\n",
    "Luminosity_Average_From_Each_AGN_075_085, Luminosity_Average_SD_From_Each_AGN_075_085 = getting_the_average_luminosity_for_each_AGN(L_3000_075_085, L_3000_SD_075_085)\n",
    "Luminosity_Average_From_Each_AGN_085_096, Luminosity_Average_SD_From_Each_AGN_085_096 = getting_the_average_luminosity_for_each_AGN(L_3000_085_096, L_3000_SD_085_096)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9feae-1448-4fda-94fa-e214f3b32742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L_3000_025_035[10][10], L_3000_SD_025_035[10][10], L_3000_SD_025_035[10][10]/L_3000_025_035[10][10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b6541-24d2-4862-8890-070abcd79b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Luminosity_Average_From_Each_AGN_025_035[10], Luminosity_Average_SD_From_Each_AGN_025_035[10], Luminosity_Average_SD_From_Each_AGN_025_035[10]/Luminosity_Average_From_Each_AGN_025_035[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bebef78-decd-4421-b9db-c974532aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining the fixed redshift arrays (fixing_the_redshift_arrays).\n",
    "\"\"\"\n",
    "Fixed_Z_Array = np.concatenate((Fixed_Z_025_035, Fixed_Z_035_045, Fixed_Z_045_055, Fixed_Z_055_065, Fixed_Z_065_075, Fixed_Z_075_085, Fixed_Z_085_096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32cb73-b2d0-4ab1-815c-9dbb290504d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making an array of all the Luminosity_Average_From_Each_AGN (getting_the_average_luminosity_for_each_AGN).\n",
    "\"\"\"\n",
    "Luminosity_3000_Array = np.concatenate((Luminosity_Average_From_Each_AGN_025_035, Luminosity_Average_From_Each_AGN_035_045, Luminosity_Average_From_Each_AGN_045_055, \n",
    "                                        Luminosity_Average_From_Each_AGN_055_065, Luminosity_Average_From_Each_AGN_065_075, \n",
    "                                        Luminosity_Average_From_Each_AGN_075_085, Luminosity_Average_From_Each_AGN_085_096))\n",
    "\n",
    "Luminosity_3000_SD_Array = np.concatenate((Luminosity_Average_SD_From_Each_AGN_025_035, Luminosity_Average_SD_From_Each_AGN_035_045, \n",
    "                                        Luminosity_Average_SD_From_Each_AGN_045_055, Luminosity_Average_SD_From_Each_AGN_055_065, Luminosity_Average_SD_From_Each_AGN_065_075, \n",
    "                                        Luminosity_Average_SD_From_Each_AGN_075_085, Luminosity_Average_SD_From_Each_AGN_085_096))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3627b3-d75b-4dfb-b5ce-b245fef373e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminosity_evolution_correction(luminosities, luminosities_SD, redshifts, ref_z=0.25, evolution_model='power_law', plot_results=True, n_bins=7):\n",
    "    \"\"\"\n",
    "    Apply luminosity evolution correction to AGN luminosity data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    luminosities : array-like\n",
    "        Original luminosity values\n",
    "    luminosities_SD : array-like\n",
    "        Standard deviations of original luminosities\n",
    "    redshifts : array-like\n",
    "        Redshift values\n",
    "    ref_z : float, default=0.25\n",
    "        Reference redshift for correction\n",
    "    evolution_model : str, default='power_law'\n",
    "        Evolution model ('power_law', 'exponential', 'linear')\n",
    "    plot_results : bool, default=True\n",
    "        Whether to create plots\n",
    "    n_bins : int, default=10\n",
    "        Number of redshift bins for binned output\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    corrected_luminosities : array\n",
    "        Luminosity values corrected for evolution\n",
    "    corrected_luminosities_SD : array\n",
    "        Standard deviations of corrected luminosities (properly propagated)\n",
    "    correction_params : dict\n",
    "        Parameters of the fitted evolution model\n",
    "    binned_results : dict\n",
    "        Dictionary containing binned corrected luminosities and their SDs\n",
    "    \"\"\"\n",
    "\n",
    "    luminosities = np.asarray(luminosities)\n",
    "    redshifts = np.asarray(redshifts)\n",
    "    luminosities_SD = np.asarray(luminosities_SD)\n",
    "\n",
    "    # Define evolution models\n",
    "    def power_law(z, alpha):\n",
    "        return (1 + z)**alpha\n",
    "    \n",
    "    def exponential(z, k):\n",
    "        return np.exp(k * z)\n",
    "    \n",
    "    def linear(z, m):\n",
    "        return 1 + m * z\n",
    "    \n",
    "    # Take natural log of luminosities for fitting\n",
    "    log_luminosities = np.log(luminosities)\n",
    "    \n",
    "    # Choose evolution model and fit\n",
    "    if evolution_model == 'power_law':\n",
    "        X = np.log(1 + redshifts).reshape(-1, 1)\n",
    "        model = stats.linregress(X.flatten(), log_luminosities)\n",
    "        alpha = model.slope\n",
    "        intercept = model.intercept\n",
    "        evolution_func = power_law\n",
    "        params = [alpha]\n",
    "        correction_params = {'model': 'power_law', 'alpha': alpha}\n",
    "    \n",
    "    elif evolution_model == 'exponential':\n",
    "        X = redshifts.reshape(-1, 1)\n",
    "        model = stats.linregress(X.flatten(), log_luminosities)\n",
    "        k = model.slope\n",
    "        intercept = model.intercept\n",
    "        evolution_func = exponential\n",
    "        params = [k]\n",
    "        correction_params = {'model': 'exponential', 'k': k}\n",
    "    \n",
    "    elif evolution_model == 'linear':\n",
    "        def linear_fit_func(z, log_L0, m):\n",
    "            return log_L0 + np.log(1 + m * z)\n",
    "        \n",
    "        popt, _ = curve_fit(linear_fit_func, redshifts, log_luminosities)\n",
    "        log_L0, m = popt\n",
    "        intercept = log_L0\n",
    "        evolution_func = linear\n",
    "        params = [m]\n",
    "        correction_params = {'model': 'linear', 'm': m}\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Evolution model must be 'power_law', 'exponential', or 'linear'\")\n",
    "    \n",
    "    # Calculate correction factors\n",
    "    correction_factors = evolution_func(redshifts, *params) / evolution_func(ref_z, *params)\n",
    "    \n",
    "    # Apply correction to normalize to reference redshift\n",
    "    corrected_luminosities = luminosities / correction_factors\n",
    "\n",
    "    # Propagate uncertainty: corrected_SD = original_SD / correction_factor\n",
    "    corrected_luminosities_SD = luminosities_SD / correction_factors\n",
    "\n",
    "    # Create redshift bins for binned output\n",
    "    z_bins = np.linspace(np.min(redshifts), np.max(redshifts), n_bins + 1)\n",
    "    z_bin_centers = (z_bins[:-1] + z_bins[1:]) / 2\n",
    "    digitized_bins = np.digitize(redshifts, z_bins)\n",
    "    \n",
    "    # Organize corrected data by redshift bins\n",
    "    binned_corrected_luminosities = []\n",
    "    binned_corrected_luminosities_SD = []\n",
    "    binned_corrected_luminosities_scatter = []  # Added for actual scatter\n",
    "    bin_info = []\n",
    "    \n",
    "    for i in range(1, len(z_bins)):\n",
    "        bin_mask = digitized_bins == i\n",
    "        if np.sum(bin_mask) > 0:\n",
    "            bin_corrected_lum = corrected_luminosities[bin_mask]\n",
    "            bin_corrected_lum_SD = corrected_luminosities_SD[bin_mask]\n",
    "            \n",
    "            # Calculate the actual scatter of luminosity values in this bin\n",
    "            bin_scatter = np.std(bin_corrected_lum) if len(bin_corrected_lum) > 1 else 0.0\n",
    "            \n",
    "            binned_corrected_luminosities.append(bin_corrected_lum)\n",
    "            binned_corrected_luminosities_SD.append(bin_corrected_lum_SD)\n",
    "            binned_corrected_luminosities_scatter.append(bin_scatter)\n",
    "            \n",
    "            bin_info.append({\n",
    "                'bin_index': i-1,\n",
    "                'z_center': z_bin_centers[i-1],\n",
    "                'z_range': (z_bins[i-1], z_bins[i]),\n",
    "                'n_objects': len(bin_corrected_lum),\n",
    "                'redshifts': redshifts[bin_mask],\n",
    "                'mean_luminosity': np.mean(bin_corrected_lum),\n",
    "                'luminosity_scatter': bin_scatter,\n",
    "                'mean_measurement_error': np.mean(bin_corrected_lum_SD)\n",
    "            })\n",
    "    \n",
    "    # Create binned results dictionary\n",
    "    binned_results = {\n",
    "        'corrected_luminosities_by_bin': binned_corrected_luminosities,\n",
    "        'corrected_luminosities_SD_by_bin': binned_corrected_luminosities_SD,\n",
    "        'corrected_luminosities_scatter_by_bin': binned_corrected_luminosities_scatter,  # Added\n",
    "        'bin_info': bin_info,\n",
    "        'z_bins': z_bins,\n",
    "        'z_bin_centers': z_bin_centers\n",
    "    }\n",
    "\n",
    "    if plot_results:\n",
    "        # Color scheme\n",
    "        purple = \"#a714ff\"\n",
    "        pink = \"#ff14f5\"\n",
    "        teal = \"#14D8FF\"\n",
    "        main_blue = \"#60B5FF\"\n",
    "        green = \"#00FF9C\"\n",
    "        orange = \"#ffbb14\"\n",
    "        red = \"#FF5757\"\n",
    "        \n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "        plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        z_bins_for_errors = np.linspace(min(redshifts), max(redshifts), 10)\n",
    "        digitized = np.digitize(redshifts, z_bins_for_errors)\n",
    "        \n",
    "        z_bin_centers = []\n",
    "        orig_lum_means = []\n",
    "        orig_lum_stds = []\n",
    "        corr_lum_means = []\n",
    "        corr_lum_stds = []\n",
    "        \n",
    "        for i in range(1, len(z_bins_for_errors)):\n",
    "            bin_mask = digitized == i\n",
    "            if np.sum(bin_mask) > 1:\n",
    "                z_bin_centers.append((z_bins_for_errors[i-1] + z_bins_for_errors[i]) / 2)\n",
    "                orig_lum_means.append(np.mean(luminosities[bin_mask]))\n",
    "                # Fixed: Use actual scatter of luminosity values, not measurement errors\n",
    "                orig_lum_stds.append(np.std(luminosities[bin_mask]))\n",
    "                corr_lum_means.append(np.mean(corrected_luminosities[bin_mask]))\n",
    "                corr_lum_stds.append(np.std(corrected_luminosities[bin_mask]))\n",
    "\n",
    "        axs[0].scatter(redshifts, luminosities, marker='o', alpha=0.5, color=main_blue, s=30, zorder=3)\n",
    "        axs[0].errorbar(redshifts, luminosities, yerr=luminosities_SD, linestyle='', ecolor=\"black\", capsize=5, capthick=2, zorder=0)\n",
    "        axs[0].set_xlabel('Redshift (z)', fontsize=12)\n",
    "        axs[0].set_ylabel('Original Luminosity', fontsize=12)\n",
    "        axs[0].set_title('Original Luminosity vs Redshift', fontsize=12)\n",
    "        axs[0].set_yscale('log')\n",
    "        axs[0].grid(True, alpha=0.3, zorder=0)\n",
    "        axs[0].spines['top'].set_linewidth(1.5)\n",
    "        axs[0].spines['right'].set_linewidth(1.5)\n",
    "        axs[0].spines['left'].set_linewidth(1.5)\n",
    "        axs[0].spines['bottom'].set_linewidth(1.5)\n",
    "        axs[0].tick_params(axis='both', which='major', width=1.5, length=5, labelsize=10)\n",
    "        axs[0].tick_params(axis='both', which='minor', width=1, length=3, labelsize=8)\n",
    "        \n",
    "        axs[1].scatter(redshifts, corrected_luminosities, alpha=0.5, color=green, s=30, zorder=3)\n",
    "        axs[1].errorbar(redshifts, corrected_luminosities, yerr=corrected_luminosities_SD, linestyle='', ecolor=\"black\", capsize=5, capthick=2, zorder=0)\n",
    "        axs[1].set_xlabel('Redshift (z)', fontsize=12)\n",
    "        axs[1].set_ylabel('Corrected Luminosity', fontsize=12)\n",
    "        axs[1].set_title(f'Corrected Luminosity vs Redshift (ref z={ref_z})', fontsize=12)\n",
    "        axs[1].set_yscale('log')\n",
    "        axs[1].grid(True, alpha=0.3, zorder=0)\n",
    "        axs[1].spines['top'].set_linewidth(1.5)\n",
    "        axs[1].spines['right'].set_linewidth(1.5)\n",
    "        axs[1].spines['left'].set_linewidth(1.5)\n",
    "        axs[1].spines['bottom'].set_linewidth(1.5)\n",
    "        axs[1].tick_params(axis='both', which='major', width=1.5, length=5, labelsize=10)\n",
    "        axs[1].tick_params(axis='both', which='minor', width=1, length=3, labelsize=8)\n",
    "        \n",
    "        axs[2].hist(np.log10(luminosities), bins=15, alpha=0.5, label='Original', color=purple)\n",
    "        axs[2].hist(np.log10(corrected_luminosities), bins=15, alpha=0.5, label='Corrected', color=teal)\n",
    "        axs[2].set_xlabel('Log Luminosity', fontsize=12)\n",
    "        axs[2].set_ylabel('Number', fontsize=12)\n",
    "        axs[2].set_title('Luminosity Distribution', fontsize=12)\n",
    "        axs[2].legend(\n",
    "            loc='upper right', \n",
    "            fontsize=9, \n",
    "            frameon=True, \n",
    "            fancybox=True, \n",
    "            shadow=True, \n",
    "            borderpad=0.8, \n",
    "            edgecolor='black', \n",
    "            facecolor='white', \n",
    "            handlelength=2.5,\n",
    "            columnspacing=1.5,\n",
    "            labelspacing=1.5\n",
    "        )\n",
    "        axs[2].grid(True, alpha=0.3, zorder=0)\n",
    "        axs[2].spines['top'].set_linewidth(1.5)\n",
    "        axs[2].spines['right'].set_linewidth(1.5)\n",
    "        axs[2].spines['left'].set_linewidth(1.5)\n",
    "        axs[2].spines['bottom'].set_linewidth(1.5)\n",
    "        axs[2].tick_params(axis='both', which='major', width=1.5, length=5, labelsize=10)\n",
    "        axs[2].tick_params(axis='both', which='minor', width=1, length=3, labelsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return corrected_luminosities, corrected_luminosities_SD, correction_params, binned_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Corrected_Luminosities, Corrected_Luminosities_SD, Correction_Params, Corrected_Luminosities_Binned_Data = luminosity_evolution_correction(Luminosity_3000_Array, Luminosity_3000_SD_Array, Fixed_Z_Array, ref_z=0.25, evolution_model='power_law', n_bins=7)\n",
    "\n",
    "# Analyze results\n",
    "analysis = analyze_correction_results(Luminosity_3000_Array, Corrected_Luminosities, Fixed_Z_Array, n_bins=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c800ed-1bd2-44df-a66d-7c0f2295c3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b60fd-39cc-40a1-a03e-36cba2a798ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923c9cd-6f16-4715-be23-b92ef9818557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8c994-f96f-495b-9838-a758fee35d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0fd786-bae6-4d45-a138-a7831c0f5de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c86e7e-92ef-4610-a0bd-d8b2c87fb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Luminosity_3000_Array[100], Luminosity_3000_SD_Array[100], Luminosity_3000_SD_Array[100]/Luminosity_3000_Array[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a31894-f3da-410a-9fb6-abdec18c424b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c9f3d-3470-4a1c-afe2-b29b429f3c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a5251-5b22-4e8d-856a-87333a6c34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corrected_Luminosities_Binned_Data_025_035 = Corrected_Luminosities_Binned_Data['corrected_luminosities_by_bin'][0]\n",
    "Corrected_Luminosities_Binned_Data_035_045 = Corrected_Luminosities_Binned_Data['corrected_luminosities_by_bin'][1]\n",
    "Corrected_Luminosities_Binned_Data_045_055 = Corrected_Luminosities_Binned_Data['corrected_luminosities_by_bin'][2]\n",
    "Corrected_Luminosities_Binned_Data_055_065 = Corrected_Luminosities_Binned_Data['corrected_luminosities_by_bin'][3]\n",
    "Corrected_Luminosities_Binned_Data_065_075 = Corrected_Luminosities_Binned_Data['corrected_luminosities_by_bin'][4]\n",
    "Corrected_Luminosities_Binned_Data_075_085 = Corrected_Luminosities_Binned_Data['corrected_luminosities_by_bin'][5]\n",
    "Corrected_Luminosities_Binned_Data_085_096 = Corrected_Luminosities_Binned_Data['corrected_luminosities_by_bin'][6]\n",
    "\n",
    "\n",
    "Corrected_Luminosities_Binned_Data_SD_025_035 = Corrected_Luminosities_Binned_Data['corrected_luminosities_SD_by_bin'][0]\n",
    "Corrected_Luminosities_Binned_Data_SD_035_045 = Corrected_Luminosities_Binned_Data['corrected_luminosities_SD_by_bin'][1]\n",
    "Corrected_Luminosities_Binned_Data_SD_045_055 = Corrected_Luminosities_Binned_Data['corrected_luminosities_SD_by_bin'][2]\n",
    "Corrected_Luminosities_Binned_Data_SD_055_065 = Corrected_Luminosities_Binned_Data['corrected_luminosities_SD_by_bin'][3]\n",
    "Corrected_Luminosities_Binned_Data_SD_065_075 = Corrected_Luminosities_Binned_Data['corrected_luminosities_SD_by_bin'][4]\n",
    "Corrected_Luminosities_Binned_Data_SD_075_085 = Corrected_Luminosities_Binned_Data['corrected_luminosities_SD_by_bin'][5]\n",
    "Corrected_Luminosities_Binned_Data_SD_085_096 = Corrected_Luminosities_Binned_Data['corrected_luminosities_SD_by_bin'][6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b9ecd-fc09-4a72-9c78-56da093fff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now with the corrected luminosities I want to recalculate the mean luminosity in each redshift bin.\n",
    "\"\"\"\n",
    "Luminosities_Binned_Data_Mean_025_035, Luminosities_Binned_Data_Mean_SD_025_035 = calculate_simple_mean_with_std(Corrected_Luminosities_Binned_Data_025_035, Corrected_Luminosities_Binned_Data_SD_025_035)\n",
    "Luminosities_Binned_Data_Mean_035_045, Luminosities_Binned_Data_Mean_SD_035_045 = calculate_simple_mean_with_std(Corrected_Luminosities_Binned_Data_035_045, Corrected_Luminosities_Binned_Data_SD_035_045)\n",
    "Luminosities_Binned_Data_Mean_045_055, Luminosities_Binned_Data_Mean_SD_045_055 = calculate_simple_mean_with_std(Corrected_Luminosities_Binned_Data_045_055, Corrected_Luminosities_Binned_Data_SD_045_055)\n",
    "Luminosities_Binned_Data_Mean_055_065, Luminosities_Binned_Data_Mean_SD_055_065 = calculate_simple_mean_with_std(Corrected_Luminosities_Binned_Data_055_065, Corrected_Luminosities_Binned_Data_SD_055_065)\n",
    "Luminosities_Binned_Data_Mean_065_075, Luminosities_Binned_Data_Mean_SD_065_075 = calculate_simple_mean_with_std(Corrected_Luminosities_Binned_Data_065_075, Corrected_Luminosities_Binned_Data_SD_065_075)\n",
    "Luminosities_Binned_Data_Mean_075_085, Luminosities_Binned_Data_Mean_SD_075_085 = calculate_simple_mean_with_std(Corrected_Luminosities_Binned_Data_075_085, Corrected_Luminosities_Binned_Data_SD_075_085)\n",
    "Luminosities_Binned_Data_Mean_085_096, Luminosities_Binned_Data_Mean_SD_085_096 = calculate_simple_mean_with_std(Corrected_Luminosities_Binned_Data_085_096, Corrected_Luminosities_Binned_Data_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8edb65-b978-49ce-8407-e61fdfd9ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Corrected_Luminosities_Binned_Data_025_035, Corrected_Luminosities_Binned_Data_SD_025_035, \n",
    "      Corrected_Luminosities_Binned_Data_SD_025_035/Corrected_Luminosities_Binned_Data_025_035\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ed10c-f1e4-4f3b-ba65-f62e8f06a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recalculating the black hole masses from the corrected luminosities. \n",
    "This one it for the two gaussian measurement without any restrictions. (example of restrictions: PSF limited or uniform narrow.)\n",
    "\n",
    "For the Narrow part of the MgII (This is not to actually be used. We want to use the broad component.)\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_025_035, BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_025_035 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_035_045, BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_035_045 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_045_055, BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_045_055 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_055_065, BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_055_065 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_065_075, BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_065_075 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_075_085, BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_075_085 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_085_096, BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_085_096 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98921d-8352-4435-905a-7785bd405bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recalculating the black hole masses from the corrected luminosities. \n",
    "This one it for the two gaussian measurement without any restrictions. (example of restrictions: PSF limited or uniform narrow.)\n",
    "\n",
    "For the Broad part of the MgII.\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "\n",
    "BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_025_035, BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_025_035 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_025_035, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_035_045, BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_035_045 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_035_045, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_045_055, BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_045_055 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_045_055, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_055_065, BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_055_065 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_055_065, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_065_075, BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_065_075 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_065_075, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_075_085, BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_075_085 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_075_085, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_085_096, BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_085_096 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096, \n",
    "                                                                                                                                  Luminosities_Binned_Data_Mean_SD_085_096, MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b3bf6-4a95-4989-8c79-9dfdd78ef57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69bbd3-d4fa-43b8-a5b0-d29b2752f10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2dcf09-ea35-4341-a7e0-267271fd53fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b61ce0-a725-4933-818e-86767e97b3c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9327b-0fd9-41c6-92d8-0a10d2bc37f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab1ad9-7db5-43e7-964f-3f9ff616ad61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7d402-898d-4a59-b0f5-44677bfbf513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435628c-294e-4071-b514-ff8512a7faaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccc1d3-9f84-4673-8d45-e2313c93c1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1998f8-0538-4d63-8386-1e04957fd3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3c825-19a9-4c74-a656-1d2b683190db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dac0cb-459e-4df7-92dd-b5c360c26c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (Black Hole Mass vs Luminosity)\n",
    "datasets = [\n",
    "    ('025_035', BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     BH_Mass_Broad_MgII_Luminosity_Corrected_Mean_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Luminosity_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Luminosity_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f054a-fba6-4771-82cc-5c3bedc08d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f31ff-ca2d-4148-b86b-a3c14c845e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (Black Hole Mass Narrow vs Luminosity)\n",
    "datasets = [\n",
    "    ('025_035', BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     BH_Mass_Narrow_MgII_Luminosity_Corrected_Mean_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_Luminosity_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_Luminosity_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a997850d-076a-40e6-bbda-78c2c7649557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258cb01-0c1a-4875-8ebb-f789511b9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Luminosity)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Broad_FWHM_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Broad_FWHM_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba075be0-b22c-48ab-a6dd-0fe59e6d7580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00bcff-4e22-4657-9288-20b497d95cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (Narrow FWHM vs Luminosity)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_FWHM_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_FWHM_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d04d3a2-e7f3-4a52-8e3c-d4213821f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Redshift bin centers for y-axis positioning\n",
    "redshift_centers = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Redshift)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035,\n",
    "     redshift_centers[0],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045,\n",
    "     redshift_centers[1],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055,\n",
    "     redshift_centers[2],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065,\n",
    "     redshift_centers[3],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075,\n",
    "     redshift_centers[4],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085,\n",
    "     redshift_centers[5],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096,\n",
    "     redshift_centers[6],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (x direction only, no y error bars)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Redshift Evolution of FWHM - Broad Component\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Redshift_FWHM_Evolution_Broad_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Redshift_FWHM_Evolution_Broad_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3580696-35e5-4624-bf7d-4233c758118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Redshift bin centers for y-axis positioning\n",
    "redshift_centers = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Redshift for Narrow component)\n",
    "datasets = [\n",
    "    ('025_035', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035,\n",
    "     redshift_centers[0],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035),\n",
    "    ('035_045', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045,\n",
    "     redshift_centers[1],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045),\n",
    "    ('045_055', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055,\n",
    "     redshift_centers[2],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055),\n",
    "    ('055_065', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065,\n",
    "     redshift_centers[3],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065),\n",
    "    ('065_075', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075,\n",
    "     redshift_centers[4],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075),\n",
    "    ('075_085', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085,\n",
    "     redshift_centers[5],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085),\n",
    "    ('085_096', MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096,\n",
    "     redshift_centers[6],\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (x direction only, no y error bars)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d777312-86a8-42eb-80db-63e86cb41cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238c1c3-bfc6-43a5-97cb-64f52ecc73d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c500403-6151-4da6-a4f2-995d30458437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9619b-b7a1-405c-b2ba-d96eefa2d8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49674e-dff1-4df2-adb3-5be4ac08cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recalculating the black hole masses from the corrected luminosities. \n",
    "This one it for the two gaussian measurement with a PSF limit.\n",
    "\n",
    "For the Narrow part of the MgII (This is not to actually be used. We want to use the broad component.)\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_025_035, BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_025_035 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_025_035, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_025_035, \n",
    "                                                                                                                                                    Luminosities_Binned_Data_Mean_SD_025_035, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_035_045, BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_035_045 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_035_045, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_035_045, \n",
    "                                                                                                                                                    Luminosities_Binned_Data_Mean_SD_035_045, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_045_055, BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_045_055 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_045_055, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_045_055, \n",
    "                                                                                                                                                    Luminosities_Binned_Data_Mean_SD_045_055, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_055_065, BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_055_065 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_055_065, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_055_065, \n",
    "                                                                                                                                                    Luminosities_Binned_Data_Mean_SD_055_065, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_065_075, BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_065_075 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_065_075, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_065_075, \n",
    "                                                                                                                                                    Luminosities_Binned_Data_Mean_SD_065_075, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_075_085, BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_075_085 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_075_085, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_075_085, \n",
    "                                                                                                                                                    Luminosities_Binned_Data_Mean_SD_075_085, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_085_096, BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_085_096 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_085_096, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_085_096, \n",
    "                                                                                                                                                    Luminosities_Binned_Data_Mean_SD_085_096, \n",
    "                                                                                                                                                    MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0c1dd-ac59-4e4e-896b-3b434eb6f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recalculating the black hole masses from the corrected luminosities. \n",
    "This one it for the two gaussian measurement with a PSF limit.\n",
    "\n",
    "For the Broad part of the MgII.\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_025_035, BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_025_035 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_025_035, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_025_035, \n",
    "                                                                                                                                                  Luminosities_Binned_Data_Mean_SD_025_035, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_035_045, BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_035_045 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_035_045, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_035_045, \n",
    "                                                                                                                                                  Luminosities_Binned_Data_Mean_SD_035_045, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_045_055, BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_045_055 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_045_055, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_045_055, \n",
    "                                                                                                                                                  Luminosities_Binned_Data_Mean_SD_045_055, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_055_065, BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_055_065 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_055_065, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_055_065, \n",
    "                                                                                                                                                  Luminosities_Binned_Data_Mean_SD_055_065, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_065_075, BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_065_075 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_065_075, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_065_075, \n",
    "                                                                                                                                                  Luminosities_Binned_Data_Mean_SD_065_075, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_075_085, BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_075_085 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_075_085, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_075_085, \n",
    "                                                                                                                                                  Luminosities_Binned_Data_Mean_SD_075_085, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_085_096, BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_085_096 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_085_096, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_085_096, \n",
    "                                                                                                                                                  Luminosities_Binned_Data_Mean_SD_085_096, \n",
    "                                                                                                                                                  MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_085_096)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a9fce-0bd3-413c-b1d8-ca0e7d0bd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (Black Hole Mass vs Luminosity)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     BH_Mass_Broad_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected PSF Limited Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin/1.05, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_BlackHole_Mass_Luminosity_Broad_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_BlackHole_Mass_Luminosity_Broad_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbe982-79c2-450f-90ae-cf352164b116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9ba88-b318-49a2-93b9-9a9e6009bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (Black Hole Mass vs Luminosity - Narrow Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     BH_Mass_Narrow_MgII_FWHM_Min_Luminosity_Corrected_Mean_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected PSF Limited Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin/1.05, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_BlackHole_Mass_Luminosity_Narrow_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_BlackHole_Mass_Luminosity_Narrow_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935206b-6d0a-4c51-ad7e-acabd41f5e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4d679-5063-4eb3-8333-45d79afdb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Luminosity - Broad Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Broad_Sigma_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected PSF Limited Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin/1.05, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce5d5c-cfd2-4230-b197-a65ddf4a0531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0c47a-3521-4b54-a5e2-c3e19de0e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Luminosity - Narrow Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_FWHM_Min_Narrow_Sigma_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected PSF Limited Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin/1.05, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7174e-1e86-4641-a825-706fb4eac722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-positions for the redshift bins\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Redshift - Broad Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, x_err) in enumerate(datasets):\n",
    "    y_pos = y_positions[i]\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_pos,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (x direction only)\n",
    "    ax.errorbar(x_data, y_pos,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected PSF Limited Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Broad_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Broad_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc5658-3a53-4748-8f15-ef99a03f3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-positions for the redshift bins\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Redshift - Narrow Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, x_err) in enumerate(datasets):\n",
    "    y_pos = y_positions[i]\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_pos,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (x direction only)\n",
    "    ax.errorbar(x_data, y_pos,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected PSF Limited Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_Narrow_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304beb6-8206-4ce0-9546-67b16e053389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031007d2-f366-4f8e-9249-267aabd1f307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aac46f-f814-44ed-bbac-afc4eb89c0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c4e60-46dc-4e94-a701-6d1e5549d491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab0178-a282-4a03-813f-f96feccb49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recalculating the black hole masses from the corrected luminosities. \n",
    "This one it for the two gaussian measurement with a PSF limit and a uniform narrow component.\n",
    "\n",
    "For the Narrow part of the MgII (This is not to actually be used. We want to use the broad component.)\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_025_035, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_025_035 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_025_035, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_025_035, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_025_035, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_035_045, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_035_045 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_035_045, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_035_045, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_035_045, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_045_055, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_045_055 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_045_055, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_045_055, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_045_055, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_055_065, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_055_065 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_055_065, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_055_065, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_055_065, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_065_075, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_065_075 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_065_075, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_065_075,\n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_065_075, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_075_085, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_075_085 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_075_085, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_075_085, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_075_085, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_085_096, BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_085_096 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_085_096, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_085_096, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_085_096, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_085_096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd362a-05dd-4539-acf4-5f61af6e1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the Broad part of the MgII.\n",
    "\n",
    "Calculate black hole mass using the MgII line width and continuum luminosity at 3000Å.\n",
    "    \n",
    "This function computes black hole mass (in solar masses) based on the empirical relation:\n",
    "    M_BH/M_☉ = 3.37 * (λL_3000/10^37 W)^0.47 * (FWHM_MgII/km s^-1)^2\n",
    "\"\"\"\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_025_035, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_025_035 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_025_035, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_025_035, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_025_035, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_025_035)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_035_045, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_035_045 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_035_045, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_035_045, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_035_045, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_035_045)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_045_055, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_045_055 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_045_055, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_045_055, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_045_055, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_045_055)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_055_065, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_055_065 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_055_065, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_055_065, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_055_065, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_055_065)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_065_075, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_065_075 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_065_075, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_065_075, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_065_075, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_065_075)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_075_085, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_075_085 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_075_085, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_075_085, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_075_085, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_075_085)\n",
    "\n",
    "BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_085_096, BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_085_096 = black_hole_mass(3000, Luminosities_Binned_Data_Mean_085_096, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_085_096, \n",
    "                                                                                                                                                                        Luminosities_Binned_Data_Mean_SD_085_096, \n",
    "                                                                                                                                                                        MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_085_096)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9445c3-be94-4207-8bb4-997f7bd17f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (Black Hole Mass vs Luminosity)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     BH_Mass_Broad_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Fixed Narrow Component Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin/1.05, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489906d-ef2d-4098-894b-c263d279a2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2d0f7-c5be-4ec0-a219-55a8d34731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (Black Hole Mass vs Luminosity - Narrow Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     BH_Mass_Narrow_MgII_Uniform_Narrow_Sigma_Luminosity_Corrected_Mean_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"Black Hole Mass [M$_{\\odot}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Fixed Narrow Component Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbac0c-c7e6-4785-a49d-cb7d3bf309fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67e850-63eb-4f84-9d4e-3445c8eadc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Luminosity - Broad Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Broad_Sigma_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Fixed Narrow Component Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin/1.05, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2907c7-8238-4695-bf97-26b35d4411c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72109195-8e9a-4c2c-999b-52765d8740b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Luminosity - Narrow Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_025_035,\n",
    "     Luminosities_Binned_Data_Mean_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_025_035,\n",
    "     Luminosities_Binned_Data_Mean_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_035_045,\n",
    "     Luminosities_Binned_Data_Mean_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_035_045,\n",
    "     Luminosities_Binned_Data_Mean_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_045_055,\n",
    "     Luminosities_Binned_Data_Mean_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_045_055,\n",
    "     Luminosities_Binned_Data_Mean_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_055_065,\n",
    "     Luminosities_Binned_Data_Mean_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_055_065,\n",
    "     Luminosities_Binned_Data_Mean_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_065_075,\n",
    "     Luminosities_Binned_Data_Mean_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_065_075,\n",
    "     Luminosities_Binned_Data_Mean_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_075_085,\n",
    "     Luminosities_Binned_Data_Mean_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_075_085,\n",
    "     Luminosities_Binned_Data_Mean_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_085_096,\n",
    "     Luminosities_Binned_Data_Mean_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Uniform_Narrow_Sigma_Narrow_Sigma_SD_085_096,\n",
    "     Luminosities_Binned_Data_Mean_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, y_data, x_err, y_err) in enumerate(datasets):\n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_data,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (both x and y directions)\n",
    "    ax.errorbar(x_data, y_data,\n",
    "               xerr=x_err,\n",
    "               yerr=y_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Continuum L$_{3000 \\AA}$ [Watts]\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Fixed Narrow Component Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='upper left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab56c6e4-6668-4272-bfba-ca70f103aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-axis positions for each redshift bin\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Redshift - Broad Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Broad_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, x_err) in enumerate(datasets):\n",
    "    y_pos = y_positions[i]\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_pos,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (x direction only)\n",
    "    ax.errorbar(x_data, y_pos,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Fixed Narrow Component Double Gaussian - Broad\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower left',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096_Broad.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096_Broad.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bed10-27b8-41ed-acfd-777264a8a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "    'mathtext.fontset': 'dejavuserif',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.7,\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.8,\n",
    "    'xtick.major.size': 8,\n",
    "    'xtick.minor.size': 4,\n",
    "    'ytick.major.size': 8,\n",
    "    'ytick.minor.size': 4,\n",
    "    'xtick.major.width': 2.0,\n",
    "    'xtick.minor.width': 1.5,\n",
    "    'ytick.major.width': 2.0,\n",
    "    'ytick.minor.width': 1.5,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'xtick.top': True,\n",
    "    'ytick.right': True,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.framealpha': 1.0\n",
    "})\n",
    "\n",
    "# Create figure with specified dimensions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6), facecolor='white')\n",
    "\n",
    "# Color scheme (organized in dictionary)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Labels for legend (formatted for better readability)\n",
    "labels = [\n",
    "    r'$0.25 < z < 0.35$',\n",
    "    r'$0.35 < z < 0.45$',\n",
    "    r'$0.45 < z < 0.55$',\n",
    "    r'$0.55 < z < 0.65$',\n",
    "    r'$0.65 < z < 0.75$',\n",
    "    r'$0.75 < z < 0.85$',\n",
    "    r'$0.85 < z < 0.96$'\n",
    "]\n",
    "\n",
    "# Y-axis positions for each redshift bin\n",
    "y_positions = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Dataset configuration for plotting (FWHM vs Redshift - Narrow Component)\n",
    "datasets = [\n",
    "    ('025_035', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_025_035,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_025_035),\n",
    "    ('035_045', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_035_045,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_035_045),\n",
    "    ('045_055', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_045_055,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_045_055),\n",
    "    ('055_065', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_055_065,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_055_065),\n",
    "    ('065_075', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_065_075,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_065_075),\n",
    "    ('075_085', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_075_085,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_075_085),\n",
    "    ('085_096', \n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_085_096,\n",
    "     MgII_ReStacked_Continuum_Scaled_Two_Gaussian_Velocity_Narrow_Sigma_SD_085_096)\n",
    "]\n",
    "\n",
    "# Plot each dataset\n",
    "for i, (key, x_data, x_err) in enumerate(datasets):\n",
    "    y_pos = y_positions[i]\n",
    "    \n",
    "    # Plot data points with heart markers\n",
    "    ax.scatter(x_data, y_pos,\n",
    "              color=colors[key],\n",
    "              s=200,\n",
    "              marker=u\"$\\u2665$\",\n",
    "              alpha=1.0,\n",
    "              zorder=10+i,\n",
    "              label=labels[i])\n",
    "    \n",
    "    # Plot error bars (x direction only)\n",
    "    ax.errorbar(x_data, y_pos,\n",
    "               xerr=x_err,\n",
    "               linestyle='',\n",
    "               ecolor='black',\n",
    "               capsize=5,\n",
    "               capthick=2,\n",
    "               elinewidth=1.5,\n",
    "               alpha=0.8,\n",
    "               zorder=i)\n",
    "\n",
    "# Configure axes labels and title\n",
    "ax.set_xlabel(r\"FWHM [km s$^{-1}$]\", fontsize=14, color=\"black\")\n",
    "ax.set_ylabel(r\"Redshift\", fontsize=14, color=\"black\")\n",
    "ax.set_title(\"Luminosity Trend Corrected Fixed Narrow Component Double Gaussian - Narrow\", fontsize=14, pad=15)\n",
    "\n",
    "# Configure legend with MNRAS style\n",
    "legend = ax.legend(\n",
    "    loc='lower right',\n",
    "    fontsize=12,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    borderpad=0.8,\n",
    "    handletextpad=0.6,\n",
    "    columnspacing=1.0,\n",
    "    handlelength=1.0,\n",
    "    labelspacing=1.0,\n",
    "    numpoints=1\n",
    ")\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "legend.get_frame().set_edgecolor('black')\n",
    "\n",
    "# Configure grid\n",
    "ax.grid(visible=True, which='both', axis='both', \n",
    "        linestyle='--', alpha=0.7, zorder=-10)\n",
    "\n",
    "# Set minor ticks\n",
    "ax.minorticks_on()\n",
    "\n",
    "# Configure spine thickness (MNRAS style)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Configure tick parameters\n",
    "ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "               length=8, width=2.0, direction='in')\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "               length=4, width=1.5, direction='in')\n",
    "\n",
    "# Enable ticks on all sides\n",
    "ax.tick_params(top=True, right=True)\n",
    "\n",
    "# Extend the upper y-limit slightly\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim(ymin, ymax * 1.05)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# Save figure in MNRAS-ready format\n",
    "# Uncomment the following lines to save:\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096_Narrow.pdf\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "# fig.savefig(\"AGN_Gaussian_Sersic_Fit_MNRAS_Ready_085_096_Narrow.png\", dpi=300, \n",
    "#             bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98152165-de97-4a54-836f-8318e885da3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2b248-e46d-4bf7-946e-b64c9da2e4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd501d0-5bdb-48fc-b9ca-65d3ae32b5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5fb03-7d45-49f4-b51e-00dbd5a54e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ec1c3-674d-42a4-8a66-e68bf1dc1fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ee87c-7b84-4a71-bea7-dabb67f83563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e7025-6ffe-4d4a-95ef-e2a595e41239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726fbe1-ac8d-4036-bfa4-6b04b46cc8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ad3de-d950-4a1c-998a-48d9fe3fcf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5a416-16e7-4e9f-be56-0ee143481d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0590a-e95b-400f-9a4b-78cb3d86c189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58422601-f540-42b2-ac76-234354e6a032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b794ed3-0e37-442b-ac6d-63f7aec92223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5aa564-fac0-4098-9582-9abdb2ac7305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31560b44-28b0-4c3d-80a4-4f63ad5c24ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fed0b-e817-4341-b0d7-1966abb15921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fd185-d22a-4213-aaa2-2d9edc5cf63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a20a45-723f-4ed2-a683-2f99223d7188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa2258-2335-4803-8af5-fab715b18de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c3270-bb51-4a07-ad69-fc741842d416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f21918-d6b8-4b10-81f6-db318617a0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355102c3-f10a-4bb9-91b2-6dcb48227e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87649cdb-e976-4d4c-8ba3-8403a9a96ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73251483-ccb6-482f-990c-1a63fca247b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66cef1-7f16-4c38-9b4b-b5481a8e6e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5927c-c8d2-45d9-929c-06e8a257aaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a981c-1b1e-4b13-98be-9feabefd394d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fcb0a-0414-4486-8506-a1b2f45e6ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd8e37-f622-4515-bfc5-9a0cfb0d85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768073d8-287a-488c-b63c-c2e8807b55c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbff45c-6f4e-4d5d-a352-1964936557b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70576f-5c4a-4a51-b9f0-0987664f97f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66267c3b-d618-4ef8-86ca-2b5620641e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19889b0-3247-4619-ad1d-713eba052145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb64a7-72ab-4138-aaac-bfefab2efca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7d1a5-952c-4656-9c61-ab27c4d0d59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
