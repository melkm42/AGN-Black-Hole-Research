{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d691ad-6dd2-42b1-a53f-bcedfd26d550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de63f52d-3e9b-4a51-85d4-f663fd68790b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <font color='#cec748'>This notebook is for SED fitting of our Chenxu AGN data</font>\n",
    "The notebook uses data from the get_spec_example file to:\n",
    "- Work with the spectra (make adjustments and clean up)\n",
    "- Look at spectra over wavelength\n",
    "- Fit spectral lines\n",
    "- Find BH Mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512183b0-8238-4e1c-b244-407c6901cee7",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f1728-e911-4424-9a39-43d3756b9dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb0d752-a53d-4b5b-acb4-ad0b8ebf4a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagpipes: PyMultiNest import failed, fitting will use the Nautilus sampler instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bagpipes as pipes\n",
    "\n",
    "from astropy.table import QTable, Table, Column\n",
    "import matplotlib as mpl\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.cosmology import Planck18\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import nautilus\n",
    "\n",
    "#import pymultinest\n",
    "import dynesty\n",
    "import ultranest\n",
    "import emcee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ccc27-f285-4a6c-9248-7139b1e573a1",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Plotting imports and settings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5652e-9f64-4750-a0c1-6250afd9d24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c780830e-7542-4083-86b6-df09cd7729d2",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3f2632-538b-49b5-9ac6-805c12491293",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 299792.5 #km s^-1\n",
    "H_0 = 70 #km s^-1 MpC^-1\n",
    "\n",
    "\"\"\"\n",
    "These are the rest wavelengths in angstroms for the lines that are important for the fits.\n",
    "\"\"\"\n",
    "HeII_2733 = 2733.289\n",
    "MgII_2800 = 2799.000\n",
    "FeIV_2829 = 2829.36\n",
    "FeIV_2836 = 2835.740\n",
    "ArIV_2854 = 2853.670\n",
    "ArIV_2868 = 2868.210\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "To get the FWHM to use in my MgII fitting in velocity space. \n",
    "This will give a minumum not a maximum.\n",
    "FWHM = speed of light / spectral resolution.\n",
    "\"\"\"\n",
    "R = 800 #Spectral Resolution\n",
    "\n",
    "FWHM_Velocity = c/R\n",
    "\n",
    "\n",
    "# Your existing code should work better now\n",
    "hsc_filter_files = {\n",
    "    'hsc_g': '/home/jovyan/work/stampede3/AGN-Black-Hole-Research/hsc_g.dat',\n",
    "    'hsc_r': '/home/jovyan/work/stampede3/AGN-Black-Hole-Research/hsc_r.dat', \n",
    "    'hsc_i': '/home/jovyan/work/stampede3/AGN-Black-Hole-Research/hsc_i.dat',\n",
    "    'hsc_z': '/home/jovyan/work/stampede3/AGN-Black-Hole-Research/hsc_z.dat',\n",
    "    'hsc_y': '/home/jovyan/work/stampede3/AGN-Black-Hole-Research/hsc_y.dat'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3dd8c2-6d2e-4647-9633-c9c542586c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get the function\\'s signature\\nsignature = inspect.signature(ESU.stack_spectra)\\nprint(\"Signature:\", signature)\\n\\n# Get the return type annotation\\nreturn_type = signature.return_annotation\\nprint(\"Return type:\", return_type)\\n\\n# Get the docstring\\ndocstring = inspect.getdoc(ESU.stack_spectra)\\nprint(\"Docstring:\", docstring)\\n\\n# Get the source code\\nsource_code = inspect.getsource(ESU.stack_spectra)\\nprint(\"Source code:\\n\", source_code)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to figure out everything about the calls / definitions\n",
    "\n",
    "\"\"\"\n",
    "# Get the function's signature\n",
    "signature = inspect.signature(ESU.stack_spectra)\n",
    "print(\"Signature:\", signature)\n",
    "\n",
    "# Get the return type annotation\n",
    "return_type = signature.return_annotation\n",
    "print(\"Return type:\", return_type)\n",
    "\n",
    "# Get the docstring\n",
    "docstring = inspect.getdoc(ESU.stack_spectra)\n",
    "print(\"Docstring:\", docstring)\n",
    "\n",
    "# Get the source code\n",
    "source_code = inspect.getsource(ESU.stack_spectra)\n",
    "print(\"Source code:\\n\", source_code)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b1a04-0985-4335-b8b2-a2cbeb6dff9d",
   "metadata": {},
   "source": [
    "'''\n",
    "For plotting clear distinctions \n",
    "\n",
    "Teal - #309898 - Original teal base\n",
    "Orange - #FF9F00 - Original orange base\n",
    "Red - #CB0404 - Original red base\n",
    "Black - #000000 - Original black base\n",
    "Navy Blue - #1D5799 - Deep blue with good contrast against teal\n",
    "Yellow - #ECC700 - Bright yellow distinguishable from orange\n",
    "Purple - #8B3D88 - Distinct from blues and reds\n",
    "Lime Green - #74B741 - Bright green distinguishable from teal\n",
    "Magenta - #DB3EB1 - Distinct pink/purple\n",
    "Brown - #8D6E42 - Earth tone distinct from oranges and reds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sequential Teal Variants (for heatmaps or gradients)\n",
    "\n",
    "Teal 100% - #309898 - Base teal\n",
    "Teal 80% - #5CACA6 - Lighter teal\n",
    "Teal 60% - #87BFB5 - Even lighter teal\n",
    "Teal 40% - #B2D2CC - Very light teal\n",
    "Teal 20% - #D9E6E3 - Almost white teal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sequential Orange Variants (for heatmaps or gradients)\n",
    "\n",
    "Orange 100% - #FF9F00 - Base orange\n",
    "Orange 80% - #FFB440 - Lighter orange\n",
    "Orange 60% - #FFC977 - Even lighter orange\n",
    "Orange 40% - #FFDEA6 - Very light orange\n",
    "Orange 20% - #FFF0D9 - Almost white orange\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "High Contrast Pairs\n",
    "These pairs are specifically designed to be highly distinguishable from each other:\n",
    "\n",
    "Vivid Blue - #0072B2 - ColorBrewer-inspired blue\n",
    "Vivid Orange - #E69F00 - ColorBrewer-inspired orange\n",
    "Vivid Green - #009E73 - ColorBrewer-inspired green\n",
    "Vivid Red - #D55E00 - ColorBrewer-inspired red\n",
    "Vivid Purple - #9467BD - ColorBrewer-inspired purple\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Special Purpose\n",
    "\n",
    "Background Gray - #F0F0F0 - Light gray for plot backgrounds\n",
    "Grid Line Gray - #CCCCCC - Medium gray for grid lines\n",
    "Highlight Yellow - #FFFB54 - Attention-grabbing highlight\n",
    "Reference Line - #505050 - Dark gray for reference lines\n",
    "Annotation Red - #E41A1C - Bright red for important annotations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red\n",
    "\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea73de4-aa6f-4f9f-b8d4-74b1dd351b12",
   "metadata": {},
   "source": [
    "## <font color='#e55730' size=3 >Definitions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12071866-68c8-4cef-8804-e5fc8a056529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bagpipes_data_loader_correct(flux_array, flux_err_array, redshift):\n",
    "    \"\"\"\n",
    "    Create CORRECT data loader function for BAGPIPES photometry-only fitting\n",
    "    \n",
    "    Based on official BAGPIPES documentation:\n",
    "    - For photometry-only: load_data should return ONLY photometry (not a tuple)\n",
    "    - Photometry should be 2D array with shape (n_filters, 2)\n",
    "    - Format: [[flux1, error1], [flux2, error2], ...]\n",
    "    - Units: microjanskys (default for phot_units)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    flux_array : array-like\n",
    "        Flux values in microjanskys\n",
    "    flux_err_array : array-like\n",
    "        Flux error values in microjanskys\n",
    "    redshift : float\n",
    "        Galaxy redshift (passed separately to galaxy object)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    function : Data loader function that returns correct format\n",
    "    \"\"\"\n",
    "    \n",
    "    def load_data(galaxy_id):\n",
    "        \"\"\"\n",
    "        Load photometry data for BAGPIPES\n",
    "        \n",
    "        For photometry-only fitting, return only the photometry array\n",
    "        Redshift is handled separately by the galaxy object\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert to numpy arrays and ensure they're 1D\n",
    "        flux_arr = np.asarray(flux_array, dtype=np.float64).flatten()\n",
    "        flux_err_arr = np.asarray(flux_err_array, dtype=np.float64).flatten()\n",
    "        \n",
    "        # Check arrays have same length\n",
    "        if len(flux_arr) != len(flux_err_arr):\n",
    "            raise ValueError(f\"Flux and error arrays must have same length: {len(flux_arr)} vs {len(flux_err_arr)}\")\n",
    "        \n",
    "        # Ensure positive fluxes and errors\n",
    "        flux_arr = np.maximum(flux_arr, 1e-10)  # Avoid zero/negative fluxes\n",
    "        flux_err_arr = np.maximum(flux_err_arr, 1e-10)  # Avoid zero/negative errors\n",
    "        \n",
    "        # Create 2D photometry array: each row is [flux, error] for one filter\n",
    "        photometry_array = np.column_stack([flux_arr, flux_err_arr])\n",
    "        \n",
    "        # Verify shape and data types\n",
    "        print(f\"Data loader returning photometry with shape: {photometry_array.shape}\")\n",
    "        print(f\"Data type: {photometry_array.dtype}\")\n",
    "        print(f\"Sample values: {photometry_array[:2]}\")\n",
    "        \n",
    "        # For photometry-only fitting, return ONLY the photometry array\n",
    "        return photometry_array\n",
    "    \n",
    "    return load_data\n",
    "\n",
    "\n",
    "def create_bagpipes_filter_files_corrected(filter_response_files, output_dir=\"bagpipes_filters\"):\n",
    "    \"\"\"\n",
    "    Create BAGPIPES-compatible filter files from HSC filter response curves\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filter_response_files : dict\n",
    "        Dictionary mapping filter names to response curve file paths\n",
    "    output_dir : str\n",
    "        Directory to save BAGPIPES filter files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (filter_file_paths_dict, filter_paths_list)\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    filter_file_paths = {}\n",
    "    \n",
    "    for filter_name, response_file_path in filter_response_files.items():\n",
    "        \n",
    "        if not os.path.exists(response_file_path):\n",
    "            print(f\"Warning: Filter file {response_file_path} not found, skipping {filter_name}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load filter response curve\n",
    "            data = np.loadtxt(response_file_path)\n",
    "            \n",
    "            if data.shape[1] != 2:\n",
    "                print(f\"Warning: {response_file_path} should have 2 columns (wavelength, transmission)\")\n",
    "                continue\n",
    "            \n",
    "            wavelength = data[:, 0]  # Assuming already in Angstroms\n",
    "            transmission = data[:, 1]\n",
    "            \n",
    "            # Create output filename\n",
    "            output_filename = f\"{filter_name}.filt\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            # Save in BAGPIPES format (wavelength in Angstroms, transmission fraction)\n",
    "            bagpipes_data = np.column_stack([wavelength, transmission])\n",
    "            np.savetxt(output_path, bagpipes_data, fmt='%.6e')\n",
    "            \n",
    "            filter_file_paths[filter_name] = output_path\n",
    "            print(f\"Created BAGPIPES filter file: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filter_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create list of filter paths in consistent order\n",
    "    filter_paths_list = [filter_file_paths[name] for name in sorted(filter_file_paths.keys())]\n",
    "    \n",
    "    return filter_file_paths, filter_paths_list\n",
    "\n",
    "def check_bagpipes_dependencies():\n",
    "    \"\"\"\n",
    "    Check which sampler is available and working - prioritizing dynesty\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : \"dynesty\", \"ultranest\", \"multinest\", \"emcee\", or \"none\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Test dynesty first (recommended MultiNest alternative)\n",
    "    try:\n",
    "        print(\"✓ dynesty is available - excellent nested sampling alternative to MultiNest\")\n",
    "        return \"dynesty\"\n",
    "    except ImportError:\n",
    "        print(\"✗ dynesty not available\")\n",
    "    \n",
    "    # Test UltraNest (another good nested sampling option)\n",
    "    try:\n",
    "        print(\"✓ ultranest is available - another nested sampling option\")\n",
    "        return \"ultranest\"\n",
    "    except ImportError:\n",
    "        print(\"✗ ultranest not available\")\n",
    "    \n",
    "    # Test MultiNest (if properly installed)\n",
    "    try:\n",
    "        # Try to actually use it to see if the library is properly installed\n",
    "        pymultinest.run(lambda: 0, lambda: 0, 1, n_live_points=2, resume=False, \n",
    "                      verbose=False, outputfiles_basename='test_', max_iter=1)\n",
    "        print(\"✓ MultiNest is available and working\")\n",
    "        return \"multinest\"\n",
    "    except Exception as e:\n",
    "        print(f\"✗ MultiNest installed but not working: {e}\")\n",
    "    \n",
    "    # Test emcee (MCMC fallback)\n",
    "    try:\n",
    "        print(\"✓ emcee is available - MCMC sampler (different from nested sampling)\")\n",
    "        return \"emcee\"\n",
    "    except ImportError:\n",
    "        print(\"✗ emcee not available\")\n",
    "    \n",
    "    # Test nautilus (last resort)\n",
    "    try:\n",
    "        print(\"✓ nautilus is available - will try with workarounds\")\n",
    "        return \"nautilus\"\n",
    "    except ImportError:\n",
    "        print(\"✗ nautilus not available\")\n",
    "    \n",
    "    print(\"✗ No supported samplers available!\")\n",
    "    return \"none\"\n",
    "\n",
    "def setup_bagpipes_model_minimal_stable(fixed_redshift=None):\n",
    "    \"\"\"\n",
    "    Set up the most minimal stable BAGPIPES model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fixed_redshift : float, optional\n",
    "        If provided, fix redshift to this value\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : BAGPIPES model configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define minimal model components\n",
    "    model_components = {}\n",
    "    \n",
    "    # Redshift - fixed or free\n",
    "    if fixed_redshift is not None:\n",
    "        model_components[\"redshift\"] = fixed_redshift\n",
    "    else:\n",
    "        model_components[\"redshift\"] = (0.299, 0.301)  # Conservative range\n",
    "    \n",
    "    # Star formation history - constant star formation rate (simplest)\n",
    "    model_components[\"constant\"] = {\n",
    "        \"age\": (1.0, 13.0),          # Avoid very young ages\n",
    "        \"massformed\": (9.0, 11.5),   # Narrow, realistic range\n",
    "        \"metallicity\": (0.5, 1.5)    # Conservative metallicity range\n",
    "    }\n",
    "    \n",
    "    return model_components\n",
    "\n",
    "def setup_bagpipes_model_robust(fixed_redshift):\n",
    "    \"\"\"\n",
    "    Set up a robust BAGPIPES model with dust for AGN research\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fixed_redshift : float, optional\n",
    "        If provided, fix redshift to this value\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : BAGPIPES model configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define model components\n",
    "    model_components = {}\n",
    "    \n",
    "    # Redshift - fixed or free\n",
    "    if fixed_redshift is not None:\n",
    "        model_components[\"redshift\"] = fixed_redshift\n",
    "    else:\n",
    "        model_components[\"redshift\"] = (0.29, 0.301)  # Avoid zero redshift\n",
    "    \n",
    "    # Star formation history - delayed exponential (tau model)\n",
    "    model_components[\"delayed\"] = {\n",
    "        \"age\": (0.5, 13.0),          # Avoid very young ages\n",
    "        \"tau\": (0.3, 5.0),           # More conservative tau range\n",
    "        \"massformed\": (8.0, 12.0),   # Realistic stellar mass range\n",
    "        \"metallicity\": (0.1, 2.0)    # Avoid extreme metallicities\n",
    "    }\n",
    "    \n",
    "    # Dust attenuation - Calzetti law\n",
    "    model_components[\"dust\"] = {\n",
    "        \"type\": \"Calzetti\",         # Calzetti dust law\n",
    "        \"Av\": (0.0, 2.0)            # Conservative attenuation range\n",
    "    }\n",
    "    \n",
    "    return model_components\n",
    "\n",
    "def setup_bagpipes_model_agn_optimized(fixed_redshift=None):\n",
    "    \"\"\"\n",
    "    Set up BAGPIPES model optimized for AGN host galaxy research\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fixed_redshift : float, optional\n",
    "        If provided, fix redshift to this value\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : BAGPIPES model configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    model_components = {}\n",
    "    \n",
    "    # Redshift\n",
    "    if fixed_redshift is not None:\n",
    "        model_components[\"redshift\"] = fixed_redshift\n",
    "    else:\n",
    "        model_components[\"redshift\"] = (0.299, 0.301)  # AGN can be at higher z\n",
    "    \n",
    "    # Double exponential SFH (good for AGN hosts with possible bursts)\n",
    "    model_components[\"dblplaw\"] = {\n",
    "        \"tau\": (0.1, 3.0),           # e-folding time\n",
    "        \"alpha\": (0.1, 1000.0),      # Power-law slope at early times\n",
    "        \"beta\": (0.1, 1000.0),       # Power-law slope at late times\n",
    "        \"massformed\": (8.5, 12.5),   # AGN hosts often massive\n",
    "        \"metallicity\": (0.2, 2.5)    # AGN hosts can be metal-rich\n",
    "    }\n",
    "    \n",
    "    # Dust - important for AGN hosts\n",
    "    model_components[\"dust\"] = {\n",
    "        \"type\": \"Calzetti\",\n",
    "        \"Av\": (0.0, 3.0)            # AGN hosts can be dusty\n",
    "    }\n",
    "    \n",
    "    return model_components\n",
    "\n",
    "def install_sampler_guide():\n",
    "    \"\"\"\n",
    "    Print installation guide for supported samplers\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAMPLER INSTALLATION GUIDE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nRecommended installation order:\")\n",
    "    print(\"\\n1. DYNESTY (BEST OPTION - direct MultiNest replacement):\")\n",
    "    print(\"   pip install dynesty\")\n",
    "    print(\"   - Pure Python nested sampling\")\n",
    "    print(\"   - No C library dependencies\")\n",
    "    print(\"   - Same algorithm family as MultiNest\")\n",
    "    print(\"\\n2. ULTRANEST (Alternative nested sampling):\")\n",
    "    print(\"   pip install ultranest\")\n",
    "    print(\"   - Another excellent nested sampler\")\n",
    "    print(\"   - Good for high-dimensional problems\")\n",
    "    print(\"\\n3. EMCEE (MCMC alternative):\")\n",
    "    print(\"   pip install emcee\")\n",
    "    print(\"   - Different approach (MCMC vs nested sampling)\")\n",
    "    print(\"   - Very reliable and widely used\")\n",
    "    print(\"\\n4. MULTINEST (if you can get it working):\")\n",
    "    print(\"   conda install -c conda-forge multinest\")\n",
    "    print(\"   - Original nested sampling implementation\")\n",
    "    print(\"   - Requires C/Fortran compilation\")\n",
    "    print(\"\\nFor AGN research, nested sampling (dynesty/ultranest) is recommended\")\n",
    "    print(\"over MCMC because it handles multi-modal posteriors better.\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "def run_bagpipes_fit_dynesty_fixed(flux_array, flux_err_array, \n",
    "                                 filter_response_files, redshift, \n",
    "                                 n_live, galaxy_id=\"agn_galaxy\",\n",
    "                                 run_name=\"agn_fit\",\n",
    "                                 model_type=\"robust\"):\n",
    "    \"\"\"\n",
    "    BAGPIPES SED fitting with FIXED parameter compatibility for dynesty and other samplers\n",
    "    \n",
    "    This version uses only parameters that are universally supported across BAGPIPES versions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    flux_array : array-like\n",
    "        Flux values in microjanskys for HSC filters\n",
    "    flux_err_array : array-like  \n",
    "        Flux error values in microjanskys for HSC filters\n",
    "    filter_response_files : dict\n",
    "        Dictionary mapping filter names to response curve file paths\n",
    "    galaxy_id : str\n",
    "        Galaxy identifier\n",
    "    redshift : float\n",
    "        Fixed spectroscopic redshift\n",
    "    run_name : str\n",
    "        Name for the fitting run\n",
    "    n_live : int\n",
    "        Number of live points for nested sampling\n",
    "    model_type : str\n",
    "        \"minimal\", \"robust\", or \"agn_optimized\"\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (fit, galaxy) BAGPIPES objects\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"BAGPIPES AGN Host Galaxy SED Fitting (Parameter-Fixed Version)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Check available samplers\n",
    "    sampler = check_bagpipes_dependencies()\n",
    "    if sampler == \"none\":\n",
    "        print(\"ERROR: No supported samplers available!\")\n",
    "        install_sampler_guide()\n",
    "        return None, None\n",
    "    \n",
    "    # 1. Create BAGPIPES-compatible filter files\n",
    "    print(\"\\nCreating BAGPIPES-compatible filter files...\")\n",
    "    filter_file_paths, filter_paths_list = create_bagpipes_filter_files_corrected(\n",
    "        filter_response_files, output_dir=\"bagpipes_filters\"\n",
    "    )\n",
    "    \n",
    "    if len(filter_file_paths) == 0:\n",
    "        print(\"ERROR: No filter files created successfully!\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Successfully created {len(filter_file_paths)} filter files\")\n",
    "    \n",
    "    # 2. Create data loader function\n",
    "    print(\"Creating data loader function...\")\n",
    "    load_data = create_bagpipes_data_loader_correct(flux_array, flux_err_array, redshift)\n",
    "    \n",
    "    # 3. Test the data loader\n",
    "    print(\"Testing data loader...\")\n",
    "    try:\n",
    "        test_photometry = load_data(galaxy_id)\n",
    "        print(f\"✓ Data loader test successful\")\n",
    "        print(f\"  Photometry shape: {test_photometry.shape}\")\n",
    "        \n",
    "        # Print photometry summary\n",
    "        print(f\"\\nPhotometric data summary:\")\n",
    "        print(\"-\" * 35)\n",
    "        filter_names = sorted(filter_file_paths.keys())\n",
    "        for i, filt_name in enumerate(filter_names):\n",
    "            if i < len(test_photometry):\n",
    "                flux, err = test_photometry[i]\n",
    "                snr = flux / err if err > 0 else 0\n",
    "                print(f\"{filt_name:10s}: {flux:8.2f} ± {err:6.2f} μJy (S/N: {snr:5.1f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Data loader test failed: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # 4. Create galaxy object\n",
    "    print(f\"\\nCreating galaxy object...\")\n",
    "    try:\n",
    "        galaxy = pipes.galaxy(galaxy_id, \n",
    "                             load_data, \n",
    "                             spectrum_exists=False,\n",
    "                             photometry_exists=True,\n",
    "                             filt_list=filter_paths_list,\n",
    "                             phot_units='mujy')\n",
    "        \n",
    "        print(f\"✓ Galaxy object created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Galaxy object creation failed: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # 5. Set up model based on type\n",
    "    print(f\"\\nSetting up {model_type} model...\")\n",
    "    if model_type == \"minimal\":\n",
    "        model_components = setup_bagpipes_model_minimal_stable(fixed_redshift=redshift)\n",
    "    elif model_type == \"agn_optimized\":\n",
    "        model_components = setup_bagpipes_model_agn_optimized(fixed_redshift=redshift)\n",
    "    else:  # robust\n",
    "        model_components = setup_bagpipes_model_robust(fixed_redshift=redshift)\n",
    "    \n",
    "    print(f\"Model configuration:\")\n",
    "    for component, params in model_components.items():\n",
    "        if isinstance(params, dict):\n",
    "            print(f\"- {component}: {list(params.keys())}\")\n",
    "        else:\n",
    "            print(f\"- {component}: {params}\")\n",
    "    \n",
    "    # 6. Create fit object\n",
    "    print(f\"\\nCreating fit object...\")\n",
    "    try:\n",
    "        fit = pipes.fit(galaxy=galaxy, \n",
    "                       fit_instructions=model_components,\n",
    "                       run=run_name,\n",
    "                       time_calls=True)\n",
    "        \n",
    "        print(f\"✓ Fit object created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Fit object creation failed: {e}\")\n",
    "        return None, galaxy\n",
    "    \n",
    "    # 7. Run fitting with CONSERVATIVE sampler-specific settings\n",
    "    print(f\"\\nRunning SED fitting with {sampler} sampler...\")\n",
    "    \n",
    "    try:\n",
    "        if sampler == \"dynesty\":\n",
    "            print(\"Using dynesty with conservative settings...\")\n",
    "            # Use only basic parameters that are universally supported\n",
    "            fit.fit(verbose=True, \n",
    "                    n_live=n_live)\n",
    "            \n",
    "        elif sampler == \"ultranest\":\n",
    "            print(\"Using ultranest with conservative settings...\")\n",
    "            fit.fit(verbose=True, \n",
    "                    n_live=n_live)\n",
    "            \n",
    "        elif sampler == \"multinest\":\n",
    "            print(\"Using MultiNest with conservative settings...\")\n",
    "            fit.fit(verbose=True, \n",
    "                    n_live=n_live)\n",
    "            \n",
    "        elif sampler == \"emcee\":\n",
    "            print(\"Using emcee with conservative settings...\")\n",
    "            # EMCEE uses different parameters\n",
    "            n_params = len([p for p in model_components.values() if isinstance(p, tuple)])\n",
    "            n_walkers = max(20, 2 * n_params)  # Safe minimum\n",
    "            n_samples = max(1000, n_live * 20)  # Reasonable sample count\n",
    "            \n",
    "            fit.fit(verbose=True, \n",
    "                    n_samples=n_samples,\n",
    "                    n_walkers=n_walkers)\n",
    "            \n",
    "        elif sampler == \"nautilus\":\n",
    "            print(\"Using nautilus with conservative settings...\")\n",
    "            fit.fit(verbose=True, \n",
    "                    n_live=max(50, n_live//2))\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"SUCCESS! SED fitting completed with {sampler}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Print basic results\n",
    "        if hasattr(fit, 'posterior'):\n",
    "            print(f\"\\nFit results summary:\")\n",
    "            if hasattr(fit.posterior, 'logz'):\n",
    "                print(f\"- Log evidence: {fit.posterior.logz:.2f}\")\n",
    "            elif hasattr(fit.posterior, 'samples'):\n",
    "                print(f\"- Number of samples: {len(fit.posterior.samples)}\")\n",
    "                \n",
    "                # Print parameter estimates\n",
    "                print(f\"\\nParameter estimates (median ± 1σ):\")\n",
    "                print(\"-\" * 40)\n",
    "                for param in sorted(fit.fitted_model.params):\n",
    "                    if param in fit.posterior.samples:\n",
    "                        samples = fit.posterior.samples[param]\n",
    "                        median_val = np.median(samples)\n",
    "                        std_val = np.std(samples)\n",
    "                        print(f\"{param:15s}: {median_val:8.3f} ± {std_val:6.3f}\")\n",
    "        \n",
    "        return fit, galaxy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Fitting with {sampler} failed: {e}\")\n",
    "        print(f\"   Error type: {type(e).__name__}\")\n",
    "        print(f\"   Error details: {str(e)}\")\n",
    "        \n",
    "        # Try most basic fitting approach\n",
    "        if sampler != \"emcee\":\n",
    "            print(\"\\nTrying most basic fitting approach...\")\n",
    "            try:\n",
    "                fit.fit(verbose=True)  # No parameters at all\n",
    "                print(\"✓ Basic fitting successful!\")\n",
    "                return fit, galaxy\n",
    "            except Exception as e2:\n",
    "                print(f\"✗ Basic fitting also failed: {e2}\")\n",
    "        \n",
    "        print(f\"All fitting attempts failed.\")\n",
    "        return None, galaxy\n",
    "\n",
    "def extract_model_manually(fit, galaxy):\n",
    "    \"\"\"\n",
    "    Manually extract model spectrum by using BAGPIPES internal methods\n",
    "    \"\"\"\n",
    "    print(\"=== MANUAL MODEL EXTRACTION ===\")\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # Extract observed data\n",
    "    if hasattr(galaxy, 'photometry') and galaxy.photometry is not None:\n",
    "        data['obs_wavelengths'] = galaxy.photometry[:, 0]\n",
    "        data['obs_fluxes'] = galaxy.photometry[:, 1] \n",
    "        data['obs_errors'] = galaxy.photometry[:, 2]\n",
    "        print(f\"✓ Extracted {len(data['obs_wavelengths'])} photometry points\")\n",
    "    \n",
    "    # Extract posterior samples\n",
    "    if hasattr(fit.posterior, 'samples'):\n",
    "        data['posterior_samples'] = fit.posterior.samples\n",
    "        data['n_samples'] = len(next(iter(fit.posterior.samples.values())))\n",
    "        print(f\"✓ Extracted {data['n_samples']} posterior samples\")\n",
    "        print(f\"✓ Parameters: {list(fit.posterior.samples.keys())}\")\n",
    "    \n",
    "    # The key insight: samples2d likely contains pre-computed model predictions\n",
    "    # Let's figure out what each column represents\n",
    "    if hasattr(fit.posterior, 'samples2d'):\n",
    "        samples2d = fit.posterior.samples2d\n",
    "        print(f\"✓ samples2d shape: {samples2d.shape}\")\n",
    "        \n",
    "        # Common BAGPIPES samples2d structure:\n",
    "        # Could be [photometry, spectrum_wavelengths, spectrum_fluxes] or similar\n",
    "        # Let's check the ranges of each column to understand what they represent\n",
    "        \n",
    "        print(\"Analyzing samples2d columns:\")\n",
    "        for i in range(samples2d.shape[1]):\n",
    "            col_data = samples2d[:, i]\n",
    "            print(f\"  Column {i}: min={col_data.min():.3e}, max={col_data.max():.3e}, mean={col_data.mean():.3e}\")\n",
    "    \n",
    "    # Try to access the fitted model directly\n",
    "    if hasattr(fit, 'fitted_model'):\n",
    "        fitted_model = fit.fitted_model\n",
    "        print(f\"✓ fitted_model type: {type(fitted_model)}\")\n",
    "        \n",
    "        # Check what attributes it has\n",
    "        model_attrs = [attr for attr in dir(fitted_model) if not attr.startswith('_')]\n",
    "        print(f\"✓ fitted_model attributes: {model_attrs}\")\n",
    "        \n",
    "        # Common attributes to check\n",
    "        for attr in ['spectrum', 'photometry', 'wavelengths', 'spec_wavs', 'phot_wavs']:\n",
    "            if hasattr(fitted_model, attr):\n",
    "                value = getattr(fitted_model, attr)\n",
    "                if value is not None:\n",
    "                    if hasattr(value, 'shape'):\n",
    "                        print(f\"  {attr}: shape {value.shape}\")\n",
    "                        data[f'model_{attr}'] = value\n",
    "                    else:\n",
    "                        print(f\"  {attr}: {type(value)}\")\n",
    "    \n",
    "    # Try to access wavelength information\n",
    "    print(\"\\nLooking for wavelength grids...\")\n",
    "    wavelength_sources = [\n",
    "        ('fit.spec_wavs', getattr(fit, 'spec_wavs', None)),\n",
    "        ('galaxy.spec_wavs', getattr(galaxy, 'spec_wavs', None)),\n",
    "        ('fit.posterior.spec_wavs', getattr(fit.posterior, 'spec_wavs', None)),\n",
    "        ('galaxy.filter_set', getattr(galaxy, 'filter_set', None)),\n",
    "        ('galaxy.filt_list', getattr(galaxy, 'filt_list', None))\n",
    "    ]\n",
    "    \n",
    "    for name, value in wavelength_sources:\n",
    "        if value is not None:\n",
    "            if hasattr(value, '__len__'):\n",
    "                print(f\"  {name}: length {len(value)}\")\n",
    "                if 'wavs' in name:\n",
    "                    data['wavelength_grid'] = value\n",
    "            else:\n",
    "                print(f\"  {name}: {type(value)}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_custom_sed(data, percentiles=[16, 50, 84], figsize=(14, 8)):\n",
    "    \"\"\"\n",
    "    Create custom SED plot from extracted data with model spectrum\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot observed photometry\n",
    "    if 'obs_wavelengths' in data:\n",
    "        ax.errorbar(data['obs_wavelengths'], data['obs_fluxes'], \n",
    "                   yerr=data['obs_errors'], fmt='o', color='red', \n",
    "                   markersize=8, capsize=4, capthick=2, alpha=0.8,\n",
    "                   label='Observed Photometry', zorder=10)\n",
    "    \n",
    "    # Plot model spectrum\n",
    "    if 'model_spectrum' in data and 'model_wavelengths' in data:\n",
    "        ax.plot(data['model_wavelengths'], data['model_spectrum'], \n",
    "               color='navy', linewidth=2, alpha=0.8,\n",
    "               label='Model Spectrum (Median)', zorder=5)\n",
    "    \n",
    "    # Plot model photometry if available\n",
    "    if 'model_photometry' in data and 'obs_wavelengths' in data:\n",
    "        ax.plot(data['obs_wavelengths'], data['model_photometry'], \n",
    "               's', color='blue', markersize=6, alpha=0.7,\n",
    "               label='Model Photometry', zorder=8)\n",
    "    \n",
    "    ax.set_xlabel('Wavelength [Å]', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Flux [μJy]', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('SED with BAGPIPES Model Spectrum', fontsize=16, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_sed_with_uncertainty(fit, galaxy, percentiles=[16, 50, 84], figsize=(14, 8)):\n",
    "    \"\"\"\n",
    "    Plot SED with model spectrum uncertainty bands\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Extract basic data\n",
    "    data = extract_all_fit_data(fit, galaxy)\n",
    "    \n",
    "    # Plot observed photometry\n",
    "    if 'obs_wavelengths' in data:\n",
    "        ax.errorbar(data['obs_wavelengths'], data['obs_fluxes'], \n",
    "                   yerr=data['obs_errors'], fmt='o', color='red', \n",
    "                   markersize=8, capsize=4, capthick=2, alpha=0.8,\n",
    "                   label='Observed Photometry', zorder=10)\n",
    "    \n",
    "    # Get model spectrum with uncertainties\n",
    "    spectrum_data = get_model_spectrum_percentiles(fit, percentiles)\n",
    "    \n",
    "    if spectrum_data and 'wavelengths' in spectrum_data:\n",
    "        wavelengths = spectrum_data['wavelengths']\n",
    "        \n",
    "        if 'percentiles' in spectrum_data:\n",
    "            # Plot median\n",
    "            median_spec = spectrum_data['percentiles'][50]\n",
    "            ax.plot(wavelengths, median_spec, color='navy', linewidth=2,\n",
    "                   label='Model Spectrum (Median)', zorder=5)\n",
    "            \n",
    "            # Plot uncertainty bands\n",
    "            if 16 in spectrum_data['percentiles'] and 84 in spectrum_data['percentiles']:\n",
    "                lower_spec = spectrum_data['percentiles'][16]\n",
    "                upper_spec = spectrum_data['percentiles'][84]\n",
    "                \n",
    "                ax.fill_between(wavelengths, lower_spec, upper_spec,\n",
    "                               alpha=0.3, color='navy', \n",
    "                               label='68% Confidence', zorder=3)\n",
    "    \n",
    "    # Alternative: if direct model spectrum is available\n",
    "    elif 'model_spectrum' in data and 'model_wavelengths' in data:\n",
    "        ax.plot(data['model_wavelengths'], data['model_spectrum'], \n",
    "               color='navy', linewidth=2, alpha=0.8,\n",
    "               label='Model Spectrum', zorder=5)\n",
    "    \n",
    "    ax.set_xlabel('Wavelength [Å]', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Flux [μJy]', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('SED with Model Spectrum Uncertainties', fontsize=16, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_model_spectrum_from_samples(fit, galaxy, n_models=50):\n",
    "    \"\"\"\n",
    "    Generate model spectrum using posterior samples and BAGPIPES model\n",
    "    \"\"\"\n",
    "    print(\"=== GENERATING MODEL SPECTRUM FROM SAMPLES ===\")\n",
    "    \n",
    "    if not hasattr(fit.posterior, 'samples'):\n",
    "        print(\"No posterior samples available\")\n",
    "        return None\n",
    "    \n",
    "    samples = fit.posterior.samples\n",
    "    n_total = len(next(iter(samples.values())))\n",
    "    \n",
    "    # Get a subset of samples\n",
    "    indices = np.random.choice(n_total, min(n_models, n_total), replace=False)\n",
    "    \n",
    "    # Try to use the same wavelength grid as the fit\n",
    "    if hasattr(fit, 'spec_wavs') and fit.spec_wavs is not None:\n",
    "        wavelengths = fit.spec_wavs\n",
    "    elif hasattr(galaxy, 'spec_wavs') and galaxy.spec_wavs is not None:\n",
    "        wavelengths = galaxy.spec_wavs\n",
    "    else:\n",
    "        # Create a reasonable wavelength grid\n",
    "        wavelengths = np.logspace(np.log10(1000), np.log10(100000), 1000)\n",
    "        print(f\"Using default wavelength grid: {len(wavelengths)} points\")\n",
    "    \n",
    "    print(f\"Wavelength range: {wavelengths.min():.0f} - {wavelengths.max():.0f} Å\")\n",
    "    \n",
    "    # The key: we need to recreate the model using BAGPIPES\n",
    "    # This requires knowing your model setup (SFH, dust, etc.)\n",
    "    \n",
    "    # Let's try to access the fit instructions which contain the model setup\n",
    "    if hasattr(fit, 'fit_instructions'):\n",
    "        print(f\"Fit instructions: {fit.fit_instructions}\")\n",
    "        model_components = fit.fit_instructions\n",
    "    elif hasattr(fit.posterior, 'fit_instructions'):\n",
    "        print(f\"Fit instructions: {fit.posterior.fit_instructions}\")\n",
    "        model_components = fit.posterior.fit_instructions\n",
    "    else:\n",
    "        print(\"Could not find fit instructions\")\n",
    "        return None\n",
    "    \n",
    "    # Now we would need to recreate the BAGPIPES model\n",
    "    # This is complex and depends on your specific model setup\n",
    "    \n",
    "    print(\"To generate models, you would need to:\")\n",
    "    print(\"1. Import the appropriate BAGPIPES model classes\")\n",
    "    print(\"2. Recreate your model using the fit_instructions\")\n",
    "    print(\"3. Generate spectra for each parameter set\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def try_extract_from_posterior_methods(fit, galaxy):\n",
    "    \"\"\"\n",
    "    Try using posterior methods to get model predictions\n",
    "    \"\"\"\n",
    "    print(\"=== TRYING POSTERIOR METHODS ===\")\n",
    "    \n",
    "    posterior = fit.posterior\n",
    "    \n",
    "    # Check available methods\n",
    "    methods = [m for m in dir(posterior) if not m.startswith('_') and callable(getattr(posterior, m))]\n",
    "    print(f\"Available posterior methods: {methods}\")\n",
    "    \n",
    "    # Try predict method if available\n",
    "    if hasattr(posterior, 'predict'):\n",
    "        print(\"Trying posterior.predict()...\")\n",
    "        try:\n",
    "            # Get median parameters\n",
    "            samples = posterior.samples\n",
    "            median_params = {}\n",
    "            for param, values in samples.items():\n",
    "                median_params[param] = np.median(values)\n",
    "            \n",
    "            print(f\"Median parameters: {list(median_params.keys())}\")\n",
    "            \n",
    "            # Try to predict\n",
    "            prediction = posterior.predict(median_params)\n",
    "            print(f\"Prediction type: {type(prediction)}\")\n",
    "            \n",
    "            if hasattr(prediction, '__dict__'):\n",
    "                pred_attrs = [attr for attr in dir(prediction) if not attr.startswith('_')]\n",
    "                print(f\"Prediction attributes: {pred_attrs}\")\n",
    "                \n",
    "                # Look for spectrum/photometry\n",
    "                for attr in ['spectrum', 'photometry', 'sed']:\n",
    "                    if hasattr(prediction, attr):\n",
    "                        value = getattr(prediction, attr)\n",
    "                        if value is not None:\n",
    "                            print(f\"  {attr}: shape {getattr(value, 'shape', 'no shape')}\")\n",
    "                            return attr, value\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"predict() failed: {e}\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def plot_extracted_data(data, figsize=(14, 8)):\n",
    "    \"\"\"\n",
    "    Plot whatever data we managed to extract\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    plots_made = []\n",
    "    \n",
    "    # Plot observed photometry\n",
    "    if 'obs_wavelengths' in data:\n",
    "        ax.errorbar(data['obs_wavelengths'], data['obs_fluxes'], \n",
    "                   yerr=data['obs_errors'], fmt='o', color='red', \n",
    "                   markersize=8, capsize=4, capthick=2, alpha=0.8,\n",
    "                   label='Observed Photometry', zorder=10)\n",
    "        plots_made.append('observed_photometry')\n",
    "    \n",
    "    # Plot any model data we found\n",
    "    model_plotted = False\n",
    "    for key, value in data.items():\n",
    "        if key.startswith('model_') and value is not None:\n",
    "            if hasattr(value, 'shape'):\n",
    "                if len(value.shape) == 1:  # 1D array - could be spectrum\n",
    "                    if 'wavelength_grid' in data and len(value) == len(data['wavelength_grid']):\n",
    "                        ax.plot(data['wavelength_grid'], value, \n",
    "                               label=f'Model ({key})', linewidth=2)\n",
    "                        model_plotted = True\n",
    "                        plots_made.append(key)\n",
    "                    else:\n",
    "                        print(f\"Found {key} but no matching wavelength grid\")\n",
    "                elif len(value.shape) == 2:  # 2D array - could be multiple spectra\n",
    "                    if 'wavelength_grid' in data and value.shape[1] == len(data['wavelength_grid']):\n",
    "                        # Plot median and percentiles\n",
    "                        median_spec = np.median(value, axis=0)\n",
    "                        p16_spec = np.percentile(value, 16, axis=0)\n",
    "                        p84_spec = np.percentile(value, 84, axis=0)\n",
    "                        \n",
    "                        ax.plot(data['wavelength_grid'], median_spec, \n",
    "                               label=f'Model Median ({key})', linewidth=2)\n",
    "                        ax.fill_between(data['wavelength_grid'], p16_spec, p84_spec,\n",
    "                                       alpha=0.3, label=f'68% CI ({key})')\n",
    "                        model_plotted = True\n",
    "                        plots_made.append(key)\n",
    "    \n",
    "    if not model_plotted:\n",
    "        ax.text(0.05, 0.95, 'No model spectrum extracted\\nSee debug output for details', \n",
    "                transform=ax.transAxes, fontsize=12, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "                verticalalignment='top')\n",
    "    \n",
    "    ax.set_xlabel('Wavelength [Å]', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Flux [μJy]', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('Manual BAGPIPES Data Extraction', fontsize=16, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    print(f\"Plotted: {plots_made}\")\n",
    "    return fig, ax\n",
    "\n",
    "# Main extraction function\n",
    "def manual_bagpipes_analysis(fit, galaxy):\n",
    "    \"\"\"\n",
    "    Complete manual extraction workflow\n",
    "    \"\"\"\n",
    "    print(\"=== MANUAL BAGPIPES ANALYSIS ===\")\n",
    "    \n",
    "    # Step 1: Extract basic data\n",
    "    data = extract_model_manually(fit, galaxy)\n",
    "    \n",
    "    # Step 2: Try posterior methods\n",
    "    pred_type, pred_value = try_extract_from_posterior_methods(fit, galaxy)\n",
    "    if pred_value is not None:\n",
    "        data[f'model_{pred_type}'] = pred_value\n",
    "    \n",
    "\n",
    "\n",
    "def debug_fit_object(fit, galaxy):\n",
    "    \"\"\"\n",
    "    Debug function to explore what's actually in your fit object\n",
    "    \"\"\"\n",
    "    print(\"=== DEBUGGING FIT OBJECT ===\")\n",
    "    print(f\"fit type: {type(fit)}\")\n",
    "    print(f\"fit attributes: {dir(fit)}\")\n",
    "    \n",
    "    if hasattr(fit, 'posterior'):\n",
    "        print(f\"\\nfit.posterior type: {type(fit.posterior)}\")\n",
    "        print(f\"fit.posterior attributes: {dir(fit.posterior)}\")\n",
    "        \n",
    "        if hasattr(fit.posterior, 'samples2d'):\n",
    "            print(f\"\\nfit.posterior.samples2d type: {type(fit.posterior.samples2d)}\")\n",
    "            if isinstance(fit.posterior.samples2d, dict):\n",
    "                print(f\"fit.posterior.samples2d keys: {list(fit.posterior.samples2d.keys())}\")\n",
    "                for key in fit.posterior.samples2d.keys():\n",
    "                    print(f\"  {key}: shape {np.array(fit.posterior.samples2d[key]).shape}\")\n",
    "        \n",
    "        if hasattr(fit.posterior, 'model_galaxy'):\n",
    "            print(f\"\\nfit.posterior.model_galaxy type: {type(fit.posterior.model_galaxy)}\")\n",
    "            print(f\"fit.posterior.model_galaxy attributes: {dir(fit.posterior.model_galaxy)}\")\n",
    "    \n",
    "    print(f\"\\ngalaxy type: {type(galaxy)}\")\n",
    "    print(f\"galaxy attributes: {dir(galaxy)}\")\n",
    "    \n",
    "    # Look for any spectrum-related attributes\n",
    "    all_attrs = []\n",
    "    for obj_name, obj in [('fit', fit), ('galaxy', galaxy)]:\n",
    "        if hasattr(obj, 'posterior'):\n",
    "            all_attrs.extend([(f'{obj_name}.posterior', attr) for attr in dir(obj.posterior)])\n",
    "        all_attrs.extend([(obj_name, attr) for attr in dir(obj)])\n",
    "    \n",
    "    spectrum_attrs = [attr for attr in all_attrs if 'spec' in attr[1].lower()]\n",
    "    print(f\"\\nSpectrum-related attributes found: {spectrum_attrs}\")\n",
    "    \n",
    "def extract_all_fit_data(fit, galaxy):\n",
    "    \"\"\"\n",
    "    Extract all available data from BAGPIPES fit and galaxy objects\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fit : bagpipes fit object\n",
    "    galaxy : bagpipes galaxy object\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing all extracted data\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # Posterior samples\n",
    "    if hasattr(fit, 'posterior') and hasattr(fit.posterior, 'samples'):\n",
    "        data['posterior_samples'] = fit.posterior.samples\n",
    "        data['n_samples'] = len(next(iter(fit.posterior.samples.values())))\n",
    "        \n",
    "    # Observed data\n",
    "    if hasattr(galaxy, 'photometry'):\n",
    "        data['obs_wavelengths'] = galaxy.photometry[:, 0]\n",
    "        data['obs_fluxes'] = galaxy.photometry[:, 1]\n",
    "        data['obs_errors'] = galaxy.photometry[:, 2]\n",
    "        \n",
    "    if hasattr(galaxy, 'spectrum'):\n",
    "        data['spec_wavelengths'] = galaxy.spectrum[:, 0]\n",
    "        data['spec_fluxes'] = galaxy.spectrum[:, 1]\n",
    "        data['spec_errors'] = galaxy.spectrum[:, 2]\n",
    "\n",
    "    # Model spectrum from BAGPIPES - try multiple methods\n",
    "    print(\"Trying to extract model spectrum...\")\n",
    "    \n",
    "    if hasattr(fit, 'posterior'):\n",
    "        # Method 1: samples2d contains model spectra for each posterior sample\n",
    "        if hasattr(fit.posterior, 'samples2d') and 'spectrum' in fit.posterior.samples2d:\n",
    "            print(\"✓ Found model spectra in samples2d\")\n",
    "            all_spectra = fit.posterior.samples2d['spectrum']\n",
    "            data['model_spectrum_median'] = np.median(all_spectra, axis=0)\n",
    "            data['model_spectrum_16'] = np.percentile(all_spectra, 16, axis=0)\n",
    "            data['model_spectrum_84'] = np.percentile(all_spectra, 84, axis=0)\n",
    "            data['all_model_spectra'] = all_spectra\n",
    "            \n",
    "        # Method 2: Direct model galaxy spectrum (median model)\n",
    "        elif hasattr(fit.posterior, 'model_galaxy'):\n",
    "            print(\"✓ Found model_galaxy\")\n",
    "            if hasattr(fit.posterior.model_galaxy, 'spectrum'):\n",
    "                data['model_spectrum_median'] = fit.posterior.model_galaxy.spectrum\n",
    "                \n",
    "        # Method 3: Try accessing through fit object directly\n",
    "        elif hasattr(fit, 'model_galaxy'):\n",
    "            print(\"✓ Found model_galaxy in fit object\")\n",
    "            if hasattr(fit.model_galaxy, 'spectrum'):\n",
    "                data['model_spectrum_median'] = fit.model_galaxy.spectrum\n",
    "                \n",
    "        # Get wavelength grid - try multiple sources\n",
    "        if hasattr(fit, 'spec_wavs'):\n",
    "            data['model_wavelengths'] = fit.spec_wavs\n",
    "            print(\"✓ Got wavelengths from fit.spec_wavs\")\n",
    "        elif hasattr(galaxy, 'spec_wavs'):\n",
    "            data['model_wavelengths'] = galaxy.spec_wavs  \n",
    "            print(\"✓ Got wavelengths from galaxy.spec_wavs\")\n",
    "        elif hasattr(fit.posterior, 'spec_wavs'):\n",
    "            data['model_wavelengths'] = fit.posterior.spec_wavs\n",
    "            print(\"✓ Got wavelengths from fit.posterior.spec_wavs\")\n",
    "        else:\n",
    "            print(\"⚠ Could not find wavelength grid\")\n",
    "            \n",
    "        # Get model photometry\n",
    "        if hasattr(fit.posterior, 'samples2d') and 'photometry' in fit.posterior.samples2d:\n",
    "            all_phot = fit.posterior.samples2d['photometry']\n",
    "            data['model_photometry'] = np.median(all_phot, axis=0)\n",
    "            print(\"✓ Got model photometry from samples2d\")\n",
    "        elif hasattr(fit.posterior, 'model_galaxy') and hasattr(fit.posterior.model_galaxy, 'photometry'):\n",
    "            data['model_photometry'] = fit.posterior.model_galaxy.photometry\n",
    "            print(\"✓ Got model photometry from model_galaxy\")\n",
    "            \n",
    "    # Fit statistics\n",
    "    if hasattr(fit, 'posterior'):\n",
    "        if hasattr(fit.posterior, 'lnz'):\n",
    "            data['log_evidence'] = fit.posterior.lnz\n",
    "        if hasattr(fit.posterior, 'lnz_err'):\n",
    "            data['log_evidence_err'] = fit.posterior.lnz_err\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_model_spectrum_percentiles(fit, percentiles=[16, 50, 84]):\n",
    "    \"\"\"\n",
    "    Extract model spectrum percentiles from BAGPIPES posterior samples\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fit : bagpipes fit object\n",
    "    percentiles : list of percentiles to calculate\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with wavelengths and spectrum percentiles\n",
    "    \"\"\"\n",
    "    \n",
    "    spectrum_data = {}\n",
    "    \n",
    "    # Try different methods to get model spectra from posterior\n",
    "    if hasattr(fit, 'posterior'):\n",
    "        \n",
    "        # Method 1: samples2d contains all model spectra\n",
    "        if hasattr(fit.posterior, 'samples2d') and 'spectrum' in fit.posterior.samples2d:\n",
    "            spectra = fit.posterior.samples2d['spectrum']\n",
    "            \n",
    "            # Calculate percentiles\n",
    "            spectrum_percentiles = np.percentile(spectra, percentiles, axis=0)\n",
    "            spectrum_data['percentiles'] = dict(zip(percentiles, spectrum_percentiles))\n",
    "            \n",
    "            # Get wavelength grid\n",
    "            if hasattr(fit, 'spec_wavs'):\n",
    "                spectrum_data['wavelengths'] = fit.spec_wavs\n",
    "            elif hasattr(fit.posterior, 'spec_wavs'):\n",
    "                spectrum_data['wavelengths'] = fit.posterior.spec_wavs\n",
    "                \n",
    "        # Method 2: Generate model spectra from parameter samples\n",
    "        elif hasattr(fit.posterior, 'samples'):\n",
    "            print(\"Generating model spectra from parameter samples...\")\n",
    "            # This would require calling BAGPIPES model generation\n",
    "            # which is more complex - see alternative approach below\n",
    "            \n",
    "    return spectrum_data\n",
    "\n",
    "def plot_custom_sed(data, percentiles=[16, 50, 84], figsize=(14, 8)):\n",
    "    \"\"\"\n",
    "    Create custom SED plot from extracted data with model spectrum\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot observed photometry\n",
    "    if 'obs_wavelengths' in data:\n",
    "        ax.errorbar(data['obs_wavelengths'], data['obs_fluxes'], \n",
    "                   yerr=data['obs_errors'], fmt='o', color='red', \n",
    "                   markersize=8, capsize=4, capthick=2, alpha=0.8,\n",
    "                   label='Observed Photometry', zorder=10)\n",
    "    \n",
    "    # Plot model spectrum\n",
    "    if 'model_spectrum' in data and 'model_wavelengths' in data:\n",
    "        ax.plot(data['model_wavelengths'], data['model_spectrum'], \n",
    "               color='navy', linewidth=2, alpha=0.8,\n",
    "               label='Model Spectrum (Median)', zorder=5)\n",
    "    \n",
    "    # Plot model photometry if available\n",
    "    if 'model_photometry' in data and 'obs_wavelengths' in data:\n",
    "        ax.plot(data['obs_wavelengths'], data['model_photometry'], \n",
    "               's', color='blue', markersize=6, alpha=0.7,\n",
    "               label='Model Photometry', zorder=8)\n",
    "    \n",
    "    ax.set_xlabel('Wavelength [Å]', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Flux [μJy]', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('SED with BAGPIPES Model Spectrum', fontsize=16, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_sed_with_uncertainty(fit, galaxy, percentiles=[16, 50, 84], figsize=(14, 8)):\n",
    "    \"\"\"\n",
    "    Plot SED with model spectrum uncertainty bands\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Extract basic data\n",
    "    data = extract_all_fit_data(fit, galaxy)\n",
    "    \n",
    "    # Plot observed photometry\n",
    "    if 'obs_wavelengths' in data:\n",
    "        ax.errorbar(data['obs_wavelengths'], data['obs_fluxes'], \n",
    "                   yerr=data['obs_errors'], fmt='o', color='red', \n",
    "                   markersize=8, capsize=4, capthick=2, alpha=0.8,\n",
    "                   label='Observed Photometry', zorder=10)\n",
    "    \n",
    "    # Get model spectrum with uncertainties\n",
    "    spectrum_data = get_model_spectrum_percentiles(fit, percentiles)\n",
    "    \n",
    "    if spectrum_data and 'wavelengths' in spectrum_data:\n",
    "        wavelengths = spectrum_data['wavelengths']\n",
    "        \n",
    "        if 'percentiles' in spectrum_data:\n",
    "            # Plot median\n",
    "            median_spec = spectrum_data['percentiles'][50]\n",
    "            ax.plot(wavelengths, median_spec, color='navy', linewidth=2,\n",
    "                   label='Model Spectrum (Median)', zorder=5)\n",
    "            \n",
    "            # Plot uncertainty bands\n",
    "            if 16 in spectrum_data['percentiles'] and 84 in spectrum_data['percentiles']:\n",
    "                lower_spec = spectrum_data['percentiles'][16]\n",
    "                upper_spec = spectrum_data['percentiles'][84]\n",
    "                \n",
    "                ax.fill_between(wavelengths, lower_spec, upper_spec,\n",
    "                               alpha=0.3, color='navy', \n",
    "                               label='68% Confidence', zorder=3)\n",
    "    \n",
    "    # Alternative: if direct model spectrum is available\n",
    "    elif 'model_spectrum' in data and 'model_wavelengths' in data:\n",
    "        ax.plot(data['model_wavelengths'], data['model_spectrum'], \n",
    "               color='navy', linewidth=2, alpha=0.8,\n",
    "               label='Model Spectrum', zorder=5)\n",
    "    \n",
    "    ax.set_xlabel('Wavelength [Å]', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Flux [μJy]', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('SED with Model Spectrum Uncertainties', fontsize=16, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_spectrum_residuals(fit, galaxy, figsize=(14, 10)):\n",
    "    \"\"\"\n",
    "    Plot SED with residuals panel\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, \n",
    "                                   height_ratios=[3, 1], sharex=True)\n",
    "    \n",
    "    # Extract data\n",
    "    data = extract_all_fit_data(fit, galaxy)\n",
    "    \n",
    "    # Main SED plot\n",
    "    if 'obs_wavelengths' in data:\n",
    "        ax1.errorbar(data['obs_wavelengths'], data['obs_fluxes'], \n",
    "                    yerr=data['obs_errors'], fmt='o', color='red', \n",
    "                    markersize=8, capsize=4, capthick=2, alpha=0.8,\n",
    "                    label='Observed Photometry', zorder=10)\n",
    "    \n",
    "    # Model spectrum\n",
    "    if 'model_spectrum' in data and 'model_wavelengths' in data:\n",
    "        ax1.plot(data['model_wavelengths'], data['model_spectrum'], \n",
    "                color='navy', linewidth=2, alpha=0.8,\n",
    "                label='Model Spectrum', zorder=5)\n",
    "    \n",
    "    # Model photometry for residuals\n",
    "    if 'model_photometry' in data and 'obs_wavelengths' in data:\n",
    "        ax1.plot(data['obs_wavelengths'], data['model_photometry'], \n",
    "                's', color='blue', markersize=6, alpha=0.7,\n",
    "                label='Model Photometry', zorder=8)\n",
    "        \n",
    "        # Residuals\n",
    "        residuals = (data['obs_fluxes'] - data['model_photometry']) / data['obs_errors']\n",
    "        ax2.errorbar(data['obs_wavelengths'], residuals, \n",
    "                    yerr=np.ones_like(residuals), fmt='o', color='darkred',\n",
    "                    markersize=6, capsize=3, alpha=0.8)\n",
    "        ax2.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "        ax2.set_ylabel('Residuals (σ)', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax1.set_ylabel('Flux [μJy]', fontsize=14, fontweight='bold')\n",
    "    ax1.set_title('SED with Model Spectrum and Residuals', fontsize=16, fontweight='bold')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(fontsize=12)\n",
    "    \n",
    "    ax2.set_xlabel('Wavelength [Å]', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, (ax1, ax2)\n",
    "\n",
    "\n",
    "\n",
    "def plot_custom_corner(data, params=None, figsize=(15, 15)):\n",
    "    \"\"\"\n",
    "    Create custom corner plot from posterior samples\n",
    "    \"\"\"\n",
    "    \n",
    "    samples = data['posterior_samples']\n",
    "    \n",
    "    if params is None:\n",
    "        # Use common parameters\n",
    "        params = ['age', 'tau', 'massformed', 'metallicity', 'Av', 'stellar_mass']\n",
    "        params = [p for p in params if p in samples]\n",
    "    \n",
    "    n_params = len(params)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_params, n_params, figsize=figsize)\n",
    "    fig.suptitle('Custom Parameter Corner Plot', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    for i, param_y in enumerate(params):\n",
    "        for j, param_x in enumerate(params):\n",
    "            ax = axes[i, j]\n",
    "            \n",
    "            if i == j:\n",
    "                # Diagonal: 1D histograms\n",
    "                ax.hist(samples[param_x], bins=50, alpha=0.7, \n",
    "                       density=True, color='skyblue', edgecolor='black')\n",
    "                \n",
    "                # Add median and confidence intervals\n",
    "                median_val = np.median(samples[param_x])\n",
    "                conf_16 = np.percentile(samples[param_x], 16)\n",
    "                conf_84 = np.percentile(samples[param_x], 84)\n",
    "                \n",
    "                ax.axvline(median_val, color='red', linestyle='--', linewidth=2)\n",
    "                ax.axvline(conf_16, color='orange', linestyle=':', alpha=0.8)\n",
    "                ax.axvline(conf_84, color='orange', linestyle=':', alpha=0.8)\n",
    "                ax.set_ylabel('Density')\n",
    "                \n",
    "            elif i > j:\n",
    "                # Lower triangle: 2D scatter/contour plots\n",
    "                ax.scatter(samples[param_x], samples[param_y], \n",
    "                          alpha=0.3, s=1, color='navy')\n",
    "                \n",
    "                # Add contours\n",
    "                try:\n",
    "                    # Create 2D histogram for contours\n",
    "                    H, xedges, yedges = np.histogram2d(samples[param_x], samples[param_y], bins=30)\n",
    "                    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "                    ax.contour(H.T, extent=extent, colors='red', alpha=0.8, levels=3)\n",
    "                except ImportError:\n",
    "                    pass\n",
    "                \n",
    "            else:\n",
    "                # Upper triangle: hide\n",
    "                ax.set_visible(False)\n",
    "            \n",
    "            # Set labels\n",
    "            if i == n_params - 1:\n",
    "                ax.set_xlabel(param_x, fontsize=12)\n",
    "            if j == 0 and i > 0:\n",
    "                ax.set_ylabel(param_y, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def plot_custom_sfh(data, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Create custom star formation history plot\n",
    "    \"\"\"\n",
    "    \n",
    "    samples = data['posterior_samples']\n",
    "    \n",
    "    # This requires knowing how BAGPIPES encodes SFH\n",
    "    # For exponential declining SFH: SFR(t) = SFR_0 * exp(-t/tau)\n",
    "    \n",
    "    if 'tau' not in samples or 'massformed' not in samples:\n",
    "        print(\"Need tau and massformed parameters for SFH plot\")\n",
    "        return None, None\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Time array (lookback time)\n",
    "    age_universe = 13.8  # Gyr\n",
    "    time = np.linspace(0.01, age_universe, 1000)\n",
    "    \n",
    "    # Calculate SFH for a subset of posterior samples\n",
    "    n_plot = min(100, len(samples['tau']))\n",
    "    indices = np.random.choice(len(samples['tau']), n_plot, replace=False)\n",
    "    \n",
    "    sfh_curves = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        tau = samples['tau'][idx]\n",
    "        massformed = 10**samples['massformed'][idx]  # Convert from log\n",
    "        \n",
    "        if 'age' in samples:\n",
    "            age = samples['age'][idx]\n",
    "            # Only show SFH up to galaxy age\n",
    "            time_gal = time[time <= age]\n",
    "        else:\n",
    "            time_gal = time\n",
    "        \n",
    "        # Exponential declining SFH\n",
    "        if tau > 0:\n",
    "            sfr = (massformed / tau) * np.exp(-time_gal / tau)\n",
    "        else:\n",
    "            sfr = np.zeros_like(time_gal)\n",
    "        \n",
    "        sfh_curves.append(sfr)\n",
    "        ax.plot(time_gal, sfr, alpha=0.1, color='blue')\n",
    "    \n",
    "    # Plot median SFH\n",
    "    if sfh_curves:\n",
    "        sfh_array = np.array(sfh_curves)\n",
    "        median_sfh = np.median(sfh_array, axis=0)\n",
    "        ax.plot(time_gal, median_sfh, color='red', linewidth=3, \n",
    "               label='Median SFH')\n",
    "    \n",
    "    ax.set_xlabel('Lookback Time [Gyr]', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('SFR [M☉/yr]', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('Custom Star Formation History', fontsize=16, fontweight='bold')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Example usage - keeping your original workflow:\n",
    "def analyze_fit_custom(fit, galaxy):\n",
    "    \"\"\"\n",
    "    Complete custom analysis workflow\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Extracting all data from fit...\")\n",
    "    data = extract_all_fit_data(fit, galaxy)\n",
    "    \n",
    "    print(f\"Found {data.get('n_samples', 0)} posterior samples\")\n",
    "    print(f\"Available parameters: {list(data.get('posterior_samples', {}).keys())}\")\n",
    "    \n",
    "    # Check what model data we extracted\n",
    "    if 'model_spectrum_median' in data:\n",
    "        print(\"✓ Model spectrum extracted successfully\")\n",
    "    if 'model_photometry' in data:\n",
    "        print(\"✓ Model photometry extracted successfully\")\n",
    "    if 'model_wavelengths' in data:\n",
    "        print(f\"✓ Wavelength grid: {len(data['model_wavelengths'])} points\")\n",
    "    \n",
    "    # Create all custom plots\n",
    "    print(\"\\nCreating custom plots...\")\n",
    "    \n",
    "    # SED plot\n",
    "    fig_sed, ax_sed = plot_custom_sed(data)\n",
    "    plt.savefig('custom_sed.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Corner plot\n",
    "    fig_corner, axes_corner = plot_custom_corner(data)\n",
    "    plt.savefig('custom_corner.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # SFH plot\n",
    "    fig_sfh, ax_sfh = plot_custom_sfh(data)\n",
    "    if fig_sfh:\n",
    "        plt.savefig('custom_sfh.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # Parameter evolution\n",
    "    if 'stellar_mass' in data['posterior_samples']:\n",
    "        fig_trace, axes_trace = plot_parameter_evolution(data, 'stellar_mass')\n",
    "        plt.savefig('custom_trace.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # Summary plot\n",
    "    fig_summary = create_custom_summary_plot(data)\n",
    "    plt.savefig('custom_summary.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"All custom plots created!\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Set MNRAS-compliant figure parameters\n",
    "def set_mnras_style():\n",
    "    \"\"\"Set matplotlib parameters for MNRAS-compliant figures\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'font.family': 'serif',\n",
    "        'font.serif': ['Times', 'Times New Roman', 'DejaVu Serif'],\n",
    "        'mathtext.fontset': 'dejavuserif',\n",
    "        'axes.linewidth': 2.5,\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.7,\n",
    "        'grid.linestyle': '--',\n",
    "        'grid.linewidth': 0.8,\n",
    "        'xtick.major.size': 8,\n",
    "        'xtick.minor.size': 4,\n",
    "        'ytick.major.size': 8,\n",
    "        'ytick.minor.size': 4,\n",
    "        'xtick.major.width': 2.0,\n",
    "        'xtick.minor.width': 1.5,\n",
    "        'ytick.major.width': 2.0,\n",
    "        'ytick.minor.width': 1.5,\n",
    "        'xtick.direction': 'in',\n",
    "        'ytick.direction': 'in',\n",
    "        'xtick.top': True,\n",
    "        'ytick.right': True,\n",
    "        'legend.frameon': True,\n",
    "        'legend.fancybox': True,\n",
    "        'legend.edgecolor': 'black',\n",
    "        'legend.facecolor': 'white',\n",
    "        'legend.framealpha': 1.0\n",
    "    })\n",
    "\n",
    "# Color scheme (same as your original code)\n",
    "colors = {\n",
    "    '025_035': \"#a714ff\",  # Purple (deep/cool)\n",
    "    '035_045': \"#ff14f5\",  # Pink\n",
    "    '045_055': \"#14D8FF\",  # Teal\n",
    "    '055_065': \"#60B5FF\",  # Blue\n",
    "    '065_075': \"#00FF9C\",  # Green\n",
    "    '075_085': \"#ffbb14\",  # Orange\n",
    "    '085_096': \"#FF5757\"   # Red (warm)\n",
    "}\n",
    "\n",
    "# Convert to list for easy indexing\n",
    "color_list = list(colors.values())\n",
    "\n",
    "def customize_sfh_plot(fig):\n",
    "    \"\"\"Customize the star formation history plot with MNRAS style\"\"\"\n",
    "    # Handle case where Bagpipes returns a tuple (fig, axes)\n",
    "    if isinstance(fig, tuple):\n",
    "        fig, axes = fig\n",
    "        if not isinstance(axes, list):\n",
    "            axes = [axes]\n",
    "    else:\n",
    "        axes = fig.get_axes()\n",
    "    \n",
    "    # Apply MNRAS styling to all axes\n",
    "    for ax in axes:\n",
    "        # Configure spines\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(2.5)\n",
    "        \n",
    "        # Configure ticks\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12,\n",
    "                      length=8, width=2.0, direction='in')\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=10,\n",
    "                      length=4, width=1.5, direction='in')\n",
    "        ax.tick_params(top=True, right=True)\n",
    "        ax.minorticks_on()\n",
    "        \n",
    "        # Configure grid\n",
    "        ax.grid(visible=True, which='both', axis='both', \n",
    "                linestyle='--', alpha=0.7, zorder=-10)\n",
    "        \n",
    "        # Update fill/patch colors if present\n",
    "        patches = ax.patches\n",
    "        if patches:\n",
    "            for i, patch in enumerate(patches):\n",
    "                if i < len(color_list):\n",
    "                    patch.set_facecolor(color_list[i % len(color_list)])\n",
    "                    patch.set_alpha(0.7)\n",
    "                    patch.set_edgecolor('black')\n",
    "                    patch.set_linewidth(1.0)\n",
    "        \n",
    "        # Update line colors\n",
    "        lines = ax.get_lines()\n",
    "        if lines:\n",
    "            for i, line in enumerate(lines):\n",
    "                if i < len(color_list):\n",
    "                    line.set_color(color_list[i % len(color_list)])\n",
    "                    line.set_linewidth(2.5)\n",
    "        \n",
    "        # Update labels\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=14, color=\"black\")\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontsize=14, color=\"black\")\n",
    "        \n",
    "        # Update legend if present\n",
    "        legend = ax.get_legend()\n",
    "        if legend:\n",
    "            legend.set_frame_on(True)\n",
    "            legend.get_frame().set_linewidth(1.5)\n",
    "            legend.get_frame().set_edgecolor('black')\n",
    "            legend.get_frame().set_facecolor('white')\n",
    "            legend.get_frame().set_alpha(1.0)\n",
    "    \n",
    "    # Set figure background\n",
    "    fig.patch.set_facecolor('white')\n",
    "    try:\n",
    "        plt.tight_layout(pad=0.5)\n",
    "    except:\n",
    "        # If tight_layout fails, just adjust margins manually\n",
    "        plt.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def customize_corner_plot(fig):\n",
    "    \"\"\"Customize the corner plot with MNRAS style\"\"\"\n",
    "    \n",
    "    # Create custom pink colormap\n",
    "    colors = ['white', '#a714ff', '#14D8FF', '#60B5FF', '#00FF9C', '#F5F5F5']\n",
    "    pink_cmap = LinearSegmentedColormap.from_list('custom_pink', colors, N=256)\n",
    "    \n",
    "    # Handle case where Bagpipes returns a tuple (fig, axes)\n",
    "    if isinstance(fig, tuple):\n",
    "        fig, axes = fig\n",
    "        if isinstance(axes, np.ndarray):\n",
    "            axes = axes.flatten()\n",
    "        elif not isinstance(axes, list):\n",
    "            axes = [axes]\n",
    "    else:\n",
    "        axes = fig.get_axes()\n",
    "    \n",
    "    # Legend elements\n",
    "    legend_elements = []\n",
    "    legend_added = False\n",
    "    \n",
    "    # Get all axes from the corner plot\n",
    "    for ax in axes:\n",
    "        # Configure spines\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(2.5)\n",
    "        \n",
    "        # Configure ticks\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10,\n",
    "                      length=6, width=1.5, direction='in')\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=8,\n",
    "                      length=3, width=1.0, direction='in')\n",
    "        ax.tick_params(top=True, right=True)\n",
    "        ax.minorticks_on()\n",
    "        \n",
    "        # Remove scientific notation offset\n",
    "        try:\n",
    "            ax.ticklabel_format(style='plain', useOffset=False)\n",
    "        except AttributeError:\n",
    "            # Skip if formatter doesn't support this (e.g., NullFormatter)\n",
    "            pass\n",
    "        \n",
    "        # Additional approach: directly set formatters to avoid offset notation\n",
    "        try:\n",
    "            # Set custom formatter for x-axis\n",
    "            if ax.xaxis.get_major_formatter().__class__.__name__ != 'NullFormatter':\n",
    "                formatter_x = ScalarFormatter(useOffset=False)\n",
    "                formatter_x.set_scientific(False)\n",
    "                ax.xaxis.set_major_formatter(formatter_x)\n",
    "            \n",
    "            # Set custom formatter for y-axis\n",
    "            if ax.yaxis.get_major_formatter().__class__.__name__ != 'NullFormatter':\n",
    "                formatter_y = ScalarFormatter(useOffset=False)\n",
    "                formatter_y.set_scientific(False)\n",
    "                ax.yaxis.set_major_formatter(formatter_y)\n",
    "        except:\n",
    "            # If setting formatters fails, continue anyway\n",
    "            pass\n",
    "        \n",
    "        # Check if this is a 2D contour plot (has collections) or 1D histogram (has patches)\n",
    "        is_contour_plot = len(ax.collections) > 0\n",
    "        is_histogram_plot = len(ax.patches) > 0\n",
    "        \n",
    "        if is_contour_plot:\n",
    "            # For 2D contour plots - very light, barely visible grid\n",
    "            ax.grid(visible=True, which='major', axis='both', \n",
    "                    linestyle='-', alpha=0.5, color='black', linewidth=0.3, zorder=-10)\n",
    "        elif is_histogram_plot:\n",
    "            # For 1D histogram plots - original style\n",
    "            ax.grid(visible=True, which='major', axis='both', \n",
    "                    linestyle='--', alpha=0.7, color='gray', linewidth=0.8, zorder=-10)\n",
    "        else:\n",
    "            # Default grid for other plots\n",
    "            ax.grid(visible=True, which='major', axis='both', \n",
    "                    linestyle='--', alpha=0.2, color='gray', zorder=-10)\n",
    "        \n",
    "        # Update contour colors if present (for 2D plots)\n",
    "        collections = ax.collections\n",
    "        if collections:\n",
    "            for i, collection in enumerate(collections):\n",
    "                # Apply custom pink colormap to filled contours\n",
    "                if hasattr(collection, 'set_cmap'):\n",
    "                    collection.set_cmap(pink_cmap)\n",
    "                elif hasattr(collection, 'set_facecolor'):\n",
    "                    # Fallback: use pink shades if colormap doesn't work\n",
    "                    pink_colors = ['#FFB3DA', '#FF80C1', '#FF4DA8']\n",
    "                    color = pink_colors[min(i, len(pink_colors)-1)]\n",
    "                    collection.set_facecolor(color)\n",
    "                    if i == 0:  # Innermost contour (highest confidence)\n",
    "                        collection.set_alpha(0.8)\n",
    "                    elif i == 1:  # Middle contour\n",
    "                        collection.set_alpha(0.6)\n",
    "                    else:  # Outer contours\n",
    "                        collection.set_alpha(0.4)\n",
    "                \n",
    "                ## Set contour line edges to blue\n",
    "                #if hasattr(collection, 'set_edgecolor'):\n",
    "                #    collection.set_edgecolor('grey')\n",
    "                #    collection.set_linewidth(1.0)\n",
    "                #    collection.set_alpha(1.0)\n",
    "        \n",
    "        # Update line colors for percentile lines\n",
    "        lines = ax.get_lines()\n",
    "        if lines:\n",
    "            for i, line in enumerate(lines):\n",
    "                if i == 0:  # Median line\n",
    "                    line.set_color(\"black\")\n",
    "                    line.set_linewidth(2.5)\n",
    "                elif i == 1:  # 1-sigma line\n",
    "                    line.set_color(color_list[1])\n",
    "                    line.set_linewidth(2.0)\n",
    "                    line.set_linestyle(\":\")\n",
    "                elif i == 2:  # 2-sigma line\n",
    "                    line.set_color(color_list[1])\n",
    "                    line.set_linewidth(1.5)\n",
    "                    line.set_linestyle(\"--\")\n",
    "                else:  # Additional lines\n",
    "                    line.set_color(color_list[1])\n",
    "                    line.set_linewidth(1.0)\n",
    "                    line.set_linestyle(\"-.\")\n",
    "        \n",
    "        # Update labels (only for edge plots)\n",
    "        if ax.get_xlabel():\n",
    "            ax.set_xlabel(ax.get_xlabel(), fontsize=12, color=\"black\")\n",
    "        if ax.get_ylabel():\n",
    "            ax.set_ylabel(ax.get_ylabel(), fontsize=12, color=\"black\")\n",
    "    \n",
    "    ## Add legend\n",
    "    #if not legend_added:\n",
    "    #    legend_elements = [\n",
    "    #        mlines.Line2D([], [], color='black', linewidth=2.5, label='Median'),\n",
    "    #        mlines.Line2D([], [], color=color_list[1], linewidth=2.0, linestyle=':', label=r'1$\\sigma$ bounds'),\n",
    "    #        mlines.Line2D([], [], color=color_list[1], linewidth=1.5, linestyle='--', label=r'2$\\sigma$ bounds'),\n",
    "    #        mlines.Line2D([], [], color=color_list[1], linewidth=1.5, linestyle='-.', label=r'3$\\sigma$ bounds')\n",
    "    #    ]\n",
    "    #    fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98), \n",
    "    #              fontsize=12, frameon=True, fancybox=True, shadow=True,\n",
    "    #              framealpha=0.9, facecolor='white', edgecolor='black')\n",
    "    #\n",
    "    # Set figure background\n",
    "    fig.patch.set_facecolor('white')\n",
    "    try:\n",
    "        plt.tight_layout(pad=0.3)\n",
    "    except:\n",
    "        # If tight_layout fails, just adjust margins manually\n",
    "        plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def auto_axis_label(ax, y_scale, z_non_zero=True, log_x=False):\n",
    "    # Fixed: Removed extra closing brace after \\AA\n",
    "    ax.set_xlabel(r\"Observed Wavelength [$\\AA$]\")  # Updated for linear scale\n",
    "    ax.set_ylabel(r\"f$_{\\lambda}$ / 10$^{\" + str(y_scale) + r\"}$ erg s$^{-1}$ A$^{-1}$\")\n",
    "\n",
    "\n",
    "def add_spectrum(spectrum, ax, y_scale=None, color=\"red\", zorder=4):\n",
    "    \"\"\" Add spectrum data to the axes with linear wavelength scale. \"\"\"\n",
    "    # Calculate y_scale if not provided\n",
    "    \n",
    "    if not y_scale:\n",
    "        ymax = 1.05*np.max(spectrum[:, 1])\n",
    "        y_scale = int(np.log10(ymax))-1\n",
    "    \n",
    "    # Plot spectrum with linear wavelength (no log conversion)\n",
    "    ax.plot(spectrum[:, 0], spectrum[:, 1]*10**-y_scale, \n",
    "            color=color, zorder=zorder, linewidth=1)\n",
    "    \n",
    "    # Add error bars if available\n",
    "    if spectrum.shape[1] > 2:\n",
    "        ax.fill_between(spectrum[:, 0], \n",
    "                       (spectrum[:, 1] - spectrum[:, 2])*10**-y_scale,\n",
    "                       (spectrum[:, 1] + spectrum[:, 2])*10**-y_scale,\n",
    "                       alpha=0.3, color=color, zorder=zorder-1)\n",
    "    \n",
    "    # Ensure linear scale\n",
    "    ax.set_xscale('linear')\n",
    "    auto_axis_label(ax, y_scale, log_x=False)\n",
    "    \n",
    "    return y_scale\n",
    "\n",
    "\n",
    "def add_observed_photometry(galaxy, ax, std):\n",
    "    \"\"\" Add observed photometry data to the axes. \"\"\"\n",
    "    photometry = np.copy(galaxy.photometry)\n",
    "    mask = (photometry[:, 1] > 0.)\n",
    "    ymax = 1.05*np.nanmax((photometry[:, 1]+photometry[:, 2])[mask])\n",
    "    y_scale = int(np.log10(ymax))-1\n",
    "    \n",
    "    # Plot with linear wavelength scale\n",
    "    ax.scatter(photometry[:, 0], photometry[:, 1]*10**-y_scale, color='#60B5FF', zorder=10)\n",
    "    \n",
    "    ax.errorbar(photometry[:, 0], photometry[:, 1]*10**-y_scale, linestyle=\"\",\n",
    "                yerr=std, color='black', capsize=3, markersize=6, zorder=9)\n",
    "    \n",
    "    # Ensure linear scale\n",
    "    ax.set_xscale('linear')\n",
    "    auto_axis_label(ax, y_scale, log_x=False)\n",
    "    \n",
    "    return y_scale\n",
    "\n",
    "\n",
    "def add_rest_wavelength_axis(ax, redshift):\n",
    "    \"\"\"Add a rest wavelength axis on top of the observed wavelength axis.\"\"\"\n",
    "    # Create a secondary x-axis on top\n",
    "    ax2 = ax.twiny()\n",
    "    \n",
    "    # Get the observed wavelength limits\n",
    "    obs_xlim = ax.get_xlim()\n",
    "    \n",
    "    # Convert to rest wavelength\n",
    "    rest_xlim = [obs_xlim[0] / (1 + redshift), obs_xlim[1] / (1 + redshift)]\n",
    "    ax2.set_xlim(rest_xlim)\n",
    "    \n",
    "    # Set appropriate tick locations for rest wavelength\n",
    "    rest_ticks = np.linspace(rest_xlim[0], rest_xlim[1], 6)\n",
    "    ax2.set_xticks(rest_ticks)\n",
    "    ax2.set_xlabel(r\"Rest Wavelength [$\\AA$]\")\n",
    "    \n",
    "    return ax2\n",
    "\n",
    "\n",
    "def plot_galaxy(galaxy, std, show=True, return_y_scale=False, y_scale_spec=None):\n",
    "    \"\"\" Make a quick plot of the data loaded into a galaxy object. \"\"\"\n",
    "    naxes = 1\n",
    "    if (galaxy.photometry_exists and galaxy.spectrum_exists):\n",
    "        naxes = 2\n",
    "    y_scale = []\n",
    "    axes = []  # Initialize axes as empty list\n",
    "    fig = plt.figure(figsize=(12, 4.*naxes))\n",
    "    gs = mpl.gridspec.GridSpec(naxes, 1, hspace=0.3)\n",
    "    \n",
    "    # Add observed spectroscopy to plot\n",
    "    if galaxy.spectrum_exists:\n",
    "        spec_ax = plt.subplot(gs[0, 0])\n",
    "        y_scale_spec = add_spectrum(galaxy.spectrum, spec_ax,\n",
    "                                    y_scale=y_scale_spec)\n",
    "        if galaxy.photometry_exists:\n",
    "            add_observed_photometry_linear(galaxy, spec_ax, standard_deviation,\n",
    "                                           y_scale=y_scale_spec)\n",
    "        axes.append(spec_ax)\n",
    "        y_scale.append(y_scale_spec)\n",
    "    \n",
    "    # Add observed photometry to plot\n",
    "    if galaxy.photometry_exists:\n",
    "        if galaxy.spectrum_exists:\n",
    "            phot_ax = plt.subplot(gs[1, 0])\n",
    "        else:\n",
    "            phot_ax = plt.subplot(gs[0, 0])  # Use first subplot if no spectrum\n",
    "        y_scale_phot = float(add_observed_photometry(galaxy, phot_ax, std))\n",
    "        y_scale.append(y_scale_phot)\n",
    "        axes.append(phot_ax)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "        #plt.close(fig)\n",
    "    \n",
    "    if return_y_scale:\n",
    "        return fig, axes, y_scale\n",
    "    \n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def add_observed_photometry_linear(galaxy, ax, standard_deviation, zorder=4, y_scale=None,\n",
    "                                   skip_no_obs=False, ptsize=40, lw=1.,\n",
    "                                   marker=\"o\", label=None, color=\"#60B5FF\"):\n",
    "    \"\"\" Adds photometric data to the passed axes without doing any\n",
    "    manipulation of the axes or labels. \"\"\"\n",
    "    photometry = np.copy(galaxy.photometry)\n",
    "\n",
    "    if skip_no_obs:\n",
    "        mask = (photometry[:, 1] != 0.)\n",
    "        photometry = photometry[mask, :]\n",
    "\n",
    "    mask = (photometry[:, 1] > 0.)\n",
    "    ymax = 1.05*np.nanmax((photometry[:, 1]+photometry[:, 2])[mask])\n",
    "\n",
    "    if not y_scale:\n",
    "        y_scale = int(np.log10(ymax))-1\n",
    "\n",
    "    # Plot the data - using linear wavelength scale\n",
    "    ax.errorbar(photometry[:, 0], photometry[:, 1]*10**-y_scale,\n",
    "                yerr=standard_deviation*10**-y_scale, lw=lw,\n",
    "                linestyle=\"\", capsize=300, capthick=lw, zorder=zorder-1,\n",
    "                color=\"black\")\n",
    "\n",
    "    #ax.scatter(photometry[:, 0], photometry[:, 1]*10**-y_scale, color=color,\n",
    "    #           s=ptsize, zorder=zorder, linewidth=lw, facecolor=color,\n",
    "    #           edgecolor=\"black\", marker=marker, label=label)\n",
    "\n",
    "    # Ensure linear scale\n",
    "    ax.set_xscale('linear')\n",
    "    auto_axis_label(ax, y_scale, log_x=False)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_spectrum_posterior(fit, standard_deviation, show=False, save=True, xlim=None, ylim=None, \n",
    "                           spectrum_xlim=None, spectrum_ylim=None, \n",
    "                           photometry_xlim=None, photometry_ylim=None):\n",
    "    \"\"\" \n",
    "    Plot the observational data and posterior from a fit object.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fit : object\n",
    "        Fit object containing galaxy data and posterior samples\n",
    "    show : bool, default False\n",
    "        Whether to display the plot\n",
    "    save : bool, default True\n",
    "        Whether to save the plot\n",
    "    xlim : tuple, optional\n",
    "        Global x-axis limits (min, max) applied to all subplots\n",
    "    ylim : tuple, optional\n",
    "        Global y-axis limits (min, max) applied to all subplots\n",
    "    spectrum_xlim : tuple, optional\n",
    "        X-axis limits specifically for spectrum plot\n",
    "    spectrum_ylim : tuple, optional\n",
    "        Y-axis limits specifically for spectrum plot\n",
    "    photometry_xlim : tuple, optional\n",
    "        X-axis limits specifically for photometry plot\n",
    "    photometry_ylim : tuple, optional\n",
    "        Y-axis limits specifically for photometry plot\n",
    "    \"\"\"\n",
    "    \n",
    "    fit.posterior.get_advanced_quantities()\n",
    "    \n",
    "    # First plot the observational data\n",
    "    print(fit.galaxy)\n",
    "    fig, ax, y_scale = plot_galaxy(fit.galaxy, standard_deviation, show=False, return_y_scale=True)\n",
    "    \n",
    "    # Get redshift for rest wavelength axis\n",
    "    if \"redshift\" in fit.fitted_model.params:\n",
    "        redshift = np.median(fit.posterior.samples[\"redshift\"])\n",
    "    else:\n",
    "        redshift = fit.fitted_model.model_components[\"redshift\"]\n",
    "    \n",
    "    # Handle spectrum plotting and limits\n",
    "    if fit.galaxy.spectrum_exists:\n",
    "        add_spectrum_posterior(fit, ax[0], zorder=6, y_scale=y_scale[0])\n",
    "        \n",
    "        # Set spectrum-specific limits or global limits BEFORE adding rest wavelength axis\n",
    "        if spectrum_xlim is not None:\n",
    "            ax[0].set_xlim(spectrum_xlim)\n",
    "        elif xlim is not None:\n",
    "            ax[0].set_xlim(xlim)\n",
    "            \n",
    "        if spectrum_ylim is not None:\n",
    "            ax[0].set_ylim(spectrum_ylim)\n",
    "        elif ylim is not None:\n",
    "            ax[0].set_ylim(ylim)\n",
    "        \n",
    "        # Add rest wavelength axis to spectrum plot AFTER setting limits\n",
    "        # This ensures the top axis adjusts to match the bottom axis limits\n",
    "        add_rest_wavelength_axis(ax[0], redshift)\n",
    "    \n",
    "    # Handle photometry plotting and limits\n",
    "    if fit.galaxy.photometry_exists:\n",
    "        add_photometry_posterior(fit, ax[-1], zorder=2, y_scale=y_scale[-1])\n",
    "        \n",
    "        # Set photometry-specific limits or global limits BEFORE adding rest wavelength axis\n",
    "        if photometry_xlim is not None:\n",
    "            ax[-1].set_xlim(photometry_xlim)\n",
    "        elif xlim is not None:\n",
    "            ax[-1].set_xlim(xlim)\n",
    "            \n",
    "        if photometry_ylim is not None:\n",
    "            ax[-1].set_ylim(photometry_ylim)\n",
    "        elif ylim is not None:\n",
    "            ax[-1].set_ylim(ylim)\n",
    "        \n",
    "        # Add rest wavelength axis to photometry plot AFTER setting limits\n",
    "        add_rest_wavelength_axis(ax[-1], redshift)\n",
    "    \n",
    "    # Apply global limits to any remaining axes if needed\n",
    "    if xlim is not None or ylim is not None:\n",
    "        for axis in ax:\n",
    "            if xlim is not None and axis.get_xlim() == axis.get_xlim():  # Check if not already set\n",
    "                axis.set_xlim(xlim)\n",
    "            if ylim is not None and axis.get_ylim() == axis.get_ylim():  # Check if not already set\n",
    "                axis.set_ylim(ylim)\n",
    "    \n",
    "    if save:\n",
    "        plotpath = \"pipes/plots/\" + fit.run + \"/\" + fit.galaxy.ID + \"_fit.pdf\"\n",
    "        plt.savefig(plotpath, bbox_inches=\"tight\")\n",
    "        #plt.close(fig)\n",
    "        \n",
    "    if show:\n",
    "        plt.show()\n",
    "        #plt.close(fig)\n",
    "        \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def add_photometry_posterior(fit, ax, zorder=4, y_scale=None, color1=None,\n",
    "                             color2=None, skip_no_obs=False,\n",
    "                             background_spectrum=True, label=None):\n",
    "    if color1 == None:\n",
    "        color1 = \"navajowhite\"\n",
    "    if color2 == None:\n",
    "        color2 = \"darkorange\"\n",
    "    mask = (fit.galaxy.photometry[:, 1] > 0.)\n",
    "    upper_lims = fit.galaxy.photometry[:, 1] + fit.galaxy.photometry[:, 2]\n",
    "    ymax = 1.05*np.max(upper_lims[mask])\n",
    "    if not y_scale:\n",
    "        y_scale = float(int(np.log10(ymax))-1)\n",
    "    # Calculate posterior median redshift.\n",
    "    if \"redshift\" in fit.fitted_model.params:\n",
    "        redshift = np.median(fit.posterior.samples[\"redshift\"])\n",
    "    else:\n",
    "        redshift = fit.fitted_model.model_components[\"redshift\"]\n",
    "    \n",
    "    # Plot the posterior photometry and full spectrum - using linear wavelength\n",
    "    # Convert from log wavelength to linear wavelength\n",
    "    wavs = fit.posterior.model_galaxy.wavelengths*(1.+redshift)  # Already linear wavelengths\n",
    "    eff_wavs = fit.galaxy.filter_set.eff_wavs  # Already linear effective wavelengths\n",
    "    \n",
    "    if background_spectrum:\n",
    "        spec_post = np.percentile(fit.posterior.samples[\"spectrum_full\"],\n",
    "                                  (16, 84), axis=0).T*10**-y_scale\n",
    "        spec_post = spec_post.astype(float)  # fixes weird isfinite error\n",
    "\n",
    "        ax.plot(wavs, spec_post[:, 1], color=\"black\",\n",
    "                zorder=zorder-1, linewidth=1.5)\n",
    "        \n",
    "        ax.fill_between(wavs, spec_post[:, 0], spec_post[:, 1],\n",
    "                        zorder=zorder-1, color=color1, linewidth=0)\n",
    "    phot_post = np.percentile(fit.posterior.samples[\"photometry\"],\n",
    "                              (16, 84), axis=0).T\n",
    "    \n",
    "    # Set x-axis to linear scale - this is the key fix\n",
    "    ax.set_xscale('linear')\n",
    "    \n",
    "    for j in range(fit.galaxy.photometry.shape[0]):\n",
    "        if skip_no_obs and fit.galaxy.photometry[j, 1] == 0.:\n",
    "            continue\n",
    "        phot_band = fit.posterior.samples[\"photometry\"][:, j]\n",
    "        mask = (phot_band > phot_post[j, 0]) & (phot_band < phot_post[j, 1])\n",
    "        phot_1sig = phot_band[mask]*10**-y_scale\n",
    "        wav_array = np.zeros(phot_1sig.shape[0]) + eff_wavs[j]  # Linear wavelengths\n",
    "        \n",
    "        if phot_1sig.min() < ymax*10**-y_scale:\n",
    "            ax.scatter(wav_array, phot_1sig, color=\"#ff14f5\",\n",
    "                       zorder=zorder, alpha=0.05, s=100, rasterized=True)\n",
    "    \n",
    "def add_spectrum_posterior(fit, ax, zorder=4, y_scale=None):\n",
    "    ymax = 1.05*np.max(fit.galaxy.spectrum[:, 1])\n",
    "    if not y_scale:\n",
    "        y_scale = float(int(np.log10(ymax))-1)\n",
    "    wavs = fit.galaxy.spectrum[:, 0]  # Linear wavelengths\n",
    "    spec_post = np.copy(fit.posterior.samples[\"spectrum\"])\n",
    "    if \"calib\" in list(fit.posterior.samples):\n",
    "        spec_post /= fit.posterior.samples[\"calib\"]\n",
    "    if \"noise\" in list(fit.posterior.samples):\n",
    "        spec_post += fit.posterior.samples[\"noise\"]\n",
    "    post = np.percentile(spec_post, (16, 50, 84), axis=0).T*10**-y_scale\n",
    "    ax.plot(wavs, post[:, 1], color=\"black\", zorder=zorder, lw=1.5)\n",
    "    ax.fill_between(wavs, post[:, 0], post[:, 2], color=\"sandybrown\",\n",
    "                    zorder=zorder, alpha=0.75, linewidth=0)\n",
    "    \n",
    "    # Set x-axis to linear scale\n",
    "    ax.set_xscale('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81874198-f0ff-4048-986a-bd2cbf95c14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d35dc2-054d-4ac2-8d51-0415c377c0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3325bda1-1ade-4155-933d-4101c21f6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "SED_File = Table.read(\"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Table_Gal_Flux_MicroJansky_For_Alexa.fits\", format = 'fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4850fdfb-89aa-4e99-ac57-362d4ebc3aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=7</i>\n",
       "<table id=\"table139924308932704\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Z_Redshift_Range</th><th>Z</th><th>Flux_SersicNOne_GaussianFixedSigma</th><th>Flux_SersicNOne_GaussianFixedSigma_SD</th></tr></thead>\n",
       "<thead><tr><th>bytes11</th><th>float64</th><th>float64[5]</th><th>float64[5]</th></tr></thead>\n",
       "<tr><td>0.25&lt;z&lt;0.35</td><td>0.3</td><td>60.2504540299246 .. 202.37658862214982</td><td>0.06919529792290219 .. 0.49851537948936625</td></tr>\n",
       "<tr><td>0.35&lt;z&lt;0.45</td><td>0.4</td><td>25.325231779057102 .. 101.36999580688371</td><td>0.04785900424257724 .. 0.22711461601382102</td></tr>\n",
       "<tr><td>0.45&lt;z&lt;0.55</td><td>0.5</td><td>22.337319170204033 .. 68.42959700049462</td><td>0.040347641948862145 .. 0.325427628753431</td></tr>\n",
       "<tr><td>0.55&lt;z&lt;0.65</td><td>0.6</td><td>19.728960480689732 .. 40.033964517428096</td><td>0.05885437270582918 .. 0.12016649003430539</td></tr>\n",
       "<tr><td>0.65&lt;z&lt;0.75</td><td>0.7</td><td>19.87106558475595 .. 39.34620130228341</td><td>0.03241986315031831 .. 0.13746596199414823</td></tr>\n",
       "<tr><td>0.75&lt;z&lt;0.85</td><td>0.8</td><td>19.09501680263071 .. 37.98986604820365</td><td>0.05203600248391178 .. 0.09519675350539408</td></tr>\n",
       "<tr><td>0.85&lt;z&lt;0.96</td><td>0.905</td><td>22.31031134907545 .. 37.25663753914093</td><td>0.03532842508160701 .. 0.10475759649761675</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=7>\n",
       "Z_Redshift_Range    Z    ...   Flux_SersicNOne_GaussianFixedSigma_SD   \n",
       "    bytes11      float64 ...                 float64[5]                \n",
       "---------------- ------- ... ------------------------------------------\n",
       "     0.25<z<0.35     0.3 ... 0.06919529792290219 .. 0.49851537948936625\n",
       "     0.35<z<0.45     0.4 ... 0.04785900424257724 .. 0.22711461601382102\n",
       "     0.45<z<0.55     0.5 ...  0.040347641948862145 .. 0.325427628753431\n",
       "     0.55<z<0.65     0.6 ... 0.05885437270582918 .. 0.12016649003430539\n",
       "     0.65<z<0.75     0.7 ... 0.03241986315031831 .. 0.13746596199414823\n",
       "     0.75<z<0.85     0.8 ... 0.05203600248391178 .. 0.09519675350539408\n",
       "     0.85<z<0.96   0.905 ... 0.03532842508160701 .. 0.10475759649761675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SED_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a3cf3f-2588-4eea-9366-c0510adeada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Redshift_Array = SED_File[\"Z\"]\n",
    "\n",
    "Flux_025_035 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma\"][0]\n",
    "Flux_035_045 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma\"][1]\n",
    "Flux_045_055 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma\"][2]\n",
    "Flux_055_065 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma\"][3]\n",
    "Flux_065_075 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma\"][4]\n",
    "Flux_075_085 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma\"][5]\n",
    "Flux_085_096 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma\"][6]\n",
    "\n",
    "Flux_SD_025_035 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma_SD\"][0]\n",
    "Flux_SD_035_045 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma_SD\"][1]\n",
    "Flux_SD_045_055 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma_SD\"][2]\n",
    "Flux_SD_055_065 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma_SD\"][3]\n",
    "Flux_SD_065_075 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma_SD\"][4]\n",
    "Flux_SD_075_085 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma_SD\"][5]\n",
    "Flux_SD_085_096 = SED_File[\"Flux_SersicNOne_GaussianFixedSigma_SD\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6563bb-f95e-4bb6-b094-a07e97577222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2fd40-7003-47bc-8e79-8acb3c38c206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64b5b8-fc80-4a67-a515-3e1c4bc0ffb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae0d31-9743-4a20-a672-94cd570565ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGPIPES AGN Host Galaxy SED Fitting (Parameter-Fixed Version)\n",
      "======================================================================\n",
      "✓ dynesty is available - excellent nested sampling alternative to MultiNest\n",
      "\n",
      "Creating BAGPIPES-compatible filter files...\n",
      "Created BAGPIPES filter file: bagpipes_filters/hsc_g.filt\n",
      "Created BAGPIPES filter file: bagpipes_filters/hsc_r.filt\n",
      "Created BAGPIPES filter file: bagpipes_filters/hsc_i.filt\n",
      "Created BAGPIPES filter file: bagpipes_filters/hsc_z.filt\n",
      "Created BAGPIPES filter file: bagpipes_filters/hsc_y.filt\n",
      "Successfully created 5 filter files\n",
      "Creating data loader function...\n",
      "Testing data loader...\n",
      "Data loader returning photometry with shape: (5, 2)\n",
      "Data type: float64\n",
      "Sample values: [[6.02504540e+01 6.91952979e-02]\n",
      " [1.54099051e+02 2.11873334e-01]]\n",
      "✓ Data loader test successful\n",
      "  Photometry shape: (5, 2)\n",
      "\n",
      "Photometric data summary:\n",
      "-----------------------------------\n",
      "hsc_g     :    60.25 ±   0.07 μJy (S/N: 870.7)\n",
      "hsc_i     :   154.10 ±   0.21 μJy (S/N: 727.3)\n",
      "hsc_r     :   109.98 ±   0.12 μJy (S/N: 910.4)\n",
      "hsc_y     :   212.14 ±   0.42 μJy (S/N: 499.9)\n",
      "hsc_z     :   202.38 ±   0.50 μJy (S/N: 406.0)\n",
      "\n",
      "Creating galaxy object...\n",
      "Data loader returning photometry with shape: (5, 2)\n",
      "Data type: float64\n",
      "Sample values: [[6.02504540e+01 6.91952979e-02]\n",
      " [1.54099051e+02 2.11873334e-01]]\n",
      "✓ Galaxy object created successfully!\n",
      "\n",
      "Setting up agn_optimized model...\n",
      "Model configuration:\n",
      "- redshift: 0.3\n",
      "- dblplaw: ['tau', 'alpha', 'beta', 'massformed', 'metallicity']\n",
      "- dust: ['type', 'Av']\n",
      "\n",
      "Creating fit object...\n",
      "✓ Fit object created successfully!\n",
      "\n",
      "Running SED fitting with dynesty sampler...\n",
      "Using dynesty with conservative settings...\n",
      "MultiNest not available. Switching to nautilus.\n",
      "\n",
      "Bagpipes: fitting object Redshift_025_035_n=300_agn_optimized_a\n",
      "\n",
      "Starting the nautilus sampler...\n",
      "Please report issues at github.com/johannesulf/nautilus.\n",
      "Status    | Bounds | Ellipses | Networks | Calls    | f_live | N_eff | log Z    \n",
      "Mean likelihood call time: 0.0027        | 900      | 1.0000 | 1     | -137520.9\n",
      "Wall time per lnlike call: 0.005\n",
      "Mean likelihood call time: 0.0024        | 1900     | 1.0000 | 1     | -87590.47\n",
      "Wall time per lnlike call: 0.0076\n",
      "Mean likelihood call time: 0.0024        | 2900     | 1.0000 | 1     | -42823.51\n",
      "Wall time per lnlike call: 0.0083\n",
      "Mean likelihood call time: 0.0024        | 3900     | 1.0000 | 1     | -42823.66\n",
      "Wall time per lnlike call: 0.0081\n",
      "Mean likelihood call time: 0.0024        | 4900     | 1.0000 | 1     | -70544.73\n",
      "Wall time per lnlike call: 0.009\n",
      "Mean likelihood call time: 0.0025        | 5900     | 1.0000 | 1     | -70547.06\n",
      "Wall time per lnlike call: 0.009\n",
      "Mean likelihood call time: 0.0024        | 6900     | 1.0000 | 1     | -70280.99\n",
      "Wall time per lnlike call: 0.0088\n",
      "Mean likelihood call time: 0.0025        | 7900     | 1.0000 | 1     | -69582.33\n",
      "Wall time per lnlike call: 0.0089\n",
      "Mean likelihood call time: 0.0024        | 8900     | 1.0000 | 1     | -69162.43\n",
      "Wall time per lnlike call: 0.0115\n",
      "Mean likelihood call time: 0.0024        | 9900     | 1.0000 | 1     | -68762.43\n",
      "Wall time per lnlike call: 0.0109\n",
      "Mean likelihood call time: 0.0025        | 10900    | 1.0000 | 1     | -68764.41\n",
      "Wall time per lnlike call: 0.0166\n",
      "Mean likelihood call time: 0.0025        | 11900    | 1.0000 | 1     | -67480.16\n",
      "Wall time per lnlike call: 0.0098\n",
      "Mean likelihood call time: 0.0026        | 12900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.0158\n",
      "Mean likelihood call time: 0.0025        | 13900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.0198\n",
      "Mean likelihood call time: 0.0024        | 14900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.0075\n",
      "Mean likelihood call time: 0.0024        | 15900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.024\n",
      "Mean likelihood call time: 0.0024        | 16900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.0093\n",
      "Mean likelihood call time: 0.0024        | 17900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.0092\n",
      "Mean likelihood call time: 0.0025        | 18900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.0299\n",
      "Mean likelihood call time: 0.0025        | 19900    | 1.0000 | 1     | -66525.78\n",
      "Wall time per lnlike call: 0.0099\n",
      "Mean likelihood call time: 0.0025        | 20900    | 1.0000 | 1     | -64368.05\n",
      "Wall time per lnlike call: 0.0097\n",
      "Mean likelihood call time: 0.0025        | 21900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0266\n",
      "Mean likelihood call time: 0.0026        | 22900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.009\n",
      "Mean likelihood call time: 0.0026        | 23900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0029\n",
      "Mean likelihood call time: 0.0026        | 24900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0029\n",
      "Mean likelihood call time: 0.0026        | 25900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0029\n",
      "Mean likelihood call time: 0.0026        | 26900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0029\n",
      "Mean likelihood call time: 0.0026        | 27900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0026        | 28900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0026        | 29900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0026        | 30900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0164\n",
      "Mean likelihood call time: 0.0026        | 31900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0214\n",
      "Mean likelihood call time: 0.0026        | 32900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0029\n",
      "Mean likelihood call time: 0.0026        | 33900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0217\n",
      "Mean likelihood call time: 0.0026        | 34900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0101\n",
      "Mean likelihood call time: 0.0026        | 35900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0066\n",
      "Mean likelihood call time: 0.0026        | 36900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0029\n",
      "Mean likelihood call time: 0.0027        | 37900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0069\n",
      "Mean likelihood call time: 0.0028        | 38900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 39900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0027        | 40900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0074\n",
      "Mean likelihood call time: 0.0027        | 41900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 42900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0026        | 43900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0107\n",
      "Mean likelihood call time: 0.0026        | 44900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0026        | 45900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0026        | 46900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0095\n",
      "Mean likelihood call time: 0.0025        | 47900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0029\n",
      "Mean likelihood call time: 0.0025        | 48900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0027        | 49900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0121\n",
      "Mean likelihood call time: 0.0027        | 50900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 51900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 52900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0103\n",
      "Mean likelihood call time: 0.0026        | 53900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.003\n",
      "Mean likelihood call time: 0.0026        | 54900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 55900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0108\n",
      "Mean likelihood call time: 0.0026        | 56900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0027        | 57900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0027        | 58900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.012\n",
      "Mean likelihood call time: 0.0027        | 59900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0027        | 60900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 61900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0199\n",
      "Mean likelihood call time: 0.0026        | 62900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 63900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0027        | 64900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0165\n",
      "Mean likelihood call time: 0.0027        | 65900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 66900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0027        | 67900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0212\n",
      "Mean likelihood call time: 0.0026        | 68900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 69900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 70900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0192\n",
      "Mean likelihood call time: 0.0027        | 71900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0028        | 72900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0027        | 73900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0194\n",
      "Mean likelihood call time: 0.0026        | 74900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 75900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 76900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0193\n",
      "Mean likelihood call time: 0.0027        | 77900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0027        | 78900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0027        | 79900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0228\n",
      "Mean likelihood call time: 0.0027        | 80900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 81900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0027        | 82900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0213\n",
      "Mean likelihood call time: 0.0027        | 83900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 84900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0031\n",
      "Mean likelihood call time: 0.0026        | 85900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0209\n",
      "Mean likelihood call time: 0.0026        | 86900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 87900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 88900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0206\n",
      "Mean likelihood call time: 0.0026        | 89900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0027        | 90900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0027        | 91900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0228\n",
      "Mean likelihood call time: 0.0027        | 92900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0027        | 93900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0026        | 94900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0229\n",
      "Mean likelihood call time: 0.0026        | 95900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0026        | 96900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0026        | 97900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0224\n",
      "Mean likelihood call time: 0.0026        | 98900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 99900    | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0027        | 100900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0176\n",
      "Mean likelihood call time: 0.0026        | 101900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0025        | 102900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0026        | 103900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0192\n",
      "Mean likelihood call time: 0.0026        | 104900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0027        | 105900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0027        | 106900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0216\n",
      "Mean likelihood call time: 0.0027        | 107900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0027        | 108900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 109900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0226\n",
      "Mean likelihood call time: 0.0026        | 110900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0026        | 111900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0026        | 112900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0198\n",
      "Mean likelihood call time: 0.0026        | 113900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0025        | 114900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0032\n",
      "Mean likelihood call time: 0.0027        | 115900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0222\n",
      "Mean likelihood call time: 0.0027        | 116900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 117900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 118900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0216\n",
      "Mean likelihood call time: 0.0026        | 119900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0027        | 120900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 121900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.025\n",
      "Mean likelihood call time: 0.0026        | 122900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 123900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0027        | 124900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0271\n",
      "Mean likelihood call time: 0.0025        | 125900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0026        | 126900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0033\n",
      "Mean likelihood call time: 0.0026        | 127900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0239\n",
      "Mean likelihood call time: 0.0026        | 128900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 129900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 130900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0253\n",
      "Mean likelihood call time: 0.0026        | 131900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 132900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 133900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0221\n",
      "Mean likelihood call time: 0.0027        | 134900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 135900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0028        | 136900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0235\n",
      "Mean likelihood call time: 0.0026        | 137900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 138900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 139900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0214\n",
      "Mean likelihood call time: 0.0026        | 140900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0026        | 141900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0034\n",
      "Mean likelihood call time: 0.0027        | 142900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0246\n",
      "Mean likelihood call time: 0.0027        | 143900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 144900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 145900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0227\n",
      "Mean likelihood call time: 0.0027        | 146900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0036\n",
      "Mean likelihood call time: 0.0026        | 147900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 148900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0292\n",
      "Mean likelihood call time: 0.0026        | 149900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 150900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0027        | 151900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0304\n",
      "Mean likelihood call time: 0.0027        | 152900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0026        | 153900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0026        | 154900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0281\n",
      "Mean likelihood call time: 0.0026        | 155900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0036\n",
      "Mean likelihood call time: 0.0027        | 156900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0027        | 157900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0289\n",
      "Mean likelihood call time: 0.0025        | 158900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 159900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0036\n",
      "Mean likelihood call time: 0.0026        | 160900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0267\n",
      "Mean likelihood call time: 0.0026        | 161900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 162900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0036\n",
      "Mean likelihood call time: 0.0026        | 163900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0283\n",
      "Mean likelihood call time: 0.0027        | 164900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0026        | 165900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0036\n",
      "Mean likelihood call time: 0.0026        | 166900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0284\n",
      "Mean likelihood call time: 0.0026        | 167900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 168900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 169900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0275\n",
      "Mean likelihood call time: 0.0025        | 170900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0025        | 171900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0035\n",
      "Mean likelihood call time: 0.0026        | 172900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0307\n",
      "Mean likelihood call time: 0.0026        | 173900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0026        | 174900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0026        | 175900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0268\n",
      "Mean likelihood call time: 0.0026        | 176900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0036\n",
      "Mean likelihood call time: 0.0026        | 177900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0027        | 178900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0356\n",
      "Mean likelihood call time: 0.0027        | 179900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0039\n",
      "Mean likelihood call time: 0.0026        | 180900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0027        | 181900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0275\n",
      "Mean likelihood call time: 0.0026        | 182900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0026        | 183900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0026        | 184900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0311\n",
      "Mean likelihood call time: 0.0026        | 185900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0037\n",
      "Mean likelihood call time: 0.0025        | 186900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0036\n",
      "Mean likelihood call time: 0.0026        | 187900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0294\n",
      "Mean likelihood call time: 0.0026        | 188900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 189900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0027        | 190900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0307\n",
      "Mean likelihood call time: 0.0027        | 191900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 192900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 193900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0302\n",
      "Mean likelihood call time: 0.0027        | 194900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0027        | 195900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 196900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0274\n",
      "Mean likelihood call time: 0.0026        | 197900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 198900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0027        | 199900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0337\n",
      "Mean likelihood call time: 0.0027        | 200900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0039\n",
      "Mean likelihood call time: 0.0027        | 201900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0027        | 202900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0318\n",
      "Mean likelihood call time: 0.0026        | 203900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 204900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 205900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0308\n",
      "Mean likelihood call time: 0.0026        | 206900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 207900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 208900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0277\n",
      "Mean likelihood call time: 0.0026        | 209900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 210900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 211900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0325\n",
      "Mean likelihood call time: 0.0027        | 212900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.004\n",
      "Mean likelihood call time: 0.0026        | 213900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0038\n",
      "Mean likelihood call time: 0.0026        | 214900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0333\n",
      "Mean likelihood call time: 0.0026        | 215900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0039\n",
      "Mean likelihood call time: 0.0027        | 216900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0039\n",
      "Mean likelihood call time: 0.0026        | 217900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0357\n",
      "Mean likelihood call time: 0.0026        | 218900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0039\n",
      "Mean likelihood call time: 0.0026        | 219900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0039\n",
      "Mean likelihood call time: 0.0027        | 220900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0349\n",
      "Mean likelihood call time: 0.0026        | 221900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0039\n",
      "Mean likelihood call time: 0.0027        | 222900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.004\n",
      "Mean likelihood call time: 0.0027        | 223900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0365\n",
      "Mean likelihood call time: 0.0026        | 224900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.004\n",
      "Mean likelihood call time: 0.0027        | 225900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 226900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0356\n",
      "Mean likelihood call time: 0.0026        | 227900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.004\n",
      "Mean likelihood call time: 0.0027        | 228900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 229900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0357\n",
      "Mean likelihood call time: 0.0026        | 230900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0027        | 231900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 232900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.038\n",
      "Mean likelihood call time: 0.0025        | 233900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.004\n",
      "Mean likelihood call time: 0.0026        | 234900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0042\n",
      "Mean likelihood call time: 0.0026        | 235900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0356\n",
      "Mean likelihood call time: 0.0026        | 236900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0027        | 237900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0042\n",
      "Mean likelihood call time: 0.0027        | 238900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0355\n",
      "Mean likelihood call time: 0.0026        | 239900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 240900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 241900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0382\n",
      "Mean likelihood call time: 0.0025        | 242900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.004\n",
      "Mean likelihood call time: 0.0026        | 243900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 244900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.038\n",
      "Mean likelihood call time: 0.0026        | 245900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0027        | 246900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0042\n",
      "Mean likelihood call time: 0.0026        | 247900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0388\n",
      "Mean likelihood call time: 0.0027        | 248900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0043\n",
      "Mean likelihood call time: 0.0026        | 249900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.004\n",
      "Mean likelihood call time: 0.0026        | 250900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0371\n",
      "Mean likelihood call time: 0.0026        | 251900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0042\n",
      "Mean likelihood call time: 0.0026        | 252900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0042\n",
      "Mean likelihood call time: 0.0026        | 253900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0338\n",
      "Mean likelihood call time: 0.0026        | 254900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 255900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0042\n",
      "Mean likelihood call time: 0.0026        | 256900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0332\n",
      "Mean likelihood call time: 0.0026        | 257900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0025        | 258900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 259900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0371\n",
      "Mean likelihood call time: 0.0026        | 260900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 261900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 262900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0326\n",
      "Mean likelihood call time: 0.0026        | 263900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0025        | 264900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0041\n",
      "Mean likelihood call time: 0.0026        | 459900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0051\n",
      "Mean likelihood call time: 0.0026        | 460900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0518\n",
      "Mean likelihood call time: 0.0025        | 461900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0051\n",
      "Mean likelihood call time: 0.0026        | 462900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0053\n",
      "Mean likelihood call time: 0.0025        | 463900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0519\n",
      "Mean likelihood call time: 0.0025        | 464900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0051\n",
      "Mean likelihood call time: 0.0025        | 465900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0026        | 466900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0464\n",
      "Mean likelihood call time: 0.0026        | 467900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0025        | 468900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0051\n",
      "Mean likelihood call time: 0.0025        | 469900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.042\n",
      "Mean likelihood call time: 0.0026        | 470900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0054\n",
      "Mean likelihood call time: 0.0025        | 471900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0025        | 472900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0457\n",
      "Mean likelihood call time: 0.0025        | 473900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0025        | 474900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0025        | 475900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0382\n",
      "Mean likelihood call time: 0.0026        | 476900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0054\n",
      "Mean likelihood call time: 0.0026        | 477900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0053\n",
      "Mean likelihood call time: 0.0026        | 478900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0363\n",
      "Mean likelihood call time: 0.0025        | 479900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0025        | 480900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0053\n",
      "Mean likelihood call time: 0.0026        | 481900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0504\n",
      "Mean likelihood call time: 0.0025        | 482900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0025        | 483900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0052\n",
      "Mean likelihood call time: 0.0025        | 484900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0556\n",
      "Mean likelihood call time: 0.0026        | 485900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0054\n",
      "Mean likelihood call time: 0.0026        | 486900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0053\n",
      "Mean likelihood call time: 0.0025        | 487900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.056\n",
      "Mean likelihood call time: 0.0026        | 488900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0054\n",
      "Mean likelihood call time: 0.0026        | 489900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0054\n",
      "Mean likelihood call time: 0.0025        | 490900   | 1.0000 | 1     | -64368.10\n",
      "Wall time per lnlike call: 0.0376\n",
      "Computing | 35     | 4        | 4        | 491200   | 1.0000 | 1     | -64368.10"
     ]
    }
   ],
   "source": [
    "fit_result_025_035, galaxy_obj_025_035 = run_bagpipes_fit_dynesty_fixed(\n",
    "    flux_array=Flux_025_035,\n",
    "    flux_err_array=Flux_SD_025_035,\n",
    "    filter_response_files=hsc_filter_files,\n",
    "    galaxy_id=\"Redshift_025_035_n=100_agn_optimized_a\",\n",
    "    redshift=0.3,\n",
    "    run_name=\"hsc_test_fit\",\n",
    "    n_live=100,\n",
    "    model_type=\"agn_optimized\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c254638-e9ea-49a9-b178-bc2704bb7948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2422daee-e544-46d2-8b90-635b96880a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "fig_025_035, ax_025_035 = plot_spectrum_posterior(fit_result_025_035, standard_deviation=Flux_SD_025_035, show=True, xlim=(4.0*10**3, 1.1*10**4), ylim=(4, 11.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192f5ac-4ff1-4152-b839-c44e65fff216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af41b9f-7110-4a07-a41d-b378aba2efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MNRAS style first\n",
    "set_mnras_style()\n",
    "\n",
    "# Create and customize corner plot\n",
    "fig_corner_025_035 = fit_result_025_035.plot_corner(save=False, show=False)\n",
    "fig_corner_025_035 = customize_corner_plot(fig_corner_025_035)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_corner_025_035, tuple):\n",
    "    fig_corner_025_035 = fig_corner_025_035[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df4ff2-7d2d-45bc-9b11-d5dc73bfd1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798a3db-799a-4c28-a335-7705ced78cfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93106418-1c35-431e-b9c2-c236600f1b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b337b-a4a9-4e44-91e3-fc17f60de034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b727a5-899f-4d8e-92ff-1eb17f960f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1764e9-e25f-4382-ad59-0fb0a8e66a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a1c1c-a440-4060-97b4-31ec4a37d0a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_result_035_045, galaxy_obj_035_045 = run_bagpipes_fit_dynesty_fixed(\n",
    "    flux_array=Flux_035_045,\n",
    "    flux_err_array=Flux_SD_035_045,\n",
    "    filter_response_files=hsc_filter_files,\n",
    "    galaxy_id=\"Redshift_035_045_n=100_agn_optimized_a\",\n",
    "    redshift=0.4,\n",
    "    run_name=\"hsc_test_fit\",\n",
    "    n_live=100,\n",
    "    model_type=\"agn_optimized\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10252a-d42b-4a48-8cea-c3503e598c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8ad7e-937d-4db8-b0f3-dd1dca820998",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "fig_035_045, ax_035_045 = plot_spectrum_posterior(fit_result_035_045, standard_deviation=Flux_SD_035_045, show=True, xlim=(4.0*10**3, 1.1*10**4), ylim=(0, 11.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a73015-8343-4424-8ec1-634c57f81eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79e458-5e01-4757-88ed-f060bc6dcacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MNRAS style first\n",
    "set_mnras_style()\n",
    "\n",
    "# Create and customize corner plot\n",
    "fig_corner_035_045 = fit_result_035_045.plot_corner(save=False, show=False)\n",
    "fig_corner_035_045 = customize_corner_plot(fig_corner_035_045)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_corner_035_045, tuple):\n",
    "    fig_corner_035_045 = fig_corner_035_045[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e53d206-bfae-48ac-88e7-32633e64d3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5de3f-20d5-4315-84bf-30bac4417ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659f3f6-b6c4-4b48-a6af-f54e09bcc00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a480f-e007-4d94-ad81-21c195a1d81a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_result_045_055, galaxy_obj_045_055 = run_bagpipes_fit_dynesty_fixed(\n",
    "    flux_array=Flux_045_055,\n",
    "    flux_err_array=Flux_SD_045_055,\n",
    "    filter_response_files=hsc_filter_files,\n",
    "    galaxy_id=\"Redshift_045_055_n=100_agn_optimized_a\",\n",
    "    redshift=0.5,\n",
    "    run_name=\"hsc_test_fit\",\n",
    "    n_live=100,\n",
    "    model_type=\"agn_optimized\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484f90c-fe55-4861-8213-24e74cfd91d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d3f74-50c6-4230-8005-675367416450",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "fig_045_055, ax_045_055 = plot_spectrum_posterior(fit_result_045_055, standard_deviation=Flux_SD_045_055, show=True, xlim=(4.0*10**3, 1.1*10**4), ylim=(0, 11.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d8269-edfa-4214-b528-2061736387e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9540505-15c8-4533-a700-91939e658cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MNRAS style first\n",
    "set_mnras_style()\n",
    "\n",
    "# Create and customize corner plot\n",
    "fig_corner_045_055 = fit_result_045_055.plot_corner(save=False, show=False)\n",
    "fig_corner_045_055 = customize_corner_plot(fig_corner_045_055)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_corner_045_055, tuple):\n",
    "    fig_corner_045_055 = fig_corner_045_055[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492aa47c-050e-43f0-8658-6ffe13602ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e4e85-e1b4-4540-a742-2a877d5f9c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b71994-dabb-4e0f-8c11-a46a93086afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3359a1-c0f9-42d9-9372-74875a26219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_055_065, galaxy_obj_055_065 = run_bagpipes_fit_dynesty_fixed(\n",
    "    flux_array=Flux_055_065,\n",
    "    flux_err_array=Flux_SD_055_065,\n",
    "    filter_response_files=hsc_filter_files,\n",
    "    galaxy_id=\"Redshift_055_065_n=100_agn_optimized_a\",\n",
    "    redshift=0.6,\n",
    "    run_name=\"hsc_test_fit\",\n",
    "    n_live=100,\n",
    "    model_type=\"agn_optimized\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aaaa30-a623-4383-853b-12b9fdae2592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc6096-c0a7-4d5e-8e53-1529ef71bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "fig_055_065, ax_055_065 = plot_spectrum_posterior(fit_result_055_065, standard_deviation=Flux_SD_055_065, show=True, xlim=(4.0*10**3, 1.1*10**4), ylim=(0, 11.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7498b73-01a3-4803-9707-09b1181a5cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6a9f9-9b93-4355-aaed-3e41848d0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MNRAS style first\n",
    "set_mnras_style()\n",
    "\n",
    "# Create and customize corner plot\n",
    "fig_corner_055_065 = fit_result_055_065.plot_corner(save=False, show=False)\n",
    "fig_corner_055_065 = customize_corner_plot(fig_corner_055_065)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_corner_055_065, tuple):\n",
    "    fig_corner_055_065 = fig_corner_055_065[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d08a17-f8d8-450e-be3a-01ade3640c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135abc1d-a454-457f-bcbb-9fd51162db1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ab2f9-9f73-4e6d-b211-2ebfcd85feb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b43ea-ca68-470f-bd6f-21787e38808f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_result_065_075, galaxy_obj_065_075 = run_bagpipes_fit_dynesty_fixed(\n",
    "    flux_array=Flux_065_075,\n",
    "    flux_err_array=Flux_SD_065_075,\n",
    "    filter_response_files=hsc_filter_files,\n",
    "    galaxy_id=\"Redshift_065_075_n=100_agn_optimized_a\",\n",
    "    redshift=0.7,\n",
    "    run_name=\"hsc_test_fit\",\n",
    "    n_live=100,\n",
    "    model_type=\"agn_optimized\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe80acd-fbba-4ca1-83a0-0682cbf74924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a8813-ec58-4cf0-a677-8557bb404a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "fig_065_075, ax_065_075 = plot_spectrum_posterior(fit_result_065_075, standard_deviation=Flux_SD_065_075, show=True, xlim=(4.0*10**3, 1.1*10**4), ylim=(0, 11.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e3796-a6c2-42a8-ae11-ec40ce17a398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c2a9e-7b0d-4a6d-8a6a-839b95553ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MNRAS style first\n",
    "set_mnras_style()\n",
    "\n",
    "# Create and customize corner plot\n",
    "fig_corner_065_075 = fit_result_065_075.plot_corner(save=False, show=False)\n",
    "fig_corner_065_075 = customize_corner_plot(fig_corner_065_075)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_corner_065_075, tuple):\n",
    "    fig_corner_065_075 = fig_corner_065_075[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad33a8-7933-41f7-8bc8-6e564eb31ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abaee7-f042-4cc4-9509-99d907dd9577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d617f2-d06c-4e09-a98b-20dbfc62f57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f4064-ae65-40f9-be66-0e6a429b66a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_result_075_085, galaxy_obj_075_085 = run_bagpipes_fit_dynesty_fixed(\n",
    "    flux_array=Flux_075_085,\n",
    "    flux_err_array=Flux_SD_075_085,\n",
    "    filter_response_files=hsc_filter_files,\n",
    "    galaxy_id=\"Redshift_075_085_n=100_agn_optimized_a\",\n",
    "    redshift=0.8,\n",
    "    run_name=\"hsc_test_fit\",\n",
    "    n_live=100,\n",
    "    model_type=\"agn_optimized\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff02ace-1922-447f-bf9c-0490b5a6d5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d7d3b-cb07-411a-b2ee-7bc004b59167",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "fig_075_085, ax_075_085 = plot_spectrum_posterior(fit_result_075_085, standard_deviation=Flux_SD_075_085, show=True, xlim=(4.0*10**3, 1.1*10**4), ylim=(0, 11.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c57bf-9caf-4cb0-9a46-a28a5372df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651b262-d302-4fae-a4e0-2d6bde79dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MNRAS style first\n",
    "set_mnras_style()\n",
    "\n",
    "# Create and customize corner plot\n",
    "fig_corner_075_085 = fit_result_075_085.plot_corner(save=False, show=False)\n",
    "fig_corner_075_085 = customize_corner_plot(fig_corner_075_085)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_corner_075_085, tuple):\n",
    "    fig_corner_075_085 = fig_corner_075_085[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0a217-07f6-4028-b4d7-e0bf0a458487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44485b0-a84f-4677-acc6-6fb3373d7c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee4225-dea8-4a53-97eb-eb5253b246e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b03f36-1e7e-45d8-9107-5f5cf6b53a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_result_085_096, galaxy_obj_085_096 = run_bagpipes_fit_dynesty_fixed(\n",
    "    flux_array=Flux_085_096,\n",
    "    flux_err_array=Flux_SD_085_096,\n",
    "    filter_response_files=hsc_filter_files,\n",
    "    galaxy_id=\"Redshift_085_096_n=100_agn_optimized_a\",\n",
    "    redshift=0.905,\n",
    "    run_name=\"hsc_test_fit\",\n",
    "    n_live=100,\n",
    "    model_type=\"agn_optimized\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf21594-18cf-48c0-a94a-757ad829e90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48933d0d-88a5-4860-9246-b6b3a7d16805",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "fig_085_096, ax_085_096 = plot_spectrum_posterior(fit_result_085_096, standard_deviation=Flux_SD_085_096, show=True, xlim=(4.0*10**3, 1.1*10**4), ylim=(0, 11.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac25212-2c5d-4424-b987-8f4a5ffdf92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565c0ba-218a-4e20-a28a-d75ff6539cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MNRAS style first\n",
    "set_mnras_style()\n",
    "\n",
    "# Create and customize corner plot\n",
    "fig_corner_085_096 = fit_result_085_096.plot_corner(save=False, show=False)\n",
    "fig_corner_085_096 = customize_corner_plot(fig_corner_085_096)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_corner_085_096, tuple):\n",
    "    fig_corner_085_096 = fig_corner_085_096[0]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0bd8c-b078-4402-b3bf-65349f9c2e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb82c4a-7d5e-4458-8982-04a39883fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stellar_Mass_025_035 = fit_result_025_035.posterior.samples[\"stellar_mass\"]\n",
    "Stellar_Mass_035_045 = fit_result_035_045.posterior.samples[\"stellar_mass\"]\n",
    "Stellar_Mass_045_055 = fit_result_045_055.posterior.samples[\"stellar_mass\"]\n",
    "Stellar_Mass_055_065 = fit_result_055_065.posterior.samples[\"stellar_mass\"]\n",
    "Stellar_Mass_065_075 = fit_result_065_075.posterior.samples[\"stellar_mass\"]\n",
    "Stellar_Mass_075_085 = fit_result_075_085.posterior.samples[\"stellar_mass\"]\n",
    "Stellar_Mass_085_096 = fit_result_085_096.posterior.samples[\"stellar_mass\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be2ac8-36be-40a8-a0ab-7c9eb3286bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Redshift_All = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.905]\n",
    "Stellar_Masses_All = [Stellar_Mass_025_035, Stellar_Mass_035_045, Stellar_Mass_045_055, Stellar_Mass_055_065, Stellar_Mass_065_075, \n",
    "                      Stellar_Mass_075_085, Stellar_Mass_085_096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273ac47-9de0-4ac0-be90-9988dac1d366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00faec44-904a-46d6-8b03-744d4e0e8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = QTable()\n",
    "    table['Z'] = Redshift_All\n",
    "    table['Stellar Mass Solar'] = Stellar_Masses_All\n",
    "\n",
    "table.write(\"/home/jovyan/work/stampede3/AGN-Black-Hole-Research/Stellar_Masses\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ccf45-a220-4935-82cb-92fe201ac182",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0dc61c-50bf-4763-9d00-33d26e6e88cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d7c09-c8de-4c6f-acb0-ad307f57064d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f72fbe-2c3a-4c00-9a49-50c47e043695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67270ea3-6295-4066-bcce-b4b66fc50c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89043af1-1be5-4653-80d9-e604a870cc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1622af0-4872-4791-bc00-ab3722767470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6582e2b-7aa2-48a9-8117-cd3ef7a2b450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5971db-90a6-4062-a80d-d14ac827e443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5180111-b4d0-4e99-aabb-3c10e06f2c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4cd67-9429-419d-9434-5493289990d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79157023-ef5f-4e00-908f-5975005c097f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d2b3d-6098-4dcd-adff-660af39bbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fit_results_linear(fit):\n",
    "    \"\"\"Print median ± error in linear units where appropriate\"\"\"\n",
    "    print(\"Parameter Results (Linear Units):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for param in sorted(fit.posterior.samples.keys()):\n",
    "        if param.startswith(('delayed:', 'dust:', 'stellar_mass', 'sfr', 'mass_weighted')):\n",
    "            samples = fit.posterior.samples[param]\n",
    "            median = np.median(samples)\n",
    "            error = (np.percentile(samples, 84) - np.percentile(samples, 16)) / 2\n",
    "            \n",
    "            # Convert log parameters to linear\n",
    "            if 'mass' in param and 'age' not in param and 'zmet' not in param:\n",
    "                # Mass parameters (log M☉ -> M☉)\n",
    "                linear_median = 10**median\n",
    "                # Error propagation for log->linear: σ_linear = ln(10) * 10^median * σ_log\n",
    "                linear_error = np.log(10) * linear_median * error\n",
    "                print(f\"{param:25s}: {linear_median:.2e} ± {linear_error:.2e} M☉\")\n",
    "                \n",
    "            elif param == 'delayed:metallicity' or 'zmet' in param:\n",
    "                # Metallicity (Z☉ units, already linear)\n",
    "                print(f\"{param:25s}: {median:.4f} ± {error:.4f} Z☉\")\n",
    "                \n",
    "            elif 'age' in param or param == 'delayed:tau':\n",
    "                # Time parameters (already in Gyr)\n",
    "                print(f\"{param:25s}: {median:.3f} ± {error:.3f} Gyr\")\n",
    "                \n",
    "            elif param == 'dust:Av':\n",
    "                # Dust attenuation (already linear in mag)\n",
    "                print(f\"{param:25s}: {median:.3f} ± {error:.3f} mag\")\n",
    "                \n",
    "            elif param == 'sfr':\n",
    "                # Star formation rate (already linear)\n",
    "                print(f\"{param:25s}: {median:.3f} ± {error:.3f} M☉/yr\")\n",
    "                \n",
    "            elif param == 'ssfr':\n",
    "                # Specific SFR (already linear)\n",
    "                print(f\"{param:25s}: {median:.2e} ± {error:.2e} yr⁻¹\")\n",
    "                \n",
    "            else:\n",
    "                # Default: print as-is with appropriate precision\n",
    "                if error < 0.01:\n",
    "                    print(f\"{param:25s}: {median:.4f} ± {error:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{param:25s}: {median:.3f} ± {error:.3f}\")\n",
    "\n",
    "# Usage:\n",
    "print_fit_results_linear(fit_result_085_096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce0eaf-28f1-4ced-a1fd-955c088b1466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658f9d6-d0a3-4272-ba53-69f986f9f28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428bf0d-f728-4afd-b35f-dba3b1ad8991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d80ce-57b3-4d18-a142-3d5a293deb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85beb6-b03f-40c8-80a2-8d639c556315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f50abd-f061-48a7-89fc-74f5889d4dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81758472-687e-4c9b-82b0-9f262ff78d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56eb6e-a395-40ee-9f46-e87130cb1d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea00b34-0111-496f-8397-670ba618534e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005216e-621f-404b-b6b3-3c0c6ad12607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9893ff3-3085-4c2f-9372-4489274855cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292981c7-6a51-48c4-9455-95f186ff3560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a5e7e-0694-4774-8e20-bdbb976e40a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419e77f-65c6-421c-9984-de72aa172b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f0366-afdb-4c9d-a1b2-0886bdf7f305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0aad3-496b-4d8f-9af3-78ef591a360b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391a66c-b183-4848-828f-486c1c699630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aee955-e7d3-462e-bb8d-a4177b219a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b140731-a3b4-4888-98bf-385ebc1a9101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b7fb9-77d5-4291-a649-d702951fb370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a9b3a-73a7-4ed9-b31b-daef7efaaba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnras_style()\n",
    "\n",
    "# Create and customize SFH plot\n",
    "fig_sfh = fit_result_025_035.plot_sfh_posterior(save=False, show=False)\n",
    "fig_sfh = customize_sfh_plot(fig_sfh)\n",
    "# Extract figure if tuple\n",
    "if isinstance(fig_sfh, tuple):\n",
    "    fig_sfh = fig_sfh[0]\n",
    "\n",
    "plt.ylim(-10, 130)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
